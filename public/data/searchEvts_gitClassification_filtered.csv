eventID,videoID,timed_url,time,img_file,text_file,notes,code_text,coords
1,2,https://www.google.com/search?q=set+up+venv+python&rlz=1C1SQJL_enUS958US958&oq=set+up+venv+&aqs=chrome.1.69i57j0i512l8j0i390.3828j0j7&sourceid=chrome&ie=UTF-8,0,screencapture-n0_2022-10-27-20_03_20.png,,search: set up venv python;,,
2,2,https://realpython.com/lessons/creating-virtual-environment/,6,screencapture-n1_2022-10-27-20_03_26.png,,visit: Creating a Virtual Environment â€“ Real Python;,,
3,2,,348,,,output: output.txt;,"Hello world from venv
(venv)",
4,2,,348,,,code: test.py;,"print(""Hello world from venv"")",
5,2,https://www.google.com/search?q=trash+vs+non+trash+classifier&rlz=1C1SQJL_enUS958US958&oq=trash+vs+non+trash+classi&aqs=chrome.1.69i57j33i160j33i160i395.6884j1j7&sourceid=chrome&ie=UTF-8,394,screencapture-n2_2022-10-27-20_09_54.png,,search: trash vs non trash classifier;,,
6,2,https://www.rootstrap.com/waste-classifier-machine-learning-case-study/,424,screencapture-n3_2022-10-27-20_10_24.png,,visit: Waste Classifier Machine Learning - Rootstrap;,,
7,2,https://www.google.com/search?q=image+classification+python&rlz=1C1SQJL_enUS958US958&sxsrf=ALiCzsZip_cmtP8XXb8oRxkTgC6XntfEEA%3A1666919393451&ei=4StbY-mbG5S0ptQP-I2E0A0&oq=image+class&gs_lp=Egdnd3Mtd2l6uAED-AEBKgIIATILEAAYsQMYgwEYkQIyBRAAGJECMgUQABiRAjIFEAAYgAQyChAAGIAEGOUEGAoyBRAAGIAEMgUQABiABDIFEAAYgAQyBRAAGIAEMgUQABiABMICBBAjGCfCAgsQABiABBixAxiDAcICCxAuGIAEGMcBGNEDwgIEEAAYQ8ICDhAuGIAEGLEDGMcBGNEDwgIEEC4YQ8ICChAAGLEDGIMBGEPCAgYQABgKGEPCAgcQABixAxhDwgIIEC4YgAQYsQPCAgcQLhixAxhDwgIIEAAYgAQYsQPCAg4QLhiABBjHARivARjUAsICCxAuGIAEGMcBGK8BSLUaUABYghBwAHgByAEAkAEAmAGIAaABhAmqAQM0LjfiAwQgTRgB4gMEIEEYAOIDBCBGGACIBgE&sclient=gws-wiz,460,screencapture-n4_2022-10-27-20_11_00.png,,search: image classification python;,,
8,2,https://www.google.com/search?q=image+classification+python+pytorch&rlz=1C1SQJL_enUS958US958&sxsrf=ALiCzsYcmwKE1RQTnr3rGdoqyFBcGqXLZw%3A1666919458892&ei=IixbY6nMNeqhptQPso6G8Ac&ved=0ahUKEwip5dzx3oH7AhXqkIkEHTKHAX4Q4dUDCBA&uact=5&oq=image+classification+python+pytorch&gs_lp=ugYGCAEQARgJugYGCAIQARgIEgdnd3Mtd2l6uAED-AEBGgIYAjIFEAAYgAQyBRAAGIYDMgUQABiGAzIFEAAYhgPCAgoQABhHGNYEGLADwgIHEAAYsAMYQ8ICDhAAGOQCGNYEGLAD2AEBwgITEC4YxwEY0QMYyAMYsAMYQ9gBAsICBBAAGEPCAgYQABgWGB7CAggQIRigARiLA8ICCBAhGBYYHhgdwgILECEYFhgeGB0YiwPCAgcQABiABBgNwgIKECEYoAEYChiLA8ICBxAhGKABGAqQBhFI_ipQswNY9ShwBngByAEAkAEAmAGQAaAB9gmqAQM4LjXiAwQgTRgB4gMEIEEYAOIDBCBGGAGIBgE&sclient=gws-wiz,468,screencapture-n5_2022-10-27-20_11_08.png,,search: image classification python pytorch;,,
9,2,https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html,477,screencapture-n6_2022-10-27-20_11_17.png,,visit: Training a Classifier â€” PyTorch Tutorials 1.13.0+cu117 documentation;,,
10,2,https://www.google.com/search?q=enter+a+venv+from+cmd&rlz=1C1SQJL_enUS958US958&oq=enter+a+venv+from+cmd&aqs=chrome..69i57j33i160.6701j1j7&sourceid=chrome&ie=UTF-8,523,screencapture-n7_2022-10-27-20_12_03.png,,search: enter a venv from cmd;,,
11,2,https://stackoverflow.com/questions/46896093/how-to-activate-virtual-environment-from-windows-10-command-prompt,524,screencapture-n8_2022-10-27-20_12_04.png,,visit: python - How to activate virtual environment from Windows 10 command prompt - Stack Overflow;,,
12,2,https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html,557,screencapture-n9_2022-10-27-20_12_37.png,,revisit: Training a Classifier â€” PyTorch Tutorials 1.13.0+cu117 documentation;,,
13,2,https://stackoverflow.com/questions/46896093/how-to-activate-virtual-environment-from-windows-10-command-prompt,589,screencapture-n10_2022-10-27-20_13_09.png,,revisit: python - How to activate virtual environment from Windows 10 command prompt - Stack Overflow;,,
14,2,https://pytorch.org/tutorials/beginner/introyt.html,602,screencapture-n11_2022-10-27-20_13_22.png,,visit: Introduction to PyTorch - YouTube Series â€” PyTorch Tutorials 1.13.0+cu117 documentation;,,
15,2,https://pytorch.org/tutorials/beginner/introyt/introyt1_tutorial.html,627,screencapture-n12_2022-10-27-20_13_47.png,,visit: Introduction to PyTorch â€” PyTorch Tutorials 1.13.0+cu117 documentation;,,
16,2,https://www.youtube.com/watch?v=IC0_FRiX-sw&t=49s,694,screencapture-n13_2022-10-27-20_14_54.png,,visit: Introduction to PyTorch - YouTube;,,
17,2,https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html,763,screencapture-n14_2022-10-27-20_16_03.png,,visit: Quickstart â€” PyTorch Tutorials 1.13.0+cu117 documentation;,,
18,2,https://www.google.com/search?q=install+pytorch&rlz=1C1SQJL_enUS958US958&oq=install+pytorch&aqs=chrome..69i57j0i20i263i512j0i512l8.3601j1j7&sourceid=chrome&ie=UTF-8,798,screencapture-n15_2022-10-27-20_16_38.png,,search: install pytorch;,,
19,2,https://pytorch.org/TensorRT/tutorials/installation.html,801,screencapture-n16_2022-10-27-20_16_41.png,,visit: Installation â€” Torch-TensorRT v1.1.1 documentation;,,
20,2,https://pytorch.org/get-started/locally/,835,screencapture-n17_2022-10-27-20_17_15.png,,visit: Start Locally | PyTorch;,,
21,2,,988,,,output: output.txt;,"c:/Users/thien/Desktop/project/venv/Scripts/python.exe c:/Users/thien/Desktop/project/test.py
tensor([[0., 0., 0.], 
        [0., 0., 0.], 
        [0., 0., 0.], 
        [0., 0., 0.], 
        [0., 0., 0.]])
<built-in method type of Tensor object at 0x00000285E4B67D10>
(venv)",
22,2,,988,,,code: test.py;,"import torch

z = torch.zeros(5, 3)
print(z)
print(z.type)",
23,2,https://www.youtube.com/watch?v=IC0_FRiX-sw&t=49s,1033,screencapture-n18_2022-10-27-20_20_33.png,,revisit: Introduction to PyTorch - YouTube;,,
24,2,https://www.youtube.com/watch?v=OSqIP-mOWOI&list=PL_lsbAsL_o2CTlGHgMxNrKhzP97BaG9ZN&index=4,1045,screencapture-n19_2022-10-27-20_20_45.png,,visit: Building Models with PyTorch - YouTube;,,
25,2,https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html,1101,screencapture-n20_2022-10-27-20_21_41.png,,revisit: Training a Classifier â€” PyTorch Tutorials 1.13.0+cu117 documentation;,,
26,2,,1343,,,output: output.txt;,"c:/Users/thien/Desktop/project/venv/Scripts/python.exe c:/Users/thien/Desktop/project/test.py
Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./dat\cifar-10-python.tar.gz
0.0%0.0%0.1%0.1%0.1%0.2%0.2%0.3%0.4%0.5%0.6%0.7%0.8%0.9%1.1%1.2%1.3%1.4%1.5%1.7%1.8%1.9%2.0%2.2%2.3%2.5%2.6%2.8%2.9%3.1%3.2%3.4%3.6%3.7%3.9%4.1%4.3%4.5%4.7%4.8%5.1%5.3%5.5%5.7%5.9%6.1%6.4%6.6%6.8%7.1%7.3%7.5%7.8%8.1%8.4%8.6%9.0%9.2%9.5%9.8%10.1%10.4%10.7%11.1%11.4%11.6%12.0%12.3%12.7%13.1%13.4%13.6%14.0%14.4%14.7%15.0%15.3%15.7%16.0%16.2%16.7%17.0%17.3%17.7%18.0%18.4%18.8%19.1%19.5%19.9%20.2%20.6%21.0%21.4%21.7%22.1%22.5%22.9%23.2%23.6%24.0%24.4%24.7%25.1%25.5%25.8%26.2%26.6%27.0%27.3%27.6%28.1%28.3%28.8%29.2%29.6%29.9%30.3%30.6%31.0%31.4%31.8%32.2%32.6%32.9%33.3%33.7%34.0%34.4%34.8%35.2%35.5%35.9%36.3%36.7%37.0%37.4%37.8%38.1%38.5%38.8%39.3%39.6%40.0%40.3%40.8%41.1%41.5%41.9%42.2%42.6%43.0%43.4%43.8%44.1%44.5%44.9%45.2%45.6%46.0%46.3%46.7%47.1%47.5%47.8%48.2%48.6%48.9%49.3%49.7%50.1%50.4%50.6%51.1%51.5%51.9%52.2%52.6%52.9%53.4%53.7%54.1%54.4%54.8%55.2%55.5%55.9%56.1%56.1%57.7%57.8%57.8%58.4%58.8%59.1%59.5%59.9%60.3%60.6%60.7%60.7%60.9%61.7%61.7%62.5%62.5%62.5%62.6%62.6%63.0%63.3%63.7%64.0%64.2%64.7%64.9%65.2%65.4%65.7%66.0%66.2%66.5%66.8%67.0%67.3%67.5%67.8%68.0%68.3%68.6%68.8%69.1%69.5%69.7%70.0%70.3%70.5%70.8%71.1%71.4%71.6%71.9%72.0%72.4%72.7%72.9%73.1%73.5%73.7%74.0%74.2%74.5%74.8%75.1%75.5%75.9%76.1%76.4%76.6%76.9%77.2%77.4%77.7%78.0%78.2%78.5%78.8%79.1%79.2%79.6%79.8%80.1%80.4%80.7%81.0%81.2%81.5%81.8%81.9%82.3%82.6%82.8%83.1%83.4%83.7%83.9%84.2%84.4%84.7%85.0%85.2%85.4%85.5%86.0%86.1%86.1%86.3%86.6%86.8%87.1%87.4%87.6%87.9%88.2%88.4%88.7%89.0%89.2%89.5%89.8%90.0%90.3%90.5%90.8%91.1%91.3%91.6%91.9%92.2%92.5%92.7%93.0%93.3%93.6%93.8%94.1%94.4%94.7%95.0%95.3%95.5%95.8%96.1%96.4%96.6%96.9%97.2%97.5%97.7%98.0%98.3%98.5%98.8%99.1%99.4%99.6%99.9%100.0%
Extracting ./dat\cifar-10-python.tar.gz to ./dat
Files already downloaded and verified
(venv)",
27,2,,1343,,,code: test.py;,"import torch
import torchvision
import torchvision.transforms as transforms


transform = transforms.Compose(
    [transforms.ToTensor(),
     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])

batch_size = 4

trainset = torchvision.datasets.CIFAR10(root='./dat', train=True,
                                        download=True, transform=transform)
trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,
                                          shuffle=True, num_workers=2)

testset = torchvision.datasets.CIFAR10(root='./dat', train=False,
                                       download=True, transform=transform)
testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,
                                         shuffle=False, num_workers=2)

classes = ('plane', 'car', 'bird', 'cat',
           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')",
28,2,,1666,,,output: output.txt;,"cat   bird  bird  dog  
(venv)",
29,2,,1666,,,code: test.py;,"import torch
import torchvision
import torchvision.transforms as transforms

import matplotlib.pyplot as plt
import numpy as np


transform = transforms.Compose(
    [transforms.ToTensor(),
     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])

batch_size = 4

trainset = torchvision.datasets.CIFAR10(root='./dat', train=True,
                                        download=False, transform=transform)
trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,
                                          shuffle=True, num_workers=0)

testset = torchvision.datasets.CIFAR10(root='./dat', train=False,
                                       download=False, transform=transform)
testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,
                                         shuffle=False, num_workers=0)

classes = ('plane', 'car', 'bird', 'cat',
           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')

# functions to show an image
def imshow(img):
    img = img / 2 + 0.5     # unnormalize
    npimg = img.numpy()
    plt.imshow(np.transpose(npimg, (1, 2, 0)))
    plt.show()


# get some random training images
dataiter = iter(trainloader)
images, labels = next(dataiter)

# show images
imshow(torchvision.utils.make_grid(images))
# print labels
print(' '.join(f'{classes[labels[j]]:5s}' for j in range(batch_size)))",
30,2,,1913,,,output: output.txt;,"c:/Users/thien/Desktop/project/venv/Scripts/python.exe c:/Users/thien/Desktop/project/test.py
[1,  2000] loss: 2.199
[1,  4000] loss: 1.849
[1,  6000] loss: 1.660
[1,  8000] loss: 1.565
[1, 10000] loss: 1.495
[1, 12000] loss: 1.423
[2,  2000] loss: 1.362
[2,  4000] loss: 1.333
[2,  6000] loss: 1.322
[2,  8000] loss: 1.295
[2, 10000] loss: 1.281
[2, 12000] loss: 1.244
Finished Training
(venv)",
31,2,,1913,,,code: test.py;,"import torch
import torchvision
import torchvision.transforms as transforms

import matplotlib.pyplot as plt
import numpy as np

import torch.nn as nn
import torch.nn.functional as F


transform = transforms.Compose(
    [transforms.ToTensor(),
     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])

batch_size = 4

trainset = torchvision.datasets.CIFAR10(root='./dat', train=True,
                                        download=False, transform=transform)
trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,
                                          shuffle=True, num_workers=0)

testset = torchvision.datasets.CIFAR10(root='./dat', train=False,
                                       download=False, transform=transform)
testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,
                                         shuffle=False, num_workers=0)

classes = ('plane', 'car', 'bird', 'cat',
           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')

# functions to show an image
def imshow(img):
    img = img / 2 + 0.5     # unnormalize
    npimg = img.numpy()
    plt.imshow(np.transpose(npimg, (1, 2, 0)))
    plt.show()


# get some random training images
dataiter = iter(trainloader)
images, labels = next(dataiter)

# show images
imshow(torchvision.utils.make_grid(images))
# print labels
# print(' '.join(f'{classes[labels[j]]:5s}' for j in range(batch_size)))


class Net(nn.Module):
    def __init__(self):
        super().__init__()
        self.conv1 = nn.Conv2d(3, 6, 5)
        self.pool = nn.MaxPool2d(2, 2)
        self.conv2 = nn.Conv2d(6, 16, 5)
        self.fc1 = nn.Linear(16 * 5 * 5, 120)
        self.fc2 = nn.Linear(120, 84)
        self.fc3 = nn.Linear(84, 10)

    def forward(self, x):
        x = self.pool(F.relu(self.conv1(x)))
        x = self.pool(F.relu(self.conv2(x)))
        x = torch.flatten(x, 1) # flatten all dimensions except batch
        x = F.relu(self.fc1(x))
        x = F.relu(self.fc2(x))
        x = self.fc3(x)
        return x

net = Net()

import torch.optim as optim

criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)

for epoch in range(2):  # loop over the dataset multiple times

    running_loss = 0.0
    for i, data in enumerate(trainloader, 0):
        # get the inputs; data is a list of [inputs, labels]
        inputs, labels = data

        # zero the parameter gradients
        optimizer.zero_grad()

        # forward + backward + optimize
        outputs = net(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        # print statistics
        running_loss += loss.item()
        if i % 2000 == 1999:    # print every 2000 mini-batches
            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')
            running_loss = 0.0

print('Finished Training')",
32,2,https://www.google.com/search?q=trash+image+dataset&rlz=1C1SQJL_enUS958US958&oq=trash+image+dataset&aqs=chrome..69i57j0i22i30j0i390l4.14984j0j7&sourceid=chrome&ie=UTF-8,2005,screencapture-n21_2022-10-27-20_36_45.png,,search: trash image dataset;,,
33,2,http://tacodataset.org/,2019,screencapture-n22_2022-10-27-20_36_59.png,,visit: http://tacodataset.org/;,,
34,2,https://github.com/pedropro/TACO,2038,screencapture-n23_2022-10-27-20_37_18.png,,visit: GitHub - pedropro/TACO: ðŸŒ® Trash Annotations in Context Dataset Toolkit;,,
35,2,https://www.google.com/search?q=waste+image+dataset&rlz=1C1SQJL_enUS958US958&oq=waste+image+dataset&aqs=chrome..69i57j0i7i30j0i5i30l2j0i390l4.8916j0j7&sourceid=chrome&ie=UTF-8,2107,screencapture-n24_2022-10-27-20_38_27.png,,search: waste image dataset;,,
36,2,https://www.kaggle.com/datasets/asdasdasasdas/garbage-classification,2130,screencapture-n25_2022-10-27-20_38_50.png,,visit: Garbage Classification | Kaggle;,,
37,2,https://recycleye.com/wastenet/,2139,screencapture-n26_2022-10-27-20_38_59.png,,visit: WasteNet - Recycleye - The world's largest dataset for waste;,,
38,2,https://www.kaggle.com/datasets/asdasdasasdas/garbage-classification,2181,screencapture-n27_2022-10-27-20_39_41.png,,revisit: Garbage Classification | Kaggle;,,
41,2,https://www.google.com/search?q=access+and+open+pil+image&rlz=1C1SQJL_enUS958US958&oq=access+and+open+pil+&aqs=chrome.3.69i57j33i160i395l5.10745j1j7&sourceid=chrome&ie=UTF-8,2556,screencapture-n30_2022-10-27-20_45_56.png,,search: access and open pil image;,,
42,2,https://www.geeksforgeeks.org/python-pil-image-open-method/,2559,screencapture-n31_2022-10-27-20_45_59.png,,visit: Python PIL | Image.open() method - GeeksforGeeks;,,
43,2,https://www.google.com/search?q=python+accessing+a+directory&rlz=1C1SQJL_enUS958US958&oq=python+accessing+a+directory&aqs=chrome..69i57j0i22i30l9.20947j0j7&sourceid=chrome&ie=UTF-8,2654,screencapture-n32_2022-10-27-20_47_34.png,,search: python accessing a directory;,,
44,2,https://stackoverflow.com/questions/14574705/accessing-directories-and-files-using-python,2657,screencapture-n33_2022-10-27-20_47_37.png,,visit: Accessing directories and files using python - Stack Overflow;,,
45,2,,2776,,,code: main.py;,"from PIL import Image
  
im = Image.open(r""C:\Users\thien\Desktop\project\dat\Garbage classification\Garbage classification\glass\glass11.jpg"")
im.show() ",
46,2,,2776,,,output: output.txt;,"c:/Users/thien/Desktop/project/venv/Scripts/python.exe c:/Users/thien/Desktop/project/main.py
(venv)",
47,2,https://www.google.com/search?q=relative+path+python&rlz=1C1SQJL_enUS958US958&oq=relative+path+&aqs=chrome.1.69i57j0i20i131i263i433i512j0i512l8.3169j0j7&sourceid=chrome&ie=UTF-8,3066,screencapture-n34_2022-10-27-20_54_26.png,,search: relative path python;,,
48,2,https://stackoverflow.com/questions/918154/relative-paths-in-python,3067,screencapture-n35_2022-10-27-20_54_27.png,,visit: Relative paths in Python - Stack Overflow;,,
49,2,,3188,,,code: main.py;,"# from PIL import Image
  
# im = Image.open(r""C:\Users\thien\Desktop\project\dat\Garbage classification\Garbage classification\glass\glass11.jpg"")
# im.show() 

import os
dir = os.path.dirname(__file__)
garbage_classification_folder = os.path.join(dir, 'Garbage classification')

print(garbage_classification_folder)",
50,2,,3188,,,output: output.txt;,"c:/Users/thien/Desktop/project/venv/Scripts/python.exe c:/Users/thien/Desktop/project/main.py
c:/Users/thien/Desktop/project\Garbage classification
(venv)",
51,2,https://www.google.com/search?q=how+to+find+if+a+directory+exists+in+python&rlz=1C1SQJL_enUS958US958&oq=how+to+find+if+a+dire&aqs=chrome.2.0i512j69i57j0i20i263i512j0i22i30l7.5770j0j4&sourceid=chrome&ie=UTF-8,3219,screencapture-n36_2022-10-27-20_56_59.png,,search: how to find if a directory exists in python;,,
52,2,https://stackoverflow.com/questions/8933237/how-do-i-check-if-directory-exists-in-python,3221,screencapture-n37_2022-10-27-20_57_01.png,,visit: How do I check if directory exists in Python? - Stack Overflow;,,
53,2,https://www.google.com/search?q=directing+to+an+existing+directory+in+python&rlz=1C1SQJL_enUS958US958&sxsrf=ALiCzsbUpvmkvNK2t8xn5A6U75dkiw8BmA%3A1666922218265&ei=6jZbY-XmD8SGptQPvp2kuA0&oq=directing+to+an+existing&gs_lp=Egdnd3Mtd2l6uAED-AEBGgIYAyoCCAAyChAhGKABGAoYiwMyChAhGKABGAoYiwMyCBAhGKsCGIsDMggQIRirAhiLAzIIECEYqwIYiwPCAgQQIxgnwgIFEAAYkQLCAg4QLhiABBixAxjHARjRA8ICCBAAGIAEGLEDwgIIEAAYsQMYgwHCAgsQABiABBixAxiDAcICERAuGIAEGLEDGIMBGMcBGNEDwgIEEAAYQ8ICCxAuGIAEGMcBGNEDwgIHEAAYyQMYQ8ICERAuGIAEGLEDGMcBGNEDGNQCwgIKEAAYsQMYgwEYQ8ICBxAAGLEDGEPCAgUQABiABMICDRAAGIAEGLEDGIMBGArCAgoQABiABBixAxgKwgINEAAYgAQYsQMYRhj5AcICCBAuGIAEGNQCwgIFEC4YgATCAgcQABiABBgKwgIFEAAYsQPCAgYQABgWGB7CAggQABgWGB4YD8ICCRAAGIAEGA0YCsICBxAAGIAEGA3CAgYQABgeGA3CAgUQABiGA8ICCxAhGBYYHhgdGIsDwgINECEYFhgeGA8YHRiLA8ICCBAhGBYYHhgdSJk5UABYtzBwAXgByAEAkAEAmAGbAaABnxOqAQQxNy444gMEIEEYAOIDBCBGGACIBgE&sclient=gws-wiz,3299,screencapture-n38_2022-10-27-20_58_19.png,,search: directing to an existing directory in python;,,
54,2,https://www.geeksforgeeks.org/change-current-working-directory-with-python/,3315,screencapture-n39_2022-10-27-20_58_35.png,,visit: Change current working directory with Python - GeeksforGeeks;,,
55,2,https://www.google.com/search?q=locate+a+path+to+a+directory+in+python&rlz=1C1SQJL_enUS958US958&oq=locate+a+path+to+a+directory+in+python&aqs=chrome..69i57j0i22i30j0i390l4.12486j1j4&sourceid=chrome&ie=UTF-8,3382,screencapture-n40_2022-10-27-20_59_42.png,,search: locate a path to a directory in python;,,
56,2,https://stackoverflow.com/questions/3430372/how-do-i-get-the-full-path-of-the-current-files-directory,3388,screencapture-n41_2022-10-27-20_59_48.png,,visit: python - How do I get the full path of the current file's directory? - Stack Overflow;,,
57,2,,3526,,,code: main.py;,"# from PIL import Image
  
# im = Image.open(r""C:\Users\thien\Desktop\project\dat\Garbage classification\Garbage classification\glass\glass11.jpg"")
# im.show() 

import os
dir = os.path.dirname(__file__)
garbage_classification_folder = os.path.join(dir, '/dat/Garbage classification/Garbage classification')

print(garbage_classification_folder, ' is a valid ', os.path.isdir(garbage_classification_folder))",
58,2,,3526,,,output: output.txt;,"c:/Users/thien/Desktop/project/venv/Scripts/python.exe c:/Users/thien/Desktop/project/main.py
c:/dat/Garbage classification/Garbage classification  is a valid  False
(venv)",
59,2,https://www.google.com/search?q=get+the+path+of+a+directory+python&rlz=1C1SQJL_enUS958US958&oq=get+the+path+to+a+directory&aqs=chrome.1.69i57j0i22i30l6j69i60.10549j1j4&sourceid=chrome&ie=UTF-8,3597,screencapture-n42_2022-10-27-21_03_17.png,,search: get the path of a directory python;,,
60,2,"https://data-flair.training/blogs/python-directory/#:~:text=To%20find%20out%20which%20directory,use%20the%20getcwd()%20method.&text=Cwd%20is%20for%20current%20working,use%20the%20method%20getcwdb().",3604,screencapture-n43_2022-10-27-21_03_24.png,,visit: Python Directory & File Management - A Quick and Easy Tutorial - DataFlair;,,
61,2,,3659,,,code: main.py;,"# from PIL import Image
  
# im = Image.open(r""C:\Users\thien\Desktop\project\dat\Garbage classification\Garbage classification\glass\glass11.jpg"")
# im.show() 

import os
dir = os.path.dirname(__file__)
print(dir)
garbage_classification_folder = os.path.join(dir, '/dat/Garbage classification/Garbage classification')

print(garbage_classification_folder, ' is a valid directory: ', os.path.isdir(garbage_classification_folder))",
62,2,,3659,,,output: output.txt;,"c:/Users/thien/Desktop/project/venv/Scripts/python.exe c:/Users/thien/Desktop/project/main.py
c:/Users/thien/Desktop/project
c:/dat/Garbage classification/Garbage classification  is a valid directory:  False
(venv)",
63,2,,3789,,,code: main.py;,"# from PIL import Image
  
# im = Image.open(r""C:\Users\thien\Desktop\project\dat\Garbage classification\Garbage classification\glass\glass11.jpg"")
# im.show() 

import os
garbage_classification_folder = r""C:\Users\thien\Desktop\project\dat\Garbage classification\Garbage classification""

print(garbage_classification_folder, ' is a valid directory: ', os.path.isdir(garbage_classification_folder))",
64,2,,3789,,,output: output.txt;,"c:/Users/thien/Desktop/project/venv/Scripts/python.exe c:/Users/thien/Desktop/project/main.py
C:\Users\thien\Desktop\project\dat\Garbage classification\Garbage classification  is a valid directory:  True
(venv)",
65,2,https://www.google.com/search?q=pytorch+how+to+create+a+dataset&rlz=1C1SQJL_enUS958US958&oq=pytorch+how+to+create+a+&aqs=chrome.2.0i512j69i57j0i20i263i512j0i22i30l7.7927j0j4&sourceid=chrome&ie=UTF-8,3829,screencapture-n44_2022-10-27-21_07_09.png,,search: pytorch how to create a dataset;,,
66,2,https://stanford.edu/~shervine/blog/pytorch-how-to-generate-data-parallel,3836,screencapture-n45_2022-10-27-21_07_16.png,,visit: A detailed example of data loaders with PyTorch;,,
67,2,https://pytorch.org/tutorials/beginner/data_loading_tutorial.html,3868,screencapture-n46_2022-10-27-21_07_48.png,,"visit: Writing Custom Datasets, DataLoaders and Transforms â€” PyTorch Tutorials 1.13.0+cu117 documentation;",,
68,2,https://pytorch-geometric.readthedocs.io/en/latest/notes/create_dataset.html,4041,screencapture-n47_2022-10-27-21_10_41.png,,visit: Creating Your Own Datasets â€” pytorch_geometric  documentation;,,
69,2,https://towardsdatascience.com/how-to-use-datasets-and-dataloader-in-pytorch-for-custom-text-data-270eed7f7c00,4072,screencapture-n48_2022-10-27-21_11_12.png,,visit: How to use Datasets and DataLoader in PyTorch for custom text data | by Wherll | Towards Data Science;,,
70,2,https://www.google.com/search?q=pytorch+how+to+create+a+custom+dataset+for+image+classification&rlz=1C1SQJL_enUS958US958&sxsrf=ALiCzsavPjdoHV9WLsxNS-Up_IcjFbqC0w%3A1666922828613&ei=TDlbY7iBJZ-aptQPl-Kf6AY&oq=pytorch+how+to+create+a+custom+dataset+for+im&gs_lp=Egdnd3Mtd2l6uAED-AEBGgIYAyoCCAAyCBAhGKABGIsDMggQIRigARiLAzIFECEYoAEyCBAhGKABGIsDMggQIRirAhiLAzIIECEYqwIYiwMyCxAhGBYYHhgdGIsDMgsQIRgWGB4YHRiLA8ICChAAGEcY1gQYsAPCAgQQIxgnwgIFEAAYhgPCAgYQABgWGB7CAgUQABiABMICBRAhGKsCwgIIECEYFhgeGB2QBghIh0pQpg1Y8ztwA3gByAEAkAEAmAGMAaABwRiqAQUxMi4xOOIDBCBNGAHiAwQgQRgA4gMEIEYYAIgGAQ&sclient=gws-wiz,4129,screencapture-n49_2022-10-27-21_12_09.png,,search: pytorch how to create a custom dataset for image classification;,,
71,2,https://www.learnpytorch.io/04_pytorch_custom_datasets/,4144,screencapture-n50_2022-10-27-21_12_24.png,,visit: 04. PyTorch Custom Datasets - Zero to Mastery Learn PyTorch for Deep Learning;,,
72,2,,4496,,,code: main.py;,"# from PIL import Image
  
# im = Image.open(r""C:\Users\thien\Desktop\project\dat\Garbage classification\Garbage classification\glass\glass11.jpg"")
# im.show() 

import os
garbage_classification_folder = r""C:\Users\thien\Desktop\project\dat\Garbage classification\Garbage classification""

from pathlib import Path

# Setup path to data folder
data_path = Path(garbage_classification_folder)
image_path = data_path / ""cardboard""

if image_path.is_dir():
    print(f""{image_path} directory exists."")",
73,2,,4496,,,output: output.txt;,"c:/Users/thien/Desktop/project/venv/Scripts/python.exe c:/Users/thien/Desktop/project/main.py
C:\Users\thien\Desktop\project\dat\Garbage classification\Garbage classification\cardboard directory exists.
(venv)",
74,2,,4586,,,code: main.py;,"# from PIL import Image
  
# im = Image.open(r""C:\Users\thien\Desktop\project\dat\Garbage classification\Garbage classification\glass\glass11.jpg"")
# im.show() 

import os
garbage_classification_folder = r""C:\Users\thien\Desktop\project\dat\Garbage classification\Garbage classification""

from pathlib import Path

# Setup path to data folder
data_path = Path(garbage_classification_folder)
image_path = data_path / ""cardboard""

def walk_through_dir(dir_path):
    for dirpath, dirnames, filenames in os.walk(dir_path):
        print(f""There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'."")

walk_through_dir(image_path)",
75,2,,4586,,,output: output.txt;,"c:/Users/thien/Desktop/project/venv/Scripts/python.exe c:/Users/thien/Desktop/project/main.py
There are 0 directories and 403 images in 'C:\Users\thien\Desktop\project\dat\Garbage classification\Garbage classification\cardboard'.
(venv)",
76,2,https://www.google.com/search?q=python+random+integer&rlz=1C1SQJL_enUS958US958&oq=python+random+&aqs=chrome.3.69i57j0i131i433i512l3j0i512j0i131i433i512l5.188945j0j7&sourceid=chrome&ie=UTF-8,4831,screencapture-n51_2022-10-27-21_23_51.png,,search: python random integer;,,
77,2,https://www.w3schools.com/python/ref_random_randint.asp,4833,screencapture-n52_2022-10-27-21_23_53.png,,visit: Python Random randint() Method;,,
78,2,https://www.google.com/search?q=how+to+pick+a+random+pictures+from+a+directory+python&rlz=1C1SQJL_enUS958US958&oq=how+to+pick+a+random+pictures+from+a+dire&aqs=chrome.1.69i57j33i160l2.12514j1j7&sourceid=chrome&ie=UTF-8,4859,screencapture-n53_2022-10-27-21_24_19.png,,search: how to pick a random pictures from a directory python;,,
79,2,https://stackoverflow.com/questions/65187875/how-do-i-get-a-random-image-from-a-folder-python,4865,screencapture-n54_2022-10-27-21_24_25.png,,visit: discord.py - How do i get a random image from a folder python - Stack Overflow;,,
80,2,https://www.learnpytorch.io/04_pytorch_custom_datasets/,4921,screencapture-n55_2022-10-27-21_25_21.png,,revisit: 04. PyTorch Custom Datasets - Zero to Mastery Learn PyTorch for Deep Learning;,,
81,2,,5304,,,code: main.py;,"# from PIL import Image
  
# im = Image.open(r""C:\Users\thien\Desktop\project\dat\Garbage classification\Garbage classification\glass\glass11.jpg"")
# im.show() 

import os
garbage_classification_folder = r""C:\Users\thien\Desktop\project\dat\Garbage classification\Garbage classification""

from pathlib import Path

# Setup path to data folder
data_path = Path(garbage_classification_folder)
image_path = data_path / ""cardboard""

def walk_through_dir(dir_path):
    for dirpath, dirnames, filenames in os.walk(dir_path):
        print(f""There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'."")

import random
from PIL import Image

def get_a_random_img(dir_path):
    # Set seed
    random.seed(42)

    # 1. Get all image paths (* means ""any combination"")
    image_path_list = list(dir_path.glob(""*/*/*.jpg""))

    # 2. Get random image path
    random_image_path = random.choice(image_path_list)

    # 3. Get image class from path name (the image class is the name of the directory where the image is stored)
    image_class = random_image_path.parent.stem

    # 4. Open image
    img = Image.open(random_image_path)

    # 5. Print metadata
    print(f""Random image path: {random_image_path}"")
    print(f""Image class: {image_class}"")
    print(f""Image height: {img.height}"") 
    print(f""Image width: {img.width}"")

get_a_random_img(image_path)
",
82,2,,5304,,,output: output.txt;,"c:/Users/thien/Desktop/project/venv/Scripts/python.exe c:/Users/thien/Desktop/project/main.py
Traceback (most recent call last):
  File ""c:/Users/thien/Desktop/project/main.py"", line 44, in <module>
    get_a_random_img(image_path)
  File ""c:/Users/thien/Desktop/project/main.py"", line 30, in get_a_random_img
    random_image_path = random.choice(image_path_list)
  File ""C:\Python38\lib\random.py"", line 290, in choice
    raise IndexError('Cannot choose from an empty sequence') from None
IndexError: Cannot choose from an empty sequence
(venv)",
83,2,https://stackoverflow.com/questions/65187875/how-do-i-get-a-random-image-from-a-folder-python,5354,screencapture-n56_2022-10-27-21_32_34.png,,revisit: discord.py - How do i get a random image from a folder python - Stack Overflow;,,
84,2,,5409,,,code: main.py;,"# from PIL import Image
  
# im = Image.open(r""C:\Users\thien\Desktop\project\dat\Garbage classification\Garbage classification\glass\glass11.jpg"")
# im.show() 

import os
garbage_classification_folder = r""C:\Users\thien\Desktop\project\dat\Garbage classification\Garbage classification""

from pathlib import Path

# Setup path to data folder
data_path = Path(garbage_classification_folder)
image_path = data_path / ""cardboard""

def walk_through_dir(dir_path):
    for dirpath, dirnames, filenames in os.walk(dir_path):
        print(f""There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'."")

import random
from PIL import Image

def get_a_random_img(dir_path):
    # Set seed
    random.seed(42)

    # 1. Get all image paths (* means ""any combination"")
    image_path_list = list(dir_path.glob(""*.jpg""))

    # 2. Get random image path
    random_image_path = random.choice(image_path_list)

    # 3. Get image class from path name (the image class is the name of the directory where the image is stored)
    image_class = random_image_path.parent.stem

    # 4. Open image
    img = Image.open(random_image_path)

    # 5. Print metadata
    print(f""Random image path: {random_image_path}"")
    print(f""Image class: {image_class}"")
    print(f""Image height: {img.height}"") 
    print(f""Image width: {img.width}"")

get_a_random_img(image_path)
",
85,2,,5409,,,output: output.txt;,"c:/Users/thien/Desktop/project/venv/Scripts/python.exe c:/Users/thien/Desktop/project/main.py
Random image path: C:\Users\thien\Desktop\project\dat\Garbage classification\Garbage classification\cardboard\cardboard394.jpg
Image class: cardboard
Image height: 384
Image width: 512
(venv)",
86,2,https://stackoverflow.com/questions/14574705/accessing-directories-and-files-using-python,5630,screencapture-n57_2022-10-27-21_37_10.png,,revisit: Accessing directories and files using python - Stack Overflow;,,
87,2,https://www.google.com/search?q=check+if+a+directory+exists+python&rlz=1C1SQJL_enUS958US958&oq=check+if+a+di&aqs=chrome.1.69i57j0i20i263i512l2j0i512l4j69i60.5872j0j7&sourceid=chrome&ie=UTF-8,5647,screencapture-n58_2022-10-27-21_37_27.png,,search: check if a directory exists python;,,
88,2,https://www.geeksforgeeks.org/python-check-if-a-file-or-directory-exists-2/,5648,screencapture-n59_2022-10-27-21_37_28.png,,visit: Python: Check if a File or Directory Exists - GeeksforGeeks;,,
89,2,https://www.learnpytorch.io/04_pytorch_custom_datasets/,5742,screencapture-n60_2022-10-27-21_39_02.png,,revisit: 04. PyTorch Custom Datasets - Zero to Mastery Learn PyTorch for Deep Learning;,,
90,2,https://www.google.com/search?q=clean+out+all+files+and+folders+in+directory+python&rlz=1C1SQJL_enUS958US958&oq=clean+out+all+files+and+&aqs=chrome.3.69i57j33i160i395l3j33i299l3.9986j1j7&sourceid=chrome&ie=UTF-8,5794,screencapture-n61_2022-10-27-21_39_54.png,,search: clean out all files and folders in directory python;,,
91,2,https://stackoverflow.com/questions/185936/how-to-delete-the-contents-of-a-folder,5797,screencapture-n62_2022-10-27-21_39_57.png,,visit: python - How to delete the contents of a folder? - Stack Overflow;,,
92,2,https://www.google.com/search?q=generate+a+random+list+of+numbers+python&rlz=1C1SQJL_enUS958US958&oq=generate+a+random+list+of+&aqs=chrome.0.0i20i263i512j69i57j0i512l3j0i22i30l5.13508j0j7&sourceid=chrome&ie=UTF-8,6265,screencapture-n63_2022-10-27-21_47_45.png,,search: generate a random list of numbers python;,,
93,2,https://www.geeksforgeeks.org/generating-random-number-list-in-python/,6268,screencapture-n64_2022-10-27-21_47_48.png,,visit: Generating random number list in Python - GeeksforGeeks;,,
94,2,https://www.geeksforgeeks.org/python-check-if-a-file-or-directory-exists-2/,6380,screencapture-n65_2022-10-27-21_49_40.png,,revisit: Python: Check if a File or Directory Exists - GeeksforGeeks;,,
95,2,https://stackoverflow.com/questions/65187875/how-do-i-get-a-random-image-from-a-folder-python,6386,screencapture-n66_2022-10-27-21_49_46.png,,revisit: discord.py - How do i get a random image from a folder python - Stack Overflow;,,
96,2,https://www.geeksforgeeks.org/generating-random-number-list-in-python/,6398,screencapture-n67_2022-10-27-21_49_58.png,,revisit: Generating random number list in Python - GeeksforGeeks;,,
97,2,,6657,,,code: main.py;,"# from PIL import Image
  
# im = Image.open(r""C:\Users\thien\Desktop\project\dat\Garbage classification\Garbage classification\glass\glass11.jpg"")
# im.show() 

import os
garbage_classification_folder = r""C:\Users\thien\Desktop\project\dat\Garbage classification\Garbage classification""

from pathlib import Path

# Setup path to data folder
data_path = Path(garbage_classification_folder)
image_path = data_path / ""cardboard""

def walk_through_dir(dir_path):
    for dirpath, dirnames, filenames in os.walk(dir_path):
        print(f""There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'."")

import random
from PIL import Image

def get_a_random_img(dir_path):
    # Set seed
    random.seed(42)

    # 1. Get all image paths (* means ""any combination"")
    image_path_list = list(dir_path.glob(""*.jpg""))

    # 2. Get random image path
    random_image_path = random.choice(image_path_list)

    # 3. Get image class from path name (the image class is the name of the directory where the image is stored)
    image_class = random_image_path.parent.stem

    # 4. Open image
    img = Image.open(random_image_path)

    # 5. Print metadata
    print(f""Random image path: {random_image_path}"")
    print(f""Image class: {image_class}"")
    print(f""Image height: {img.height}"") 
    print(f""Image width: {img.width}"")

def make_train_test_folder(dir_path):
    import shutil
    train_folder = dir_path / ""train""
    test_folder = dir_path / ""test""
    if os.path.exists(train_folder):
        shutil.rmtree(train_folder)
    else:
        # we need to select random images from all img folders and build up our train set
        collection = [""cardboard"", ""glass"", ""metal"", ""paper"", ""plastic"", ""trash""]
        for el in collection:
            el_path = dir_path / el
            walk_through_dir(el_path)

make_train_test_folder(data_path)
",
98,2,,6657,,,output: output.txt;,"c:/Users/thien/Desktop/project/venv/Scripts/python.exe c:/Users/thien/Desktop/project/main.py
There are 0 directories and 403 images in 'C:\Users\thien\Desktop\project\dat\Garbage classification\Garbage classification\cardboard'.
There are 0 directories and 501 images in 'C:\Users\thien\Desktop\project\dat\Garbage classification\Garbage classification\glass'.
There are 0 directories and 410 images in 'C:\Users\thien\Desktop\project\dat\Garbage classification\Garbage classification\metal'.
There are 0 directories and 594 images in 'C:\Users\thien\Desktop\project\dat\Garbage classification\Garbage classification\paper'.
There are 0 directories and 482 images in 'C:\Users\thien\Desktop\project\dat\Garbage classification\Garbage classification\plastic'.
There are 0 directories and 137 images in 'C:\Users\thien\Desktop\project\dat\Garbage classification\Garbage classification\trash'.
(venv)",
99,2,https://www.google.com/search?q=how+to+use+random+choice+for+a+list&rlz=1C1SQJL_enUS958US958&oq=how+to+use+random+choice+for+a+list&aqs=chrome..69i57j33i160i395l2j33i160j33i22i29i30.9348j1j7&sourceid=chrome&ie=UTF-8,6954,screencapture-n68_2022-10-27-21_59_14.png,,search: how to use random choice for a list;,,
100,2,https://www.google.com/search?q=how+to+use+random+to+select+some+percentage+for+a+list&rlz=1C1SQJL_enUS958US958&sxsrf=ALiCzsaJPMs2GB-nPFmRBt-5uPb9gq8VOA%3A1666925953536&ei=gUVbY8KkIPe2ptQPxrSZ-A8&oq=how+to+use+random+to+select+some+per&gs_lp=Egdnd3Mtd2l6uAED-AEBGgIYAyoCCAEyBRAhGKABMggQIRigARiLAzIIECEYoAEYiwMyCBAhGKABGIsDwgIKEAAYRxjWBBiwA8ICBxAAGIAEGArCAgUQABiABMICBhAAGBYYHsICCBAAGBYYHhgPwgIIECEYqwIYiwPCAgsQIRgWGB4YHRiLA8ICBRAAGIYDwgIFECEYqwLCAggQIRgWGB4YHcICChAhGBYYHhgPGB2QBghIxyxQugVY9h9wAXgByAEAkAEAmAF3oAGIDqoBAzkuOeIDBCBNGAHiAwQgQRgA4gMEIEYYAIgGAQ&sclient=gws-wiz,6978,screencapture-n69_2022-10-27-21_59_38.png,,search: how to use random to select some percentage for a list;,,
101,2,https://stackabuse.com/how-to-randomly-select-elements-from-a-list-in-python/,6980,screencapture-n70_2022-10-27-21_59_40.png,,visit: How to Randomly Select Elements From a List in Python;,,
102,2,https://www.google.com/search?q=selecting+random+elements+from+list+python+without+repetition&rlz=1C1SQJL_enUS958US958&oq=select+random+elements+from+list+with+no+&aqs=chrome.1.69i57j0i22i30l2j0i390l4.15336j1j7&sourceid=chrome&ie=UTF-8,7247,screencapture-n71_2022-10-27-22_04_07.png,,search: selecting random elements from list python without repetition;,,
103,2,https://stackoverflow.com/questions/30735892/random-without-repetition,7249,screencapture-n72_2022-10-27-22_04_09.png,,visit: python - Random without repetition? - Stack Overflow;,,
104,2,https://www.geeksforgeeks.org/randomly-select-elements-from-list-without-repetition-in-python/,7299,screencapture-n73_2022-10-27-22_04_59.png,,visit: Randomly select elements from list without repetition in Python - GeeksforGeeks;,,
105,2,https://stackabuse.com/how-to-randomly-select-elements-from-a-list-in-python/,7367,screencapture-n74_2022-10-27-22_06_07.png,,revisit: How to Randomly Select Elements From a List in Python;,,
106,2,,7548,,,code: main.py;,"# from PIL import Image
  
# im = Image.open(r""C:\Users\thien\Desktop\project\dat\Garbage classification\Garbage classification\glass\glass11.jpg"")
# im.show() 

import os
garbage_classification_folder = r""C:\Users\thien\Desktop\project\dat\Garbage classification\Garbage classification""

from pathlib import Path

# Setup path to data folder
data_path = Path(garbage_classification_folder)
image_path = data_path / ""cardboard""

def walk_through_dir(dir_path):
    for dirpath, dirnames, filenames in os.walk(dir_path):
        print(f""There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'."")

import random
from PIL import Image

def get_a_random__img(dir_path):
    # Set seed
    random.seed(42)

    # 1. Get all image paths (* means ""any combination"")
    image_path_list = list(dir_path.glob(""*.jpg""))

    # 2. Get random image path
    random_image_path = random.choice(image_path_list)

    # 3. Get image class from path name (the image class is the name of the directory where the image is stored)
    image_class = random_image_path.parent.stem

    # 4. Open image
    img = Image.open(random_image_path)

    # 5. Print metadata
    print(f""Random image path: {random_image_path}"")
    print(f""Image class: {image_class}"")
    print(f""Image height: {img.height}"") 
    print(f""Image width: {img.width}"")

def make_train_test_folder(dir_path):
    import shutil
    train_folder = dir_path / ""train""
    test_folder = dir_path / ""test""
    if os.path.exists(train_folder):
        shutil.rmtree(train_folder)
    else:
        # we need to select random images from all img folders and build up our train set
        collection = [""cardboard"", ""glass"", ""metal"", ""paper"", ""plastic"", ""trash""]
        for el in collection:
            el_path = dir_path / el
            random.seed(42)
            img_path_list = list(el_path.glob(""*.jpg""))
            print(img_path_list[:5])

make_train_test_folder(data_path)
",
107,2,,7548,,,output: output.txt;,"c:/Users/thien/Desktop/project/venv/Scripts/python.exe c:/Users/thien/Desktop/project/main.py
[WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard1.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard10
jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard100.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/car
board101.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard102.jpg')]
[WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/glass/glass1.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/glass/glass10.jpg'), WindowsP
th('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/glass/glass100.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/glass/glass101.jpg'), WindowsPath('C:
Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/glass/glass102.jpg')]
[WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/metal/metal1.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/metal/metal10.jpg'), WindowsP
th('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/metal/metal100.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/metal/metal101.jpg'), WindowsPath('C:
Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/metal/metal102.jpg')]
[WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/paper/paper1.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/paper/paper10.jpg'), WindowsP
th('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/paper/paper100.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/paper/paper101.jpg'), WindowsPath('C:
Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/paper/paper102.jpg')]
[WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/plastic/plastic1.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/plastic/plastic10.jpg'), 
indowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/plastic/plastic100.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/plastic/plastic101.jpg'),
WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/plastic/plastic102.jpg')]
[WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/trash/trash1.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/trash/trash10.jpg'), WindowsP
th('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/trash/trash100.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/trash/trash101.jpg'), WindowsPath('C:
Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/trash/trash102.jpg')]
(venv)",
108,2,https://www.geeksforgeeks.org/randomly-select-elements-from-list-without-repetition-in-python/,7719,screencapture-n75_2022-10-27-22_11_59.png,,revisit: Randomly select elements from list without repetition in Python - GeeksforGeeks;,,
109,2,https://www.google.com/search?q=flatten+array+python&rlz=1C1SQJL_enUS958US958&oq=flatten+array&aqs=chrome.1.69i57j0i20i131i263i433i512j0i131i433i512j0i512l7.3496j0j7&sourceid=chrome&ie=UTF-8,7733,screencapture-n76_2022-10-27-22_12_13.png,,search: flatten array python;,,
110,2,https://stackoverflow.com/questions/952914/how-do-i-make-a-flat-list-out-of-a-list-of-lists,7740,screencapture-n77_2022-10-27-22_12_20.png,,visit: python - How do I make a flat list out of a list of lists? - Stack Overflow;,,
111,2,https://stackabuse.com/how-to-randomly-select-elements-from-a-list-in-python/,7769,screencapture-n78_2022-10-27-22_12_49.png,,revisit: How to Randomly Select Elements From a List in Python;,,
112,2,,8198,,,code: main.py;,"# from PIL import Image
  
# im = Image.open(r""C:\Users\thien\Desktop\project\dat\Garbage classification\Garbage classification\glass\glass11.jpg"")
# im.show() 

import os
garbage_classification_folder = r""C:\Users\thien\Desktop\project\dat\Garbage classification\Garbage classification""

from pathlib import Path

# Setup path to data folder
data_path = Path(garbage_classification_folder)
image_path = data_path / ""cardboard""

def walk_through_dir(dir_path):
    for dirpath, dirnames, filenames in os.walk(dir_path):
        print(f""There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'."")

import random
from PIL import Image

# pass in the img dir path (eg. ./cardboard)
def get_random_img_list(dir_path, N):
    # Set seed
    random.seed(42)

    # 1. Get all image paths (* means ""any combination"")
    image_path_list = list(dir_path.glob(""*.jpg""))

    # converting the list into a set
    image_path_set = set(image_path_list)

    # 2. Get random image path
    updated_rand_image_list = random.choices(list(image_path_set), k = N)

    return updated_rand_image_list

def make_train_test_folder(dir_path):
    import shutil
    train_folder = dir_path / ""train""
    test_folder = dir_path / ""test""
    if os.path.exists(train_folder):
        shutil.rmtree(train_folder)
    else:
        # we need to select random images from all img folders and build up our train set
        collection = [""cardboard"", ""glass"", ""metal"", ""paper"", ""plastic"", ""trash""]
        for el in collection:
            el_path = dir_path / el
            rand_img_list = get_random_img_list(el_path, 5)
            print(rand_img_list)

make_train_test_folder(data_path)
",
113,2,,8198,,,output: output.txt;,"c:/Users/thien/Desktop/project/venv/Scripts/python.exe c:/Users/thien/Desktop/project/main.py
[WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard306.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard
44.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard127.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/
ardboard369.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard124.jpg')]
[WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/glass/glass247.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/glass/glass499.jpg'), Windo
sPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/glass/glass426.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/glass/glass261.jpg'), WindowsPath(
C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/glass/glass179.jpg')]
[WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/metal/metal303.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/metal/metal271.jpg'), Windo
sPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/metal/metal339.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/metal/metal30.jpg'), WindowsPath('
:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/metal/metal279.jpg')]
[WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/paper/paper348.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/paper/paper306.jpg'), Windo
sPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/paper/paper113.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/paper/paper302.jpg'), WindowsPath(
C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/paper/paper529.jpg')]
[WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/plastic/plastic399.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/plastic/plastic168.jpg'
, WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/plastic/plastic260.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/plastic/plastic439.jpg
), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/plastic/plastic28.jpg')]
[WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/trash/trash71.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/trash/trash107.jpg'), Window
Path('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/trash/trash21.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/trash/trash3.jpg'), WindowsPath('C:/
sers/thien/Desktop/project/dat/Garbage classification/Garbage classification/trash/trash1.jpg')]
(venv)",
114,2,https://www.google.com/search?q=grab+80+elements+from+array+python&rlz=1C1SQJL_enUS958US958&oq=grab+80%25+elem&aqs=chrome.2.69i57j33i160i395l3.12815j1j7&sourceid=chrome&ie=UTF-8,8514,screencapture-n79_2022-10-27-22_25_14.png,,search: grab 80 elements from array python;,,
115,2,https://www.google.com/search?q=grab+80+percent+of+elements+from+array+python&rlz=1C1SQJL_enUS958US958&sxsrf=ALiCzsayFU9ItK7XYqjTROm-mulf_95TVQ%3A1666927513158&ei=mUtbY7mgCZifptQP9uyW2AU&ved=0ahUKEwj50Kby_IH7AhWYj4kEHXa2BVsQ4dUDCBA&uact=5&oq=grab+80+percent+of+elements+from+array+python&gs_lp=Egdnd3Mtd2l6uAED-AEBGgIYAsICChAAGEcY1gQYsAPCAggQABiiBBiLA8ICCxAhGMMEGKABGIsDwgIKECEYwwQYChigAZAGCEiRWlD0Q1j1VXACeAHIAQCQAQCYAW-gAaYIqgEDOC4z4gMEIE0YAeIDBCBBGADiAwQgRhgAiAYB&sclient=gws-wiz,8527,screencapture-n80_2022-10-27-22_25_27.png,,search: grab 80 percent of elements from array python;,,
116,2,https://stackoverflow.com/questions/13423759/percent-list-slicing,8530,screencapture-n81_2022-10-27-22_25_30.png,,visit: python - Percent list slicing - Stack Overflow;,,
117,2,https://www.geeksforgeeks.org/numpy-percentile-in-python/,8592,screencapture-n82_2022-10-27-22_26_32.png,,visit: numpy.percentile() in python - GeeksforGeeks;,,
118,2,https://www.google.com/search?q=round+python&rlz=1C1SQJL_enUS958US958&sxsrf=ALiCzsbh8841Yx0TdkFnqYyF31ZqfHRhaw%3A1666927527139&ei=p0tbY--HCOiiptQP6uCQ6Aw&ved=0ahUKEwiv9_v4_IH7AhVokYkEHWowBM0Q4dUDCBA&uact=5&oq=round+python&gs_lp=Egdnd3Mtd2l6uAED-AEBMgsQABixAxiDARiRAjIFEAAYgAQyBRAAGIAEMgUQABiABDIFEAAYgAQyBRAAGIAEMgUQABiABDIFEAAYgAQyBRAAGIAEMgUQABiABMICBBAjGCfCAgUQABiRAsICCxAuGIAEGLEDGIMBwgIIEC4YsQMYgwHCAhEQLhiABBixAxiDARjHARjRA8ICCxAuGIAEGLEDGNQCwgIEEAAYQ8ICCxAAGIAEGLEDGIMBwgIOEC4YgAQYsQMYxwEY0QPCAgoQABixAxiDARhDwgIHEAAYsQMYQ8ICCxAuGLEDGMcBGNEDwgIIEAAYgAQYsQPCAgkQABjJAxgKGEPCAggQLhiABBixA8ICDhAuGLEDGIMBGMcBGK8BwgIKEAAYgAQYhwIYFEiCSFAAWJwlcAB4AcgBAJABAJgBcqAB9wiqAQM2LjbiAwQgTRgB4gMEIEEYAOIDBCBGGACIBgE&sclient=gws-wiz,8616,screencapture-n83_2022-10-27-22_26_56.png,,search: round python;,,
119,2,https://www.w3schools.com/python/ref_func_round.asp,8617,screencapture-n84_2022-10-27-22_26_57.png,,visit: Python round() Function;,,
120,2,https://www.google.com/search?q=find+the+difference+elements+between+two+lists+python&rlz=1C1SQJL_enUS958US958&oq=find+the+different+elements+between+&aqs=chrome.1.69i57j0i10i512j0i10i22i30j0i22i30j0i390l4.8588j0j9&sourceid=chrome&ie=UTF-8,8793,screencapture-n85_2022-10-27-22_29_53.png,,search: find the difference elements between two lists python;,,
121,2,"https://www.codingem.com/difference-between-two-python-lists/#:~:text=To%20get%20the%20symmetric%20difference,result%20back%20to%20a%20list.",8795,screencapture-n86_2022-10-27-22_29_55.png,,visit: Python How to Find the Difference Between Two Lists - codingem.com;,,
122,2,https://stackoverflow.com/questions/3462143/get-difference-between-two-lists,8817,screencapture-n87_2022-10-27-22_30_17.png,,visit: python - Get difference between two lists - Stack Overflow;,,
123,2,,9164,,,code: main.py;,"# from PIL import Image
  
# im = Image.open(r""C:\Users\thien\Desktop\project\dat\Garbage classification\Garbage classification\glass\glass11.jpg"")
# im.show() 

import math
import os
garbage_classification_folder = r""C:\Users\thien\Desktop\project\dat\Garbage classification\Garbage classification""

from pathlib import Path

# Setup path to data folder
data_path = Path(garbage_classification_folder)
image_path = data_path / ""cardboard""

def walk_through_dir(dir_path):
    no_of_files = 0
    for dirpath, dirnames, filenames in os.walk(dir_path):
        # print(f""There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'."")
        no_of_files = len(filenames)
    return no_of_files

import random
from PIL import Image

# pass in the img dir path (eg. ./cardboard)
def get_random_img_list(dir_path, N):
    # Set seed
    random.seed(42)

    # 1. Get all image paths (* means ""any combination"")
    image_path_list = list(dir_path.glob(""*.jpg""))

    # converting the list into a set
    image_path_set = set(image_path_list)

    # 2. Get random image path
    image_list_train = random.choices(list(image_path_set), k = N)

    image_list_test = list(set(image_path_list) - set(image_list_train))

    return image_list_train, image_list_test

def make_train_test_folder(dir_path):
    import shutil
    train_folder = dir_path / ""train""
    test_folder = dir_path / ""test""
    if os.path.exists(train_folder):
        shutil.rmtree(train_folder)
    else:
        # we need to select random images from all img folders and build up our train set
        collection = [""cardboard"", ""glass"", ""metal"", ""paper"", ""plastic"", ""trash""]
        for el in collection:
            el_path = dir_path / el
            no_of_imgs = walk_through_dir(el_path)

            # grab 80% of imgs for training
            training_amount = math.floor(0.8 * no_of_imgs)
            training_dat, testing_dat = get_random_img_list(el_path, training_amount)

            print('5 elements from training data', training_dat[:5])
            print('5 elements from testing data', testing_dat[:5])
            print('length of train data:', len(training_dat))
            print('length of test data:', len(testing_dat))
            

make_train_test_folder(data_path)
",
124,2,,9164,,,output: output.txt;,"c:/Users/thien/Desktop/project/venv/Scripts/python.exe c:/Users/thien/Desktop/project/main.py
5 elements from training data [WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard287.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage clas
ification/cardboard/cardboard308.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard383.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Gar
age classification/cardboard/cardboard124.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard230.jpg')]
5 elements from testing data [WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard375.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage class
fication/cardboard/cardboard107.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard278.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garb
ge classification/cardboard/cardboard92.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard327.jpg')]
length of train data: 322
length of test data: 184
5 elements from training data [WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/glass/glass389.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classificati
n/glass/glass19.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/glass/glass473.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/glass
glass99.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/glass/glass264.jpg')]
5 elements from testing data [WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/glass/glass267.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classificatio
/glass/glass499.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/glass/glass247.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/glass
glass431.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/glass/glass30.jpg')]
length of train data: 400
length of test data: 234
5 elements from training data [WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/metal/metal184.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classificati
n/metal/metal310.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/metal/metal178.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/meta
/metal81.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/metal/metal313.jpg')]
5 elements from testing data [WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/metal/metal161.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classificatio
/metal/metal64.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/metal/metal358.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/metal/
etal388.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/metal/metal120.jpg')]
length of train data: 328
length of test data: 194
5 elements from training data [WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/paper/paper204.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classificati
n/paper/paper15.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/paper/paper257.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/paper
paper409.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/paper/paper419.jpg')]
5 elements from testing data [WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/paper/paper127.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classificatio
/paper/paper237.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/paper/paper510.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/paper
paper164.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/paper/paper228.jpg')]
length of train data: 475
length of test data: 278
5 elements from training data [WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/plastic/plastic27.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classific
tion/plastic/plastic46.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/plastic/plastic246.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classific
tion/plastic/plastic173.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/plastic/plastic70.jpg')]
5 elements from testing data [WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/plastic/plastic223.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classific
tion/plastic/plastic256.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/plastic/plastic96.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classific
tion/plastic/plastic114.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/plastic/plastic433.jpg')]
length of train data: 385
length of test data: 226
5 elements from training data [WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/trash/trash93.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classificatio
/trash/trash37.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/trash/trash54.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/trash/t
ash86.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/trash/trash87.jpg')]
5 elements from testing data [WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/trash/trash120.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classificatio
/trash/trash115.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/trash/trash30.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/trash/
rash128.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/trash/trash4.jpg')]
length of train data: 109
length of test data: 62
(venv)",
125,2,,9530,,,code: main.py;,"# from PIL import Image
  
# im = Image.open(r""C:\Users\thien\Desktop\project\dat\Garbage classification\Garbage classification\glass\glass11.jpg"")
# im.show() 

import math
import os
garbage_classification_folder = r""C:\Users\thien\Desktop\project\dat\Garbage classification\Garbage classification""

from pathlib import Path

# Setup path to data folder
data_path = Path(garbage_classification_folder)
image_path = data_path / ""cardboard""

def walk_through_dir(dir_path):
    no_of_files = 0
    for dirpath, dirnames, filenames in os.walk(dir_path):
        # print(f""There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'."")
        no_of_files = len(filenames)
    return no_of_files

import random
from PIL import Image

# pass in the img dir path (eg. ./cardboard)
def get_random_img_list(dir_path, N):
    # Set seed
    random.seed(42)

    # 1. Get all image paths (* means ""any combination"")
    image_path_list = list(dir_path.glob(""*.jpg""))

    # converting the list into a set
    image_path_set = set(image_path_list)

    # 2. Get random image path
    image_list_train = random.choices(list(image_path_set), k = N)

    image_list_test = list(set(image_path_list) - set(image_list_train))

    return image_list_train, image_list_test

def make_train_test_folder(dir_path):
    import shutil
    train_folder = dir_path / ""train""
    test_folder = dir_path / ""test""
    if os.path.exists(train_folder):
        shutil.rmtree(train_folder)
    else:
        # we need to select random images from all img folders and build up our train set
        collection = [""cardboard"", ""glass"", ""metal"", ""paper"", ""plastic"", ""trash""]
        for el in collection:
            el_path = dir_path / el
            no_of_imgs = walk_through_dir(el_path)

            # grab 80% of imgs for training
            training_amount = math.floor(0.8 * no_of_imgs)
            print('80 percent of', no_of_imgs, 'is', training_amount)
            training_dat, testing_dat = get_random_img_list(el_path, training_amount)

            print('5 elements from training data', training_dat[:5])
            print('5 elements from testing data', testing_dat[:5])
            print('length of train data:', len(training_dat))
            print('length of test data:', len(testing_dat))
            

make_train_test_folder(data_path)
",
126,2,,9530,,,output: output.txt;,"c:/Users/thien/Desktop/project/venv/Scripts/python.exe c:/Users/thien/Desktop/project/main.py
80 percent of 403 is 322
5 elements from training data [WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard189.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage clas
ification/cardboard/cardboard118.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard96.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garb
ge classification/cardboard/cardboard122.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard133.jpg')]
5 elements from testing data [WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard257.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage class
fication/cardboard/cardboard263.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard23.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garba
e classification/cardboard/cardboard179.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard5.jpg')]
length of train data: 322
length of test data: 184
80 percent of 501 is 400
5 elements from training data [WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/glass/glass70.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classificatio
/glass/glass121.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/glass/glass369.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/glass
glass279.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/glass/glass323.jpg')]
5 elements from testing data [WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/glass/glass351.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classificatio
/glass/glass386.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/glass/glass413.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/glass
glass318.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/glass/glass142.jpg')]
length of train data: 400
length of test data: 234
80 percent of 410 is 328
5 elements from training data [WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/metal/metal258.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classificati
n/metal/metal238.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/metal/metal23.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/metal
metal234.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/metal/metal208.jpg')]
5 elements from testing data [WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/metal/metal87.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification
metal/metal198.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/metal/metal191.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/metal/
etal157.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/metal/metal111.jpg')]
length of train data: 328
length of test data: 194
80 percent of 594 is 475
5 elements from training data [WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/paper/paper378.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classificati
n/paper/paper514.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/paper/paper458.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/pape
/paper505.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/paper/paper81.jpg')]
5 elements from testing data [WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/paper/paper297.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classificatio
/paper/paper372.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/paper/paper577.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/paper
paper528.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/paper/paper104.jpg')]
length of train data: 475
length of test data: 278
80 percent of 482 is 385
5 elements from training data [WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/plastic/plastic309.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classifi
ation/plastic/plastic73.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/plastic/plastic165.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classifi
ation/plastic/plastic417.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/plastic/plastic465.jpg')]
5 elements from testing data [WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/plastic/plastic473.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classific
tion/plastic/plastic120.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/plastic/plastic348.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classifi
ation/plastic/plastic305.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/plastic/plastic468.jpg')]
length of train data: 385
length of test data: 226
80 percent of 137 is 109
5 elements from training data [WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/trash/trash99.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classificatio
/trash/trash3.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/trash/trash63.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/trash/tr
sh91.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/trash/trash80.jpg')]
5 elements from testing data [WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/trash/trash55.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification
trash/trash6.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/trash/trash127.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/trash/tr
sh42.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/trash/trash21.jpg')]
length of train data: 109
length of test data: 62
(venv)",
127,2,,9840,,,code: main.py;,"# from PIL import Image
  
# im = Image.open(r""C:\Users\thien\Desktop\project\dat\Garbage classification\Garbage classification\glass\glass11.jpg"")
# im.show() 

import math
import os
garbage_classification_folder = r""C:\Users\thien\Desktop\project\dat\Garbage classification\Garbage classification""

from pathlib import Path

# Setup path to data folder
data_path = Path(garbage_classification_folder)
image_path = data_path / ""cardboard""

def walk_through_dir(dir_path):
    no_of_files = 0
    for dirpath, dirnames, filenames in os.walk(dir_path):
        # print(f""There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'."")
        no_of_files = len(filenames)
    return no_of_files

import random
from PIL import Image

# pass in the img dir path (eg. ./cardboard)
def get_random_img_list(dir_path, N):
    # Set seed
    random.seed(42)

    # 1. Get all image paths (* means ""any combination"")
    image_path_list = list(dir_path.glob(""*.jpg""))

    # converting the list into a set
    image_path_set = set(image_path_list)

    # 2. Get random image path
    image_list_train = random.choices(list(image_path_set), k = N)

    s = set(image_list_train)
    image_list_test = [x for x in image_path_list if x not in s]

    return image_list_train, image_list_test

def make_train_test_folder(dir_path):
    import shutil
    train_folder = dir_path / ""train""
    test_folder = dir_path / ""test""
    if os.path.exists(train_folder):
        shutil.rmtree(train_folder)
    else:
        # we need to select random images from all img folders and build up our train set
        collection = [""cardboard"", ""glass"", ""metal"", ""paper"", ""plastic"", ""trash""]
        for el in collection:
            el_path = dir_path / el
            no_of_imgs = walk_through_dir(el_path)

            # grab 80% of imgs for training
            training_amount = math.floor(0.8 * no_of_imgs)
            print('80 percent of', no_of_imgs, 'is', training_amount)
            training_dat, testing_dat = get_random_img_list(el_path, training_amount)

            # print('5 elements from training data', training_dat[:5])
            # print('5 elements from testing data', testing_dat[:5])
            print('length of train data:', len(training_dat))
            print('length of test data:', len(testing_dat))
            

make_train_test_folder(data_path)
",
128,2,,9840,,,output: output.txt;,"c:/Users/thien/Desktop/project/venv/Scripts/python.exe c:/Users/thien/Desktop/project/main.py
80 percent of 403 is 322
length of train data: 322
length of test data: 184
80 percent of 501 is 400
length of train data: 400
length of test data: 234
80 percent of 410 is 328
length of train data: 328
length of test data: 194
80 percent of 594 is 475
length of train data: 475
length of test data: 278
80 percent of 482 is 385
length of train data: 385
length of test data: 226
80 percent of 137 is 109
length of train data: 109
length of test data: 62
(venv)",
129,2,https://www.google.com/search?q=check+if+all+values+in+list+are+unique+python&rlz=1C1SQJL_enUS958US958&oq=check+if+all+values+in+list+are+uni&aqs=chrome.0.0i512j69i57j0i22i30l6j0i390l2.8353j0j7&sourceid=chrome&ie=UTF-8,9924,screencapture-n88_2022-10-27-22_48_44.png,,search: check if all values in list are unique python;,,
130,2,https://stackoverflow.com/questions/5278122/checking-if-all-elements-in-a-list-are-unique,9926,screencapture-n89_2022-10-27-22_48_46.png,,visit: python - Checking if all elements in a list are unique - Stack Overflow;,,
131,2,,10072,,,code: main.py;,"# from PIL import Image
  
# im = Image.open(r""C:\Users\thien\Desktop\project\dat\Garbage classification\Garbage classification\glass\glass11.jpg"")
# im.show() 

import math
import os
garbage_classification_folder = r""C:\Users\thien\Desktop\project\dat\Garbage classification\Garbage classification""

from pathlib import Path

# Setup path to data folder
data_path = Path(garbage_classification_folder)
image_path = data_path / ""cardboard""

def walk_through_dir(dir_path):
    no_of_files = 0
    for dirpath, dirnames, filenames in os.walk(dir_path):
        # print(f""There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'."")
        no_of_files = len(filenames)
    return no_of_files

import random
from PIL import Image

# pass in the img dir path (eg. ./cardboard)
def get_random_img_list(dir_path, N):
    # Set seed
    random.seed(42)

    # 1. Get all image paths (* means ""any combination"")
    image_path_list = list(dir_path.glob(""*.jpg""))

    # converting the list into a set
    image_path_set = set(image_path_list)

    # 2. Get random image path
    image_list_train = random.choices(list(image_path_set), k = N)

    import numpy as np
    print(np.unique(image_list_train).size == len(image_list_train))

    s = set(image_list_train)
    image_list_test = [x for x in image_path_list if x not in s]

    return image_list_train, image_list_test

def make_train_test_folder(dir_path):
    import shutil
    train_folder = dir_path / ""train""
    test_folder = dir_path / ""test""
    if os.path.exists(train_folder):
        shutil.rmtree(train_folder)
    else:
        # we need to select random images from all img folders and build up our train set
        collection = [""cardboard"", ""glass"", ""metal"", ""paper"", ""plastic"", ""trash""]
        for el in collection:
            el_path = dir_path / el
            no_of_imgs = walk_through_dir(el_path)

            # grab 80% of imgs for training
            training_amount = math.floor(0.8 * no_of_imgs)
            print('80 percent of', no_of_imgs, 'is', training_amount)
            training_dat, testing_dat = get_random_img_list(el_path, training_amount)

            # print('5 elements from training data', training_dat[:5])
            # print('5 elements from testing data', testing_dat[:5])
            print('length of train data:', len(training_dat))
            print('length of test data:', len(testing_dat))
            

make_train_test_folder(data_path)
",
132,2,,10072,,,output: output.txt;,"c:/Users/thien/Desktop/project/venv/Scripts/python.exe c:/Users/thien/Desktop/project/main.py
80 percent of 403 is 322
False
length of train data: 322
length of test data: 184
80 percent of 501 is 400
False
length of train data: 400
length of test data: 234
80 percent of 410 is 328
False
length of train data: 328
length of test data: 194
80 percent of 594 is 475
False
length of train data: 475
length of test data: 278
80 percent of 482 is 385
False
length of train data: 385
length of test data: 226
80 percent of 137 is 109
False
length of train data: 109
length of test data: 62
(venv)",
133,2,,10215,,,code: main.py;,"# from PIL import Image
  
# im = Image.open(r""C:\Users\thien\Desktop\project\dat\Garbage classification\Garbage classification\glass\glass11.jpg"")
# im.show() 

import math
import os
garbage_classification_folder = r""C:\Users\thien\Desktop\project\dat\Garbage classification\Garbage classification""

from pathlib import Path

# Setup path to data folder
data_path = Path(garbage_classification_folder)
image_path = data_path / ""cardboard""

def walk_through_dir(dir_path):
    no_of_files = 0
    for dirpath, dirnames, filenames in os.walk(dir_path):
        # print(f""There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'."")
        no_of_files = len(filenames)
    return no_of_files

import random
from PIL import Image

def allUnique(x):
    seen = list()
    return not any(i in seen or seen.append(i) for i in x)

# pass in the img dir path (eg. ./cardboard)
def get_random_img_list(dir_path, N):
    # Set seed
    random.seed(42)

    # 1. Get all image paths (* means ""any combination"")
    image_path_list = list(dir_path.glob(""*.jpg""))

    # converting the list into a set
    image_path_set = set(image_path_list)

    # 2. Get random image path
    image_list_train = random.choices(list(image_path_set), k = N)

    print(allUnique(image_list_train))

    s = set(image_list_train)
    image_list_test = [x for x in image_path_list if x not in s]

    return image_list_train, image_list_test

def make_train_test_folder(dir_path):
    import shutil
    train_folder = dir_path / ""train""
    test_folder = dir_path / ""test""
    if os.path.exists(train_folder):
        shutil.rmtree(train_folder)
    else:
        # we need to select random images from all img folders and build up our train set
        collection = [""cardboard"", ""glass"", ""metal"", ""paper"", ""plastic"", ""trash""]
        for el in collection:
            el_path = dir_path / el
            no_of_imgs = walk_through_dir(el_path)

            # grab 80% of imgs for training
            training_amount = math.floor(0.8 * no_of_imgs)
            print('80 percent of', no_of_imgs, 'is', training_amount)
            training_dat, testing_dat = get_random_img_list(el_path, training_amount)

            # print('5 elements from training data', training_dat[:5])
            # print('5 elements from testing data', testing_dat[:5])
            print('length of train data:', len(training_dat))
            print('length of test data:', len(testing_dat))
            

make_train_test_folder(data_path)
",
134,2,https://www.geeksforgeeks.org/randomly-select-elements-from-list-without-repetition-in-python/,10228,screencapture-n90_2022-10-27-22_53_48.png,,revisit: Randomly select elements from list without repetition in Python - GeeksforGeeks;,,
135,2,https://www.google.com/search?q=how+to+random+selecting+from+a+list+without+repetition+python&rlz=1C1SQJL_enUS958US958&oq=how+to+randomly+select+from+a+list+without+&aqs=chrome.8.69i57j33i160l2j33i160i395j33i299i395l3j33i22i29i30i395l2.16247j1j7&sourceid=chrome&ie=UTF-8,10268,screencapture-n91_2022-10-27-22_54_28.png,,search: how to random selecting from a list without repetition python;,,
136,2,https://stackoverflow.com/questions/9755538/how-do-i-create-a-list-of-random-numbers-without-duplicates,10284,screencapture-n92_2022-10-27-22_54_44.png,,visit: python - How do I create a list of random numbers without duplicates - Stack Overflow;,,
137,2,https://www.oreilly.com/library/view/python-cookbook/0596001673/ch02s09.html,10315,screencapture-n93_2022-10-27-22_55_15.png,,visit: Selecting Random Elements from a List Without Repetition - Python Cookbook [Book];,,
138,2,https://stackabuse.com/how-to-randomly-select-elements-from-a-list-in-python/,10351,screencapture-n94_2022-10-27-22_55_51.png,,revisit: How to Randomly Select Elements From a List in Python;,,
139,2,https://stackoverflow.com/questions/30735892/random-without-repetition,10405,screencapture-n95_2022-10-27-22_56_45.png,,revisit: python - Random without repetition? - Stack Overflow;,,
140,2,https://www.geeksforgeeks.org/python-random-sample-function/,10437,screencapture-n96_2022-10-27-22_57_17.png,,visit: Python | random.sample() function - GeeksforGeeks;,,
141,2,,10541,,,code: main.py;,"# from PIL import Image
  
# im = Image.open(r""C:\Users\thien\Desktop\project\dat\Garbage classification\Garbage classification\glass\glass11.jpg"")
# im.show() 

import math
import os
garbage_classification_folder = r""C:\Users\thien\Desktop\project\dat\Garbage classification\Garbage classification""

from pathlib import Path

# Setup path to data folder
data_path = Path(garbage_classification_folder)
image_path = data_path / ""cardboard""

def walk_through_dir(dir_path):
    no_of_files = 0
    for dirpath, dirnames, filenames in os.walk(dir_path):
        # print(f""There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'."")
        no_of_files = len(filenames)
    return no_of_files

import random
from PIL import Image

def allUnique(x):
    seen = list()
    return not any(i in seen or seen.append(i) for i in x)

# pass in the img dir path (eg. ./cardboard)
def get_random_img_list(dir_path, N):
    # Set seed
    random.seed(42)

    # 1. Get all image paths (* means ""any combination"")
    image_path_list = list(dir_path.glob(""*.jpg""))

    # converting the list into a set
    # image_path_set = set(image_path_list)

    # 2. Get random image path
    image_list_train = random.sample(image_path_list, k = N)

    print(allUnique(image_list_train))

    s = set(image_list_train)
    image_list_test = [x for x in image_path_list if x not in s]

    return image_list_train, image_list_test

def make_train_test_folder(dir_path):
    import shutil
    train_folder = dir_path / ""train""
    test_folder = dir_path / ""test""
    if os.path.exists(train_folder):
        shutil.rmtree(train_folder)
    else:
        # we need to select random images from all img folders and build up our train set
        collection = [""cardboard"", ""glass"", ""metal"", ""paper"", ""plastic"", ""trash""]
        for el in collection:
            el_path = dir_path / el
            no_of_imgs = walk_through_dir(el_path)

            # grab 80% of imgs for training
            training_amount = math.floor(0.8 * no_of_imgs)
            print('80 percent of', no_of_imgs, 'is', training_amount)
            training_dat, testing_dat = get_random_img_list(el_path, training_amount)

            # print('5 elements from training data', training_dat[:5])
            # print('5 elements from testing data', testing_dat[:5])
            print('length of train data:', len(training_dat))
            print('length of test data:', len(testing_dat))
            

make_train_test_folder(data_path)
",
142,2,,10541,,,output: output.txt;,"c:/Users/thien/Desktop/project/venv/Scripts/python.exe c:/Users/thien/Desktop/project/main.py
80 percent of 403 is 322
True
length of train data: 322
length of test data: 81
80 percent of 501 is 400
True
length of train data: 400
length of test data: 101
80 percent of 410 is 328
True
length of train data: 328
length of test data: 82
80 percent of 594 is 475
True
length of train data: 475
length of test data: 119
80 percent of 482 is 385
True
length of train data: 385
length of test data: 97
80 percent of 137 is 109
True
length of train data: 109
length of test data: 28
(venv)",
143,2,https://www.google.com/search?q=how+to+move+images+from+one+folder+to+another+in+python&rlz=1C1SQJL_enUS958US958&oq=how+to+move+images+from+one+folder+to&aqs=chrome.0.0i512j69i57j0i22i30l8.41989j1j4&sourceid=chrome&ie=UTF-8,10903,screencapture-n97_2022-10-27-23_05_03.png,,search: how to move images from one folder to another in python;,,
144,2,https://www.learndatasci.com/solutions/python-move-file/,10908,screencapture-n98_2022-10-27-23_05_08.png,,visit: How to Move Files in Python: Single and Multiple File Examples â€“ LearnDataSci;,,
145,2,https://www.google.com/search?q=shutil+move+without+deleting&rlz=1C1SQJL_enUS958US958&oq=shutil+move+without+deleting&aqs=chrome..69i57j0i22i30j0i390l4.8245j1j7&sourceid=chrome&ie=UTF-8,10962,screencapture-n99_2022-10-27-23_06_02.png,,search: shutil move without deleting;,,
146,2,https://stackoverflow.com/questions/21786321/shutil-move-doesnt-delete-source-files,10964,screencapture-n100_2022-10-27-23_06_04.png,,visit: python - shutil.move doesn't delete source files - Stack Overflow;,,
147,2,https://www.geeksforgeeks.org/python-shutil-move-method/,10976,screencapture-n101_2022-10-27-23_06_16.png,,visit: Python | shutil.move() method - GeeksforGeeks;,,
148,2,https://www.google.com/search?q=how+to+copy+and+paste+img+in+python&rlz=1C1SQJL_enUS958US958&oq=how+to+copy+and+paste+img+in+python&aqs=chrome..69i57j33i10i160i395j33i10i160j33i10i299j33i10i22i29i30l6.8994j1j9&sourceid=chrome&ie=UTF-8,11022,screencapture-n102_2022-10-27-23_07_02.png,,search: how to copy and paste img in python;,,
149,2,https://www.google.com/search?q=how+to+move+image+in+python+without+deleting+source+files&rlz=1C1SQJL_enUS958US958&sxsrf=ALiCzsbAw1cypBgzEVQ5tISQG1uz5RtCNg%3A1666930021238&ei=ZVVbY8iJDpuyptQP7qKq4AY&oq=how+to+move+img+in+python+without+deleting+source+file&gs_lp=Egdnd3Mtd2l6uAED-AEBGgIYAyoCCAAyBxAhGKABGAoyChAhGKABGAoYiwMyBxAhGAoYqwLCAgoQABhHGNYEGLADwgIGEAAYHhgNwgIIEAAYCBgeGA3CAgcQABiABBgNwgIFEAAYhgPCAgYQABgWGB7CAgoQIRgKGKsCGIsDwgINECEYFhgeGAoYHRiLA8ICChAhGBYYHhgKGB2QBghI7XVQ4QhYimNwBHgByAEAkAEBmAF_oAH1HKoBBTEwLjI14gMEIE0YAeIDBCBBGADiAwQgRhgAiAYB&sclient=gws-wiz,11051,screencapture-n103_2022-10-27-23_07_31.png,,search: how to move image in python without deleting source files;,,
150,2,https://stackoverflow.com/questions/8858008/how-to-move-a-file-in-python,11058,screencapture-n104_2022-10-27-23_07_38.png,,visit: How to move a file in Python? - Stack Overflow;,,
151,2,https://www.geeksforgeeks.org/copy-all-files-from-one-directory-to-another-using-python/,11147,screencapture-n105_2022-10-27-23_09_07.png,,visit: Copy all files from one directory to another using Python - GeeksforGeeks;,,
152,2,https://www.google.com/search?q=shutil+copy2&rlz=1C1SQJL_enUS958US958&oq=shutil+copy2&aqs=chrome..69i57j0i512l8j0i390.2890j0j7&sourceid=chrome&ie=UTF-8,11200,screencapture-n106_2022-10-27-23_10_00.png,,search: shutil copy2;,,
153,2,https://towardsdatascience.com/copy-files-python-ad17998264db,11210,screencapture-n107_2022-10-27-23_10_10.png,,visit: How to Copy Files in Python | Towards Data Science;,,
154,2,https://www.google.com/search?q=how+to+copy+files+in+python&rlz=1C1SQJL_enUS958US958&oq=how+to+copy+files+&aqs=chrome.1.69i57j0i20i263i512j0i512l6.5308j0j7&sourceid=chrome&ie=UTF-8,11309,screencapture-n108_2022-10-27-23_11_49.png,,search: how to copy files in python;,,
155,2,https://stackoverflow.com/questions/123198/how-to-copy-files,11310,screencapture-n109_2022-10-27-23_11_50.png,,visit: python - How to copy files - Stack Overflow;,,
156,2,,11650,,,code: main.py;,"# from PIL import Image
  
# im = Image.open(r""C:\Users\thien\Desktop\project\dat\Garbage classification\Garbage classification\glass\glass11.jpg"")
# im.show() 

from genericpath import exists
import math
import os
garbage_classification_folder = r""C:\Users\thien\Desktop\project\dat\Garbage classification\Garbage classification""

from pathlib import Path

# Setup path to data folder
data_path = Path(garbage_classification_folder)
image_path = data_path / ""cardboard""

def walk_through_dir(dir_path):
    no_of_files = 0
    for dirpath, dirnames, filenames in os.walk(dir_path):
        # print(f""There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'."")
        no_of_files = len(filenames)
    return no_of_files

import random
from PIL import Image

def allUnique(x):
    seen = list()
    return not any(i in seen or seen.append(i) for i in x)

# pass in the img dir path (eg. ./cardboard)
def get_random_img_list(dir_path, N):
    # Set seed
    random.seed(42)

    # 1. Get all image paths (* means ""any combination"")
    image_path_list = list(dir_path.glob(""*.jpg""))

    # converting the list into a set
    # image_path_set = set(image_path_list)

    # 2. Get random image path
    image_list_train = random.sample(image_path_list, k = N)

    s = set(image_list_train)
    image_list_test = [x for x in image_path_list if x not in s]

    return image_list_train, image_list_test

import shutil
def make_train_test_folder(dir_path):
    train_folder = dir_path / ""train""
    test_folder = dir_path / ""test""
    if os.path.exists(train_folder):
        shutil.rmtree(train_folder)
    else:
        # we need to select random images from all img folders and build up our train set
        training_dataset = []
        testing_dataset = []
        collection = [""cardboard"", ""glass"", ""metal"", ""paper"", ""plastic"", ""trash""]
        for el in collection:
            el_path = dir_path / el
            no_of_imgs = walk_through_dir(el_path)

            # grab 80% of imgs for training
            training_amount = math.floor(0.8 * no_of_imgs)
            training_dat, testing_dat = get_random_img_list(el_path, training_amount)
            
            training_dataset.append(training_dat)
            testing_dataset.append(testing_dat)
        
srcFile = data_path / ""cardboard"" / ""cardboard1.jpg""
destDir = data_path / ""testCopy""
if not os.path.exists(destDir):
    os.mkdir(destDir)

shutil.copy2(src = srcFile, dst = destDir)


# make_train_test_folder(data_path)
",
157,2,,11650,,,output: output.txt;,"c:/Users/thien/Desktop/project/venv/Scripts/python.exe c:/Users/thien/Desktop/project/main.py
(venv)",
158,2,,12348,,,code: main.py;,"# from PIL import Image
  
# im = Image.open(r""C:\Users\thien\Desktop\project\dat\Garbage classification\Garbage classification\glass\glass11.jpg"")
# im.show() 

from genericpath import exists
import math
import os
garbage_classification_folder = r""C:\Users\thien\Desktop\project\dat\Garbage classification\Garbage classification""

from pathlib import Path

# Setup path to data folder
data_path = Path(garbage_classification_folder)
image_path = data_path / ""cardboard""

def walk_through_dir(dir_path):
    no_of_files = 0
    for dirpath, dirnames, filenames in os.walk(dir_path):
        # print(f""There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'."")
        no_of_files = len(filenames)
    return no_of_files

import random
from PIL import Image

def allUnique(x):
    seen = list()
    return not any(i in seen or seen.append(i) for i in x)

# pass in the img dir path (eg. ./cardboard)
def get_random_img_list(dir_path, N):
    # Set seed
    random.seed(42)

    # 1. Get all image paths (* means ""any combination"")
    image_path_list = list(dir_path.glob(""*.jpg""))

    # converting the list into a set
    # image_path_set = set(image_path_list)

    # 2. Get random image path
    image_list_train = random.sample(image_path_list, k = N)

    s = set(image_list_train)
    image_list_test = [x for x in image_path_list if x not in s]

    return image_list_train, image_list_test

import shutil
def make_train_test_folder(dir_path):
    train_folder = dir_path / ""train""
    test_folder = dir_path / ""test""
    if os.path.exists(train_folder):
        shutil.rmtree(train_folder)
    elif os.path.exists(test_folder):
        shutil.rmtree(test_folder)
    else:
        # we need to select random images from all img folders and build up our train set
        training_dataset = []
        testing_dataset = []
        collection = [""cardboard"", ""glass"", ""metal"", ""paper"", ""plastic"", ""trash""]
        for el in collection:
            el_path = dir_path / el
            no_of_imgs = walk_through_dir(el_path)

            # grab 80% of imgs for training
            training_amount = math.floor(0.8 * no_of_imgs)
            training_dat, testing_dat = get_random_img_list(el_path, training_amount)
            
            training_dataset.append(training_dat)
            testing_dataset.append(testing_dat)
        
        os.mkdir(train_folder)
        os.mkdir(test_folder)
        for train_img_path in training_dataset:
            shutil.copy2(src=train_img_path, dst=train_folder)
        
        for test_img_path in testing_dataset:
            shutil.copy2(src=test_img_path, dst=test_folder)


# make_train_test_folder(data_path)
",
159,2,,12374,,,code: main.py;,"# from PIL import Image
  
# im = Image.open(r""C:\Users\thien\Desktop\project\dat\Garbage classification\Garbage classification\glass\glass11.jpg"")
# im.show() 

from genericpath import exists
import math
import os
garbage_classification_folder = r""C:\Users\thien\Desktop\project\dat\Garbage classification\Garbage classification""

from pathlib import Path

# Setup path to data folder
data_path = Path(garbage_classification_folder)
image_path = data_path / ""cardboard""

def walk_through_dir(dir_path):
    no_of_files = 0
    for dirpath, dirnames, filenames in os.walk(dir_path):
        # print(f""There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'."")
        no_of_files = len(filenames)
    return no_of_files

import random
from PIL import Image

def allUnique(x):
    seen = list()
    return not any(i in seen or seen.append(i) for i in x)

# pass in the img dir path (eg. ./cardboard)
def get_random_img_list(dir_path, N):
    # Set seed
    random.seed(42)

    # 1. Get all image paths (* means ""any combination"")
    image_path_list = list(dir_path.glob(""*.jpg""))

    # converting the list into a set
    # image_path_set = set(image_path_list)

    # 2. Get random image path
    image_list_train = random.sample(image_path_list, k = N)

    s = set(image_list_train)
    image_list_test = [x for x in image_path_list if x not in s]

    return image_list_train, image_list_test

import shutil
def make_train_test_folder(dir_path):
    train_folder = dir_path / ""train""
    test_folder = dir_path / ""test""
    if os.path.exists(train_folder):
        shutil.rmtree(train_folder)
    elif os.path.exists(test_folder):
        shutil.rmtree(test_folder)
    else:
        # we need to select random images from all img folders and build up our train set
        training_dataset = []
        testing_dataset = []
        collection = [""cardboard"", ""glass"", ""metal"", ""paper"", ""plastic"", ""trash""]
        for el in collection:
            el_path = dir_path / el
            no_of_imgs = walk_through_dir(el_path)

            # grab 80% of imgs for training
            training_amount = math.floor(0.8 * no_of_imgs)
            training_dat, testing_dat = get_random_img_list(el_path, training_amount)
            
            training_dataset.append(training_dat)
            testing_dataset.append(testing_dat)
        
        os.mkdir(train_folder)
        os.mkdir(test_folder)
        for train_img_path in training_dataset:
            shutil.copy2(src=train_img_path, dst=train_folder)
        
        for test_img_path in testing_dataset:
            shutil.copy2(src=test_img_path, dst=test_folder)

make_train_test_folder(data_path)
",
160,2,,12374,,,output: output.txt;,"c:/Users/thien/Desktop/project/venv/Scripts/python.exe c:/Users/thien/Desktop/project/main.py
Traceback (most recent call last):
  File ""c:/Users/thien/Desktop/project/main.py"", line 82, in <module>
    make_train_test_folder(data_path)
  File ""c:/Users/thien/Desktop/project/main.py"", line 77, in make_train_test_folder
    shutil.copy2(src=train_img_path, dst=train_folder)
  File ""C:\Python38\lib\shutil.py"", line 431, in copy2
    dst = os.path.join(dst, os.path.basename(src))
  File ""C:\Python38\lib\ntpath.py"", line 216, in basename
    return split(p)[1]
  File ""C:\Python38\lib\ntpath.py"", line 185, in split
    p = os.fspath(p)
TypeError: expected str, bytes or os.PathLike object, not list
(venv)",
161,2,,12423,,,code: main.py;,"# from PIL import Image
  
# im = Image.open(r""C:\Users\thien\Desktop\project\dat\Garbage classification\Garbage classification\glass\glass11.jpg"")
# im.show() 

from genericpath import exists
import math
import os
garbage_classification_folder = r""C:\Users\thien\Desktop\project\dat\Garbage classification\Garbage classification""

from pathlib import Path

# Setup path to data folder
data_path = Path(garbage_classification_folder)
image_path = data_path / ""cardboard""

def walk_through_dir(dir_path):
    no_of_files = 0
    for dirpath, dirnames, filenames in os.walk(dir_path):
        # print(f""There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'."")
        no_of_files = len(filenames)
    return no_of_files

import random
from PIL import Image

def allUnique(x):
    seen = list()
    return not any(i in seen or seen.append(i) for i in x)

# pass in the img dir path (eg. ./cardboard)
def get_random_img_list(dir_path, N):
    # Set seed
    random.seed(42)

    # 1. Get all image paths (* means ""any combination"")
    image_path_list = list(dir_path.glob(""*.jpg""))

    # converting the list into a set
    # image_path_set = set(image_path_list)

    # 2. Get random image path
    image_list_train = random.sample(image_path_list, k = N)

    s = set(image_list_train)
    image_list_test = [x for x in image_path_list if x not in s]

    return image_list_train, image_list_test

import shutil
def make_train_test_folder(dir_path):
    train_folder = dir_path / ""train""
    test_folder = dir_path / ""test""
    if os.path.exists(train_folder):
        shutil.rmtree(train_folder)
    elif os.path.exists(test_folder):
        shutil.rmtree(test_folder)
    else:
        # we need to select random images from all img folders and build up our train set
        training_dataset = []
        testing_dataset = []
        collection = [""cardboard"", ""glass"", ""metal"", ""paper"", ""plastic"", ""trash""]
        for el in collection:
            el_path = dir_path / el
            no_of_imgs = walk_through_dir(el_path)

            # grab 80% of imgs for training
            training_amount = math.floor(0.8 * no_of_imgs)
            training_dat, testing_dat = get_random_img_list(el_path, training_amount)
            
            training_dataset.append(training_dat)
            testing_dataset.append(testing_dat)
        
        os.mkdir(train_folder)
        os.mkdir(test_folder)
        for train_img_path in training_dataset:
            print(train_img_path)
            shutil.copy2(src=train_img_path, dst=train_folder)
        
        for test_img_path in testing_dataset:
            shutil.copy2(src=test_img_path, dst=test_folder)

make_train_test_folder(data_path)
",
162,2,,12423,,,output: output.txt;,"c:/Users/thien/Desktop/project/venv/Scripts/python.exe c:/Users/thien/Desktop/project/main.py
(venv)",
163,2,,12671,,,code: main.py;,"# from PIL import Image
  
# im = Image.open(r""C:\Users\thien\Desktop\project\dat\Garbage classification\Garbage classification\glass\glass11.jpg"")
# im.show() 

from genericpath import exists
import math
import os
garbage_classification_folder = r""C:\Users\thien\Desktop\project\dat\Garbage classification\Garbage classification""

from pathlib import Path

# Setup path to data folder
data_path = Path(garbage_classification_folder)
image_path = data_path / ""cardboard""

def walk_through_dir(dir_path):
    no_of_files = 0
    for dirpath, dirnames, filenames in os.walk(dir_path):
        # print(f""There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'."")
        no_of_files = len(filenames)
    return no_of_files

import random
from PIL import Image

def allUnique(x):
    seen = list()
    return not any(i in seen or seen.append(i) for i in x)

# pass in the img dir path (eg. ./cardboard)
def get_random_img_list(dir_path, N):
    # Set seed
    random.seed(42)

    # 1. Get all image paths (* means ""any combination"")
    image_path_list = list(dir_path.glob(""*.jpg""))

    # converting the list into a set
    # image_path_set = set(image_path_list)

    # 2. Get random image path
    image_list_train = random.sample(image_path_list, k = N)

    s = set(image_list_train)
    image_list_test = [x for x in image_path_list if x not in s]

    return image_list_train, image_list_test

import shutil
def make_train_test_folder(dir_path):
    train_folder = dir_path / ""train""
    test_folder = dir_path / ""test""
    if os.path.exists(train_folder):
        shutil.rmtree(train_folder)
    if os.path.exists(test_folder):
        shutil.rmtree(test_folder)
    
    if not os.path.exists(train_folder) and not os.path.exists(test_folder):
        # we need to select random images from all img folders and build up our train set
        training_dataset = []
        testing_dataset = []
        collection = [""cardboard"", ""glass"", ""metal"", ""paper"", ""plastic"", ""trash""]
        for el in collection:
            el_path = dir_path / el
            no_of_imgs = walk_through_dir(el_path)

            # grab 80% of imgs for training
            training_amount = math.floor(0.8 * no_of_imgs)
            training_dat, testing_dat = get_random_img_list(el_path, training_amount)
            
            training_dataset.append(training_dat)
            testing_dataset.append(testing_dat)
        
        os.mkdir(train_folder)
        os.mkdir(test_folder)
        for train_img_path in training_dataset:
            print(train_img_path)
            shutil.copy2(src=train_img_path, dst=train_folder)
        
        for test_img_path in testing_dataset:
            shutil.copy2(src=test_img_path, dst=test_folder)

make_train_test_folder(data_path)
",
164,2,,12671,,,output: output.txt;,"c:/Users/thien/Desktop/project/venv/Scripts/python.exe c:/Users/thien/Desktop/project/main.py
[WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard394.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard
50.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard11.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/c
rdboard78.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard225.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/car
board/cardboard211.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard201.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classific
tion/cardboard/cardboard163.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard76.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage c
assification/cardboard/cardboard146.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard48.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/G
rbage classification/cardboard/cardboard96.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard350.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classifi
ation/Garbage classification/cardboard/cardboard139.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard371.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage
classification/Garbage classification/cardboard/cardboard294.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard113.jpg'), WindowsPath('C:/Users/thien/Desktop/project/da
/Garbage classification/Garbage classification/cardboard/cardboard112.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard141.jpg'), WindowsPath('C:/Users/thien/Desktop/p
oject/dat/Garbage classification/Garbage classification/cardboard/cardboard2.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard206.jpg'), WindowsPath('C:/Users/thien/De
ktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard331.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard377.jpg'), WindowsPath('C:/Users
thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard110.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard358.jpg'), WindowsPath(
C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard190.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard66.jpg'), Wind
wsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard399.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard6.jpg'
, WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard88.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard
92.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard20.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/c
rdboard305.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard370.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/ca
dboard/cardboard227.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard101.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classifi
ation/cardboard/cardboard172.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard58.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage 
lassification/cardboard/cardboard85.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard256.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/
arbage classification/cardboard/cardboard68.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard170.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classif
cation/Garbage classification/cardboard/cardboard199.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard254.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbag
 classification/Garbage classification/cardboard/cardboard90.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard82.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat
Garbage classification/Garbage classification/cardboard/cardboard274.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard143.jpg'), WindowsPath('C:/Users/thien/Desktop/pr
ject/dat/Garbage classification/Garbage classification/cardboard/cardboard264.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard258.jpg'), WindowsPath('C:/Users/thien/D
sktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard378.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard220.jpg'), WindowsPath('C:/User
/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard119.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard310.jpg'), WindowsPath
'C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard346.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard156.jpg'), Wi
dowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard273.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard135.
pg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard353.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/card
oard234.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard389.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardb
ard/cardboard384.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard266.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classificat
on/cardboard/cardboard365.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard188.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage cl
ssification/cardboard/cardboard130.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard12.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Ga
bage classification/cardboard/cardboard203.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard232.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classifi
ation/Garbage classification/cardboard/cardboard47.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard80.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage c
assification/Garbage classification/cardboard/cardboard145.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard57.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/G
rbage classification/Garbage classification/cardboard/cardboard62.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard308.jpg'), WindowsPath('C:/Users/thien/Desktop/proje
t/dat/Garbage classification/Garbage classification/cardboard/cardboard392.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard267.jpg'), WindowsPath('C:/Users/thien/Desk
op/project/dat/Garbage classification/Garbage classification/cardboard/cardboard174.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard27.jpg'), WindowsPath('C:/Users/th
en/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard262.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard196.jpg'), WindowsPath('C:
Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard221.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard131.jpg'), Window
Path('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard38.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard178.jpg')
 WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard345.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard
4.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard99.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/ca
dboard311.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard397.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/car
board/cardboard223.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard356.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classific
tion/cardboard/cardboard70.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard249.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage c
assification/cardboard/cardboard124.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard204.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/
arbage classification/cardboard/cardboard84.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard244.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classif
cation/Garbage classification/cardboard/cardboard284.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard222.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbag
 classification/Garbage classification/cardboard/cardboard129.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard197.jpg'), WindowsPath('C:/Users/thien/Desktop/project/d
t/Garbage classification/Garbage classification/cardboard/cardboard360.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard374.jpg'), WindowsPath('C:/Users/thien/Desktop/
roject/dat/Garbage classification/Garbage classification/cardboard/cardboard69.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard329.jpg'), WindowsPath('C:/Users/thien/
esktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard281.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard31.jpg'), WindowsPath('C:/User
/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard165.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard52.jpg'), WindowsPath(
C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard92.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard212.jpg'), Wind
wsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard77.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard347.jpg
), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard22.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboar
297.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard283.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard
cardboard42.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard379.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/c
rdboard/cardboard162.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard333.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classif
cation/cardboard/cardboard326.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard140.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbag
 classification/cardboard/cardboard120.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard15.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classificatio
/Garbage classification/cardboard/cardboard17.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard75.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classi
ication/Garbage classification/cardboard/cardboard64.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard128.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbag
 classification/Garbage classification/cardboard/cardboard277.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard275.jpg'), WindowsPath('C:/Users/thien/Desktop/project/d
t/Garbage classification/Garbage classification/cardboard/cardboard314.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard342.jpg'), WindowsPath('C:/Users/thien/Desktop/
roject/dat/Garbage classification/Garbage classification/cardboard/cardboard214.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard103.jpg'), WindowsPath('C:/Users/thien
Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard151.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard44.jpg'), WindowsPath('C:/Use
s/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard63.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard98.jpg'), WindowsPath(
C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard45.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard3.jpg'), Window
Path('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard171.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard395.jpg'
, WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard10.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard
59.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard33.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/c
rdboard181.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard148.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/ca
dboard/cardboard335.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard243.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classifi
ation/cardboard/cardboard168.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard293.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage
classification/cardboard/cardboard246.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard215.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classificatio
/Garbage classification/cardboard/cardboard239.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard144.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage clas
ification/Garbage classification/cardboard/cardboard134.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard185.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Gar
age classification/Garbage classification/cardboard/cardboard344.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard136.jpg'), WindowsPath('C:/Users/thien/Desktop/projec
/dat/Garbage classification/Garbage classification/cardboard/cardboard380.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard279.jpg'), WindowsPath('C:/Users/thien/Deskt
p/project/dat/Garbage classification/Garbage classification/cardboard/cardboard382.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard363.jpg'), WindowsPath('C:/Users/th
en/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard50.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard1.jpg'), WindowsPath('C:/Us
rs/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard237.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard173.jpg'), WindowsPa
h('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard43.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard102.jpg'), W
ndowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard79.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard182.
pg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard300.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/card
oard290.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard285.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardb
ard/cardboard349.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard154.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classificat
on/cardboard/cardboard111.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard302.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage cl
ssification/cardboard/cardboard23.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard117.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Ga
bage classification/cardboard/cardboard118.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard268.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classifi
ation/Garbage classification/cardboard/cardboard210.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard287.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage
classification/Garbage classification/cardboard/cardboard114.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard381.jpg'), WindowsPath('C:/Users/thien/Desktop/project/da
/Garbage classification/Garbage classification/cardboard/cardboard339.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard276.jpg'), WindowsPath('C:/Users/thien/Desktop/p
oject/dat/Garbage classification/Garbage classification/cardboard/cardboard5.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard291.jpg'), WindowsPath('C:/Users/thien/De
ktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard250.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard208.jpg'), WindowsPath('C:/Users
thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard95.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard137.jpg'), WindowsPath('
:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard16.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard343.jpg'), Windo
sPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard322.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard368.jpg
), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard367.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboa
d317.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard9.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/
ardboard393.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard54.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/ca
dboard/cardboard398.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard263.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classifi
ation/cardboard/cardboard61.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard191.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage 
lassification/cardboard/cardboard253.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard53.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/
arbage classification/cardboard/cardboard32.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard355.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classif
cation/Garbage classification/cardboard/cardboard218.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard202.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbag
 classification/Garbage classification/cardboard/cardboard126.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard49.jpg'), WindowsPath('C:/Users/thien/Desktop/project/da
/Garbage classification/Garbage classification/cardboard/cardboard337.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard375.jpg'), WindowsPath('C:/Users/thien/Desktop/p
oject/dat/Garbage classification/Garbage classification/cardboard/cardboard177.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard340.jpg'), WindowsPath('C:/Users/thien/
esktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard336.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard226.jpg'), WindowsPath('C:/Use
s/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard34.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard385.jpg'), WindowsPath
'C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard35.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard332.jpg'), Win
owsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard115.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard369.j
g'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard83.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardbo
rd261.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard295.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboa
d/cardboard106.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard175.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classificatio
/cardboard/cardboard316.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard217.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage clas
ification/cardboard/cardboard153.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard362.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Gar
age classification/cardboard/cardboard37.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard282.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classifica
ion/Garbage classification/cardboard/cardboard366.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard86.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage cl
ssification/Garbage classification/cardboard/cardboard230.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard231.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/G
rbage classification/Garbage classification/cardboard/cardboard289.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard155.jpg'), WindowsPath('C:/Users/thien/Desktop/proj
ct/dat/Garbage classification/Garbage classification/cardboard/cardboard242.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard193.jpg'), WindowsPath('C:/Users/thien/Des
top/project/dat/Garbage classification/Garbage classification/cardboard/cardboard142.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard72.jpg'), WindowsPath('C:/Users/t
ien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard238.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard60.jpg'), WindowsPath('C:
Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard180.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard357.jpg'), Window
Path('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard194.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard74.jpg')
 WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard89.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard1
1.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard338.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/c
rdboard192.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard265.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/ca
dboard/cardboard123.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard298.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classifi
ation/cardboard/cardboard56.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard373.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage 
lassification/cardboard/cardboard372.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard93.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/
arbage classification/cardboard/cardboard402.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard260.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classi
ication/Garbage classification/cardboard/cardboard351.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard280.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garba
e classification/Garbage classification/cardboard/cardboard205.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard390.jpg'), WindowsPath('C:/Users/thien/Desktop/project/
at/Garbage classification/Garbage classification/cardboard/cardboard116.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard200.jpg'), WindowsPath('C:/Users/thien/Desktop
project/dat/Garbage classification/Garbage classification/cardboard/cardboard257.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard97.jpg'), WindowsPath('C:/Users/thien
Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard383.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard161.jpg'), WindowsPath('C:/Us
rs/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard39.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard259.jpg'), WindowsPat
('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard109.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard270.jpg'), W
ndowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard186.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard304
jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard269.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/car
board299.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard59.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardb
ard/cardboard241.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard306.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classificat
on/cardboard/cardboard396.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard236.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage cl
ssification/cardboard/cardboard278.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard105.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/G
rbage classification/cardboard/cardboard376.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard224.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classif
cation/Garbage classification/cardboard/cardboard312.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard288.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbag
 classification/Garbage classification/cardboard/cardboard245.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard19.jpg'), WindowsPath('C:/Users/thien/Desktop/project/da
/Garbage classification/Garbage classification/cardboard/cardboard24.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard255.jpg'), WindowsPath('C:/Users/thien/Desktop/pr
ject/dat/Garbage classification/Garbage classification/cardboard/cardboard388.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard247.jpg'), WindowsPath('C:/Users/thien/D
sktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard18.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard183.jpg'), WindowsPath('C:/Users
thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard219.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard252.jpg'), WindowsPath(
C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard330.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard391.jpg'), Win
owsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard216.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard315.j
g'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard132.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardb
ard323.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard271.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardbo
rd/cardboard166.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard41.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classificatio
/cardboard/cardboard189.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard4.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classi
ication/cardboard/cardboard228.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard104.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garba
e classification/cardboard/cardboard179.jpg'), WindowsPath('C:/Users/thien/Desktop/project/dat/Garbage classification/Garbage classification/cardboard/cardboard324.jpg')]
Traceback (most recent call last):
  File ""c:/Users/thien/Desktop/project/main.py"", line 84, in <module>
    make_train_test_folder(data_path)
  File ""c:/Users/thien/Desktop/project/main.py"", line 79, in make_train_test_folder
    shutil.copy2(src=train_img_path, dst=train_folder)
  File ""C:\Python38\lib\shutil.py"", line 431, in copy2
    dst = os.path.join(dst, os.path.basename(src))
  File ""C:\Python38\lib\ntpath.py"", line 216, in basename
    return split(p)[1]
  File ""C:\Python38\lib\ntpath.py"", line 185, in split
    p = os.fspath(p)
TypeError: expected str, bytes or os.PathLike object, not list
(venv)",
165,2,https://stackoverflow.com/questions/3462143/get-difference-between-two-lists,12696,screencapture-n110_2022-10-27-23_34_56.png,,revisit: python - Get difference between two lists - Stack Overflow;,,
166,2,https://stackoverflow.com/questions/30735892/random-without-repetition,12699,screencapture-n111_2022-10-27-23_34_59.png,,revisit: python - Random without repetition? - Stack Overflow;,,
167,2,https://stackoverflow.com/questions/952914/how-do-i-make-a-flat-list-out-of-a-list-of-lists,12708,screencapture-n112_2022-10-27-23_35_08.png,,revisit: python - How do I make a flat list out of a list of lists? - Stack Overflow;,,
168,2,,12900,,,code: main.py;,"# from PIL import Image
  
# im = Image.open(r""C:\Users\thien\Desktop\project\dat\Garbage classification\Garbage classification\glass\glass11.jpg"")
# im.show() 

from genericpath import exists
import math
import os
garbage_classification_folder = r""C:\Users\thien\Desktop\project\dat\Garbage classification\Garbage classification""

from pathlib import Path

# Setup path to data folder
data_path = Path(garbage_classification_folder)
image_path = data_path / ""cardboard""

def walk_through_dir(dir_path):
    no_of_files = 0
    for dirpath, dirnames, filenames in os.walk(dir_path):
        # print(f""There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'."")
        no_of_files = len(filenames)
    return no_of_files

import random
from PIL import Image

def allUnique(x):
    seen = list()
    return not any(i in seen or seen.append(i) for i in x)

# pass in the img dir path (eg. ./cardboard)
def get_random_img_list(dir_path, N):
    # Set seed
    random.seed(42)

    # 1. Get all image paths (* means ""any combination"")
    image_path_list = list(dir_path.glob(""*.jpg""))

    # converting the list into a set
    # image_path_set = set(image_path_list)

    # 2. Get random image path
    image_list_train = random.sample(image_path_list, k = N)

    s = set(image_list_train)
    image_list_test = [x for x in image_path_list if x not in s]

    return image_list_train, image_list_test

def flatten(l):
    return [item for sublist in l for item in sublist]

import shutil
def make_train_test_folder(dir_path):
    train_folder = dir_path / ""train""
    test_folder = dir_path / ""test""
    if os.path.exists(train_folder):
        shutil.rmtree(train_folder)
    if os.path.exists(test_folder):
        shutil.rmtree(test_folder)
    
    if not os.path.exists(train_folder) and not os.path.exists(test_folder):
        # we need to select random images from all img folders and build up our train set
        training_dataset = []
        testing_dataset = []
        collection = [""cardboard"", ""glass"", ""metal"", ""paper"", ""plastic"", ""trash""]
        for el in collection:
            el_path = dir_path / el
            no_of_imgs = walk_through_dir(el_path)

            # grab 80% of imgs for training
            training_amount = math.floor(0.8 * no_of_imgs)
            training_dat, testing_dat = get_random_img_list(el_path, training_amount)
            
            training_dataset.append(training_dat)
            testing_dataset.append(testing_dat)

        training_dataset = flatten(training_dataset)
        testing_dataset = flatten(testing_dataset)
        
        os.mkdir(train_folder)
        os.mkdir(test_folder)
        for train_img_path in training_dataset:
            shutil.copy2(src=train_img_path, dst=train_folder)
        
        for test_img_path in testing_dataset:
            shutil.copy2(src=test_img_path, dst=test_folder)

make_train_test_folder(data_path)
",
169,2,,12900,,,output: output.txt;,"c:/Users/thien/Desktop/project/venv/Scripts/python.exe c:/Users/thien/Desktop/project/main.py
(venv)",
170,2,https://www.learnpytorch.io/04_pytorch_custom_datasets/,12979,screencapture-n113_2022-10-27-23_39_39.png,,revisit: 04. PyTorch Custom Datasets - Zero to Mastery Learn PyTorch for Deep Learning;,,
171,2,,13823,,,code: main.py;,"# from PIL import Image
  
# im = Image.open(r""C:\Users\thien\Desktop\project\dat\Garbage classification\Garbage classification\glass\glass11.jpg"")
# im.show() 

from genericpath import exists
import math
import os
garbage_classification_folder = r""C:\Users\thien\Desktop\project\dat\Garbage classification\Garbage classification""

from pathlib import Path

# Setup path to data folder
data_path = Path(garbage_classification_folder)
image_path = data_path / ""cardboard""

def walk_through_dir(dir_path):
    no_of_files = 0
    for dirpath, dirnames, filenames in os.walk(dir_path):
        # print(f""There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'."")
        no_of_files = len(filenames)
    return no_of_files

import random
from PIL import Image

def allUnique(x):
    seen = list()
    return not any(i in seen or seen.append(i) for i in x)

# pass in the img dir path (eg. ./cardboard)
def get_random_img_list(dir_path, N):
    # Set seed
    random.seed(42)

    # 1. Get all image paths (* means ""any combination"")
    image_path_list = list(dir_path.glob(""*.jpg""))

    # converting the list into a set
    # image_path_set = set(image_path_list)

    # 2. Get random image path
    image_list_train = random.sample(image_path_list, k = N)

    s = set(image_list_train)
    image_list_test = [x for x in image_path_list if x not in s]

    return image_list_train, image_list_test

def flatten(l):
    return [item for sublist in l for item in sublist]

import shutil
def make_train_test_folder(dir_path):
    train_folder = dir_path / ""train""
    test_folder = dir_path / ""test""
    if os.path.exists(train_folder):
        shutil.rmtree(train_folder)
    if os.path.exists(test_folder):
        shutil.rmtree(test_folder)
    
    if not os.path.exists(train_folder) and not os.path.exists(test_folder):
        # we need to select random images from all img folders and build up our train set
        training_dataset = []
        testing_dataset = []
        collection = [""cardboard"", ""glass"", ""metal"", ""paper"", ""plastic"", ""trash""]
        for el in collection:
            el_path = dir_path / el
            no_of_imgs = walk_through_dir(el_path)

            # grab 80% of imgs for training
            training_amount = math.floor(0.8 * no_of_imgs)
            training_dat, testing_dat = get_random_img_list(el_path, training_amount)
            
            training_dataset.append(training_dat)
            testing_dataset.append(testing_dat)

        training_dataset = flatten(training_dataset)
        testing_dataset = flatten(testing_dataset)
        
        os.mkdir(train_folder)
        os.mkdir(test_folder)
        for train_img_path in training_dataset:
            shutil.copy2(src=train_img_path, dst=train_folder)
        
        for test_img_path in testing_dataset:
            shutil.copy2(src=test_img_path, dst=test_folder)

# make_train_test_folder(data_path)

import torch
from torch.utils.data import DataLoader
from torchvision import datasets, transforms

train_dir = data_path / ""train""
test_dir = data_path / ""test""

# Write transform for image
data_transform = transforms.Compose([
    # Resize the images to 128x128
    transforms.Resize(size=(128, 128)),
    # Turn the image into a torch.Tensor
    transforms.ToTensor() # this also converts all pixel values from 0 to 255 to be between 0.0 and 1.0 
])

image_path_list_test = list(train_dir.glob(""*.jpg""))
random_image_path_test = random.choice(image_path_list_test)

import matplotlib.pyplot as plt

def plot_transformed_images(image_paths, transform, n=3):
    # Plots a series of random images from image_paths.
    # Will open n image paths from image_paths, transform them
    # with transform and plot them side by side.
    random.seed(42)
    random_image_paths = random.sample(image_paths, k=n)
    for image_path in random_image_paths:
        with Image.open(image_path) as f:
            fig, ax = plt.subplots(1, 2)
            ax[0].imshow(f) 
            ax[0].set_title(f""Original \nSize: {f.size}"")
            ax[0].axis(""off"")

            # Transform and plot image
            # Note: permute() will change shape of image to suit matplotlib 
            # (PyTorch default is [C, H, W] but Matplotlib is [H, W, C])
            transformed_image = transform(f).permute(1, 2, 0) 
            ax[1].imshow(transformed_image) 
            ax[1].set_title(f""Transformed \nSize: {transformed_image.shape}"")
            ax[1].axis(""off"")

            fig.suptitle(f""Class: {image_path.parent.stem}"", fontsize=16)

plot_transformed_images(image_path_list_test, transform=data_transform, n=3)",
172,2,https://www.google.com/search?q=how+to+show+fig+python&rlz=1C1SQJL_enUS958US958&oq=how+to+show+fig+&aqs=chrome.1.69i57j0i22i30l9.4388j0j7&sourceid=chrome&ie=UTF-8,13844,screencapture-n114_2022-10-27-23_54_04.png,,search: how to show fig python;,,
173,2,https://www.geeksforgeeks.org/matplotlib-figure-figure-show-in-python/,13846,screencapture-n115_2022-10-27-23_54_06.png,,visit: Matplotlib.figure.Figure.show() in Python - GeeksforGeeks;,,
174,2,,13875,,,code: main.py;,"# from PIL import Image
  
# im = Image.open(r""C:\Users\thien\Desktop\project\dat\Garbage classification\Garbage classification\glass\glass11.jpg"")
# im.show() 

from genericpath import exists
import math
import os
garbage_classification_folder = r""C:\Users\thien\Desktop\project\dat\Garbage classification\Garbage classification""

from pathlib import Path

# Setup path to data folder
data_path = Path(garbage_classification_folder)
image_path = data_path / ""cardboard""

def walk_through_dir(dir_path):
    no_of_files = 0
    for dirpath, dirnames, filenames in os.walk(dir_path):
        # print(f""There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'."")
        no_of_files = len(filenames)
    return no_of_files

import random
from PIL import Image

def allUnique(x):
    seen = list()
    return not any(i in seen or seen.append(i) for i in x)

# pass in the img dir path (eg. ./cardboard)
def get_random_img_list(dir_path, N):
    # Set seed
    random.seed(42)

    # 1. Get all image paths (* means ""any combination"")
    image_path_list = list(dir_path.glob(""*.jpg""))

    # converting the list into a set
    # image_path_set = set(image_path_list)

    # 2. Get random image path
    image_list_train = random.sample(image_path_list, k = N)

    s = set(image_list_train)
    image_list_test = [x for x in image_path_list if x not in s]

    return image_list_train, image_list_test

def flatten(l):
    return [item for sublist in l for item in sublist]

import shutil
def make_train_test_folder(dir_path):
    train_folder = dir_path / ""train""
    test_folder = dir_path / ""test""
    if os.path.exists(train_folder):
        shutil.rmtree(train_folder)
    if os.path.exists(test_folder):
        shutil.rmtree(test_folder)
    
    if not os.path.exists(train_folder) and not os.path.exists(test_folder):
        # we need to select random images from all img folders and build up our train set
        training_dataset = []
        testing_dataset = []
        collection = [""cardboard"", ""glass"", ""metal"", ""paper"", ""plastic"", ""trash""]
        for el in collection:
            el_path = dir_path / el
            no_of_imgs = walk_through_dir(el_path)

            # grab 80% of imgs for training
            training_amount = math.floor(0.8 * no_of_imgs)
            training_dat, testing_dat = get_random_img_list(el_path, training_amount)
            
            training_dataset.append(training_dat)
            testing_dataset.append(testing_dat)

        training_dataset = flatten(training_dataset)
        testing_dataset = flatten(testing_dataset)
        
        os.mkdir(train_folder)
        os.mkdir(test_folder)
        for train_img_path in training_dataset:
            shutil.copy2(src=train_img_path, dst=train_folder)
        
        for test_img_path in testing_dataset:
            shutil.copy2(src=test_img_path, dst=test_folder)

# make_train_test_folder(data_path)

import torch
from torch.utils.data import DataLoader
from torchvision import datasets, transforms

train_dir = data_path / ""train""
test_dir = data_path / ""test""

# Write transform for image
data_transform = transforms.Compose([
    # Resize the images to 128x128
    transforms.Resize(size=(128, 128)),
    # Turn the image into a torch.Tensor
    transforms.ToTensor() # this also converts all pixel values from 0 to 255 to be between 0.0 and 1.0 
])

image_path_list_test = list(train_dir.glob(""*.jpg""))
random_image_path_test = random.choice(image_path_list_test)

import matplotlib.pyplot as plt

def plot_transformed_images(image_paths, transform, n=3):
    # Plots a series of random images from image_paths.
    # Will open n image paths from image_paths, transform them
    # with transform and plot them side by side.
    random.seed(42)
    random_image_paths = random.sample(image_paths, k=n)
    for image_path in random_image_paths:
        with Image.open(image_path) as f:
            fig, ax = plt.subplots(1, 2)
            ax[0].imshow(f) 
            ax[0].set_title(f""Original \nSize: {f.size}"")
            ax[0].axis(""off"")

            # Transform and plot image
            # Note: permute() will change shape of image to suit matplotlib 
            # (PyTorch default is [C, H, W] but Matplotlib is [H, W, C])
            transformed_image = transform(f).permute(1, 2, 0) 
            ax[1].imshow(transformed_image) 
            ax[1].set_title(f""Transformed \nSize: {transformed_image.shape}"")
            ax[1].axis(""off"")

            fig.suptitle(f""Class: {image_path.parent.stem}"", fontsize=16)
    fig.show()

plot_transformed_images(image_path_list_test, transform=data_transform, n=3)",
175,2,,13899,,,code: main.py;,"# from PIL import Image
  
# im = Image.open(r""C:\Users\thien\Desktop\project\dat\Garbage classification\Garbage classification\glass\glass11.jpg"")
# im.show() 

from genericpath import exists
import math
import os
garbage_classification_folder = r""C:\Users\thien\Desktop\project\dat\Garbage classification\Garbage classification""

from pathlib import Path

# Setup path to data folder
data_path = Path(garbage_classification_folder)
image_path = data_path / ""cardboard""

def walk_through_dir(dir_path):
    no_of_files = 0
    for dirpath, dirnames, filenames in os.walk(dir_path):
        # print(f""There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'."")
        no_of_files = len(filenames)
    return no_of_files

import random
from PIL import Image

def allUnique(x):
    seen = list()
    return not any(i in seen or seen.append(i) for i in x)

# pass in the img dir path (eg. ./cardboard)
def get_random_img_list(dir_path, N):
    # Set seed
    random.seed(42)

    # 1. Get all image paths (* means ""any combination"")
    image_path_list = list(dir_path.glob(""*.jpg""))

    # converting the list into a set
    # image_path_set = set(image_path_list)

    # 2. Get random image path
    image_list_train = random.sample(image_path_list, k = N)

    s = set(image_list_train)
    image_list_test = [x for x in image_path_list if x not in s]

    return image_list_train, image_list_test

def flatten(l):
    return [item for sublist in l for item in sublist]

import shutil
def make_train_test_folder(dir_path):
    train_folder = dir_path / ""train""
    test_folder = dir_path / ""test""
    if os.path.exists(train_folder):
        shutil.rmtree(train_folder)
    if os.path.exists(test_folder):
        shutil.rmtree(test_folder)
    
    if not os.path.exists(train_folder) and not os.path.exists(test_folder):
        # we need to select random images from all img folders and build up our train set
        training_dataset = []
        testing_dataset = []
        collection = [""cardboard"", ""glass"", ""metal"", ""paper"", ""plastic"", ""trash""]
        for el in collection:
            el_path = dir_path / el
            no_of_imgs = walk_through_dir(el_path)

            # grab 80% of imgs for training
            training_amount = math.floor(0.8 * no_of_imgs)
            training_dat, testing_dat = get_random_img_list(el_path, training_amount)
            
            training_dataset.append(training_dat)
            testing_dataset.append(testing_dat)

        training_dataset = flatten(training_dataset)
        testing_dataset = flatten(testing_dataset)
        
        os.mkdir(train_folder)
        os.mkdir(test_folder)
        for train_img_path in training_dataset:
            shutil.copy2(src=train_img_path, dst=train_folder)
        
        for test_img_path in testing_dataset:
            shutil.copy2(src=test_img_path, dst=test_folder)

# make_train_test_folder(data_path)

import torch
from torch.utils.data import DataLoader
from torchvision import datasets, transforms

train_dir = data_path / ""train""
test_dir = data_path / ""test""

# Write transform for image
data_transform = transforms.Compose([
    # Resize the images to 128x128
    transforms.Resize(size=(128, 128)),
    # Turn the image into a torch.Tensor
    transforms.ToTensor() # this also converts all pixel values from 0 to 255 to be between 0.0 and 1.0 
])

image_path_list_test = list(train_dir.glob(""*.jpg""))
random_image_path_test = random.choice(image_path_list_test)

import matplotlib.pyplot as plt

def plot_transformed_images(image_paths, transform, n=3):
    # Plots a series of random images from image_paths.
    # Will open n image paths from image_paths, transform them
    # with transform and plot them side by side.
    random.seed(42)
    random_image_paths = random.sample(image_paths, k=n)
    for image_path in random_image_paths:
        with Image.open(image_path) as f:
            fig, ax = plt.subplots(1, 2)
            ax[0].imshow(f) 
            ax[0].set_title(f""Original \nSize: {f.size}"")
            ax[0].axis(""off"")

            # Transform and plot image
            # Note: permute() will change shape of image to suit matplotlib 
            # (PyTorch default is [C, H, W] but Matplotlib is [H, W, C])
            transformed_image = transform(f).permute(1, 2, 0) 
            ax[1].imshow(transformed_image) 
            ax[1].set_title(f""Transformed \nSize: {transformed_image.shape}"")
            ax[1].axis(""off"")

            fig.suptitle(f""Class: {image_path.parent.stem}"", fontsize=16)
            fig.show()

plot_transformed_images(image_path_list_test, transform=data_transform, n=3)",
176,2,https://www.google.com/search?q=how+to+show+fig+python+but+not+close+right+away&rlz=1C1SQJL_enUS958US958&sxsrf=ALiCzsZzGb0r4hHFnO7YcOkWPdKUwnob4Q%3A1666932843663&ei=a2BbY7iMKPGGptQPypuG2A4&oq=how+to+show+fig+python+but+not+close+right+&gs_lp=Egdnd3Mtd2l6uAED-AEBGgIYAyoCCAAyChAhGKABGAoYiwMyBxAhGKABGAoyChAhGKABGAoYiwMyChAhGKABGAoYiwMyBRAhGKsCMggQIRirAhiLA8ICChAAGEcY1gQYsAPCAgYQABgWGB7CAgUQABiGA8ICCxAhGBYYHhgdGIsDwgIIECEYFhgeGB2QBghI9FBQngJY1T5wAXgByAEAkAEAmAF3oAGkEaoBBDQuMTfiAwQgTRgB4gMEIEEYAOIDBCBGGACIBgE&sclient=gws-wiz,13942,screencapture-n116_2022-10-27-23_55_42.png,,search: how to show fig python but not close right away;,,
177,2,https://www.google.com/search?q=how+to+show+figure+python+matplotlib+without+close+right+away&rlz=1C1SQJL_enUS958US958&sxsrf=ALiCzsbBCtnHtWXBJuZuhS4EqKUQiLZSOw%3A1666932940900&ei=zGBbY73GNpi0ptQPuuuroAw&oq=how+to+show+figure+python+matplotlib+without+&gs_lp=Egdnd3Mtd2l6uAED-AEBGgIYAyoCCAEyBRAhGKABMgUQIRigATIIECEYoAEYiwMyCBAhGKABGIsDMggQIRirAhiLAzIIECEYqwIYiwMyCBAhGKsCGIsDwgIKEAAYRxjWBBiwA8ICBBAjGCfCAgUQABiABMICBhAAGBYYHsICBRAAGIYDwgILECEYFhgeGB0YiwPCAggQIRgWGB4YHcICDRAhGBYYHhgPGB0YiwPCAgoQIRgWGB4YDxgdkAYISMdHUMIGWK83cAF4AcgBAJABAJgBhAGgAbERqgEEMTUuOOIDBCBNGAHiAwQgQRgA4gMEIEYYAIgGAQ&sclient=gws-wiz,13967,screencapture-n117_2022-10-27-23_56_07.png,,search: how to show figure python matplotlib without close right away;,,
178,2,https://stackoverflow.com/questions/458209/is-there-a-way-to-detach-matplotlib-plots-so-that-the-computation-can-continue,13972,screencapture-n118_2022-10-27-23_56_12.png,,visit: python - Is there a way to detach matplotlib plots so that the computation can continue? - Stack Overflow;,,
179,2,https://www.google.com/search?q=how+to+avoid+plt+closing+on+its+own&rlz=1C1SQJL_enUS958US958&sxsrf=ALiCzsb428RuIWPb3cK-bHmtHc5E0SXTZQ%3A1666932966616&ei=5mBbY7z5JN-1ptQPioirmA0&oq=how+to+avoid+plt+closing+&gs_lp=Egdnd3Mtd2l6uAED-AEBGgIYAyoCCAAyBRAhGKABMggQIRigARiLAzIIECEYoAEYiwMyCBAhGKsCGIsDMggQIRirAhiLA8ICBBAjGCfCAgUQABiRAsICERAuGIAEGLEDGIMBGMcBGNEDwgILEAAYgAQYsQMYgwHCAgQQABhDwgILEC4YgAQYsQMY1ALCAggQABixAxiDAcICBRAAGIAEwgIIEAAYgAQYsQPCAggQABiABBjJA8ICBhAAGBYYHsICCBAAGBYYHhgPwgIFEAAYhgPCAgsQIRgWGB4YHRiLA8ICBRAhGKsCwgIIECEYFhgeGB3CAgoQIRigARgKGIsDSOMsUABYpiFwAHgByAEAkAEAmAFwoAGcEaoBBDE5LjbiAwQgTRgB4gMEIEEYAOIDBCBGGACIBgE&sclient=gws-wiz,14031,screencapture-n119_2022-10-27-23_57_11.png,,search: how to avoid plt closing on its own;,,
180,2,https://stackoverflow.com/questions/11140787/closing-pyplot-windows,14033,screencapture-n120_2022-10-27-23_57_13.png,,visit: python - Closing pyplot windows - Stack Overflow;,,
181,2,,14071,,,code: main.py;,"# from PIL import Image
  
# im = Image.open(r""C:\Users\thien\Desktop\project\dat\Garbage classification\Garbage classification\glass\glass11.jpg"")
# im.show() 

from genericpath import exists
import math
import os
garbage_classification_folder = r""C:\Users\thien\Desktop\project\dat\Garbage classification\Garbage classification""

from pathlib import Path

# Setup path to data folder
data_path = Path(garbage_classification_folder)
image_path = data_path / ""cardboard""

def walk_through_dir(dir_path):
    no_of_files = 0
    for dirpath, dirnames, filenames in os.walk(dir_path):
        # print(f""There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'."")
        no_of_files = len(filenames)
    return no_of_files

import random
from PIL import Image

def allUnique(x):
    seen = list()
    return not any(i in seen or seen.append(i) for i in x)

# pass in the img dir path (eg. ./cardboard)
def get_random_img_list(dir_path, N):
    # Set seed
    random.seed(42)

    # 1. Get all image paths (* means ""any combination"")
    image_path_list = list(dir_path.glob(""*.jpg""))

    # converting the list into a set
    # image_path_set = set(image_path_list)

    # 2. Get random image path
    image_list_train = random.sample(image_path_list, k = N)

    s = set(image_list_train)
    image_list_test = [x for x in image_path_list if x not in s]

    return image_list_train, image_list_test

def flatten(l):
    return [item for sublist in l for item in sublist]

import shutil
def make_train_test_folder(dir_path):
    train_folder = dir_path / ""train""
    test_folder = dir_path / ""test""
    if os.path.exists(train_folder):
        shutil.rmtree(train_folder)
    if os.path.exists(test_folder):
        shutil.rmtree(test_folder)
    
    if not os.path.exists(train_folder) and not os.path.exists(test_folder):
        # we need to select random images from all img folders and build up our train set
        training_dataset = []
        testing_dataset = []
        collection = [""cardboard"", ""glass"", ""metal"", ""paper"", ""plastic"", ""trash""]
        for el in collection:
            el_path = dir_path / el
            no_of_imgs = walk_through_dir(el_path)

            # grab 80% of imgs for training
            training_amount = math.floor(0.8 * no_of_imgs)
            training_dat, testing_dat = get_random_img_list(el_path, training_amount)
            
            training_dataset.append(training_dat)
            testing_dataset.append(testing_dat)

        training_dataset = flatten(training_dataset)
        testing_dataset = flatten(testing_dataset)
        
        os.mkdir(train_folder)
        os.mkdir(test_folder)
        for train_img_path in training_dataset:
            shutil.copy2(src=train_img_path, dst=train_folder)
        
        for test_img_path in testing_dataset:
            shutil.copy2(src=test_img_path, dst=test_folder)

# make_train_test_folder(data_path)

import torch
from torch.utils.data import DataLoader
from torchvision import datasets, transforms

train_dir = data_path / ""train""
test_dir = data_path / ""test""

# Write transform for image
data_transform = transforms.Compose([
    # Resize the images to 128x128
    transforms.Resize(size=(128, 128)),
    # Turn the image into a torch.Tensor
    transforms.ToTensor() # this also converts all pixel values from 0 to 255 to be between 0.0 and 1.0 
])

image_path_list_test = list(train_dir.glob(""*.jpg""))
random_image_path_test = random.choice(image_path_list_test)

import matplotlib.pyplot as plt

def plot_transformed_images(image_paths, transform, n=3):
    # Plots a series of random images from image_paths.
    # Will open n image paths from image_paths, transform them
    # with transform and plot them side by side.
    random.seed(42)
    random_image_paths = random.sample(image_paths, k=n)
    for image_path in random_image_paths:
        with Image.open(image_path) as f:
            fig, ax = plt.subplots(1, 2)
            ax[0].imshow(f) 
            ax[0].set_title(f""Original \nSize: {f.size}"")
            ax[0].axis(""off"")

            # Transform and plot image
            # Note: permute() will change shape of image to suit matplotlib 
            # (PyTorch default is [C, H, W] but Matplotlib is [H, W, C])
            transformed_image = transform(f).permute(1, 2, 0) 
            ax[1].imshow(transformed_image) 
            ax[1].set_title(f""Transformed \nSize: {transformed_image.shape}"")
            ax[1].axis(""off"")

            fig.suptitle(f""Class: {image_path.parent.stem}"", fontsize=16)
            fig.show()
            plt.show(block=False)

plot_transformed_images(image_path_list_test, transform=data_transform, n=3)",
182,2,,14117,,,code: main.py;,"# from PIL import Image
  
# im = Image.open(r""C:\Users\thien\Desktop\project\dat\Garbage classification\Garbage classification\glass\glass11.jpg"")
# im.show() 

from genericpath import exists
import math
import os
garbage_classification_folder = r""C:\Users\thien\Desktop\project\dat\Garbage classification\Garbage classification""

from pathlib import Path

# Setup path to data folder
data_path = Path(garbage_classification_folder)
image_path = data_path / ""cardboard""

def walk_through_dir(dir_path):
    no_of_files = 0
    for dirpath, dirnames, filenames in os.walk(dir_path):
        # print(f""There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'."")
        no_of_files = len(filenames)
    return no_of_files

import random
from PIL import Image

def allUnique(x):
    seen = list()
    return not any(i in seen or seen.append(i) for i in x)

# pass in the img dir path (eg. ./cardboard)
def get_random_img_list(dir_path, N):
    # Set seed
    random.seed(42)

    # 1. Get all image paths (* means ""any combination"")
    image_path_list = list(dir_path.glob(""*.jpg""))

    # converting the list into a set
    # image_path_set = set(image_path_list)

    # 2. Get random image path
    image_list_train = random.sample(image_path_list, k = N)

    s = set(image_list_train)
    image_list_test = [x for x in image_path_list if x not in s]

    return image_list_train, image_list_test

def flatten(l):
    return [item for sublist in l for item in sublist]

import shutil
def make_train_test_folder(dir_path):
    train_folder = dir_path / ""train""
    test_folder = dir_path / ""test""
    if os.path.exists(train_folder):
        shutil.rmtree(train_folder)
    if os.path.exists(test_folder):
        shutil.rmtree(test_folder)
    
    if not os.path.exists(train_folder) and not os.path.exists(test_folder):
        # we need to select random images from all img folders and build up our train set
        training_dataset = []
        testing_dataset = []
        collection = [""cardboard"", ""glass"", ""metal"", ""paper"", ""plastic"", ""trash""]
        for el in collection:
            el_path = dir_path / el
            no_of_imgs = walk_through_dir(el_path)

            # grab 80% of imgs for training
            training_amount = math.floor(0.8 * no_of_imgs)
            training_dat, testing_dat = get_random_img_list(el_path, training_amount)
            
            training_dataset.append(training_dat)
            testing_dataset.append(testing_dat)

        training_dataset = flatten(training_dataset)
        testing_dataset = flatten(testing_dataset)
        
        os.mkdir(train_folder)
        os.mkdir(test_folder)
        for train_img_path in training_dataset:
            shutil.copy2(src=train_img_path, dst=train_folder)
        
        for test_img_path in testing_dataset:
            shutil.copy2(src=test_img_path, dst=test_folder)

# make_train_test_folder(data_path)

import torch
from torch.utils.data import DataLoader
from torchvision import datasets, transforms

train_dir = data_path / ""train""
test_dir = data_path / ""test""

# Write transform for image
data_transform = transforms.Compose([
    # Resize the images to 128x128
    transforms.Resize(size=(128, 128)),
    # Turn the image into a torch.Tensor
    transforms.ToTensor() # this also converts all pixel values from 0 to 255 to be between 0.0 and 1.0 
])

image_path_list_test = list(train_dir.glob(""*.jpg""))
random_image_path_test = random.choice(image_path_list_test)

import matplotlib.pyplot as plt

def plot_transformed_images(image_paths, transform, n=3):
    # Plots a series of random images from image_paths.
    # Will open n image paths from image_paths, transform them
    # with transform and plot them side by side.
    random.seed(42)
    random_image_paths = random.sample(image_paths, k=n)
    for image_path in random_image_paths:
        with Image.open(image_path) as f:
            fig, ax = plt.subplots(1, 2)
            ax[0].imshow(f) 
            ax[0].set_title(f""Original \nSize: {f.size}"")
            ax[0].axis(""off"")

            # Transform and plot image
            # Note: permute() will change shape of image to suit matplotlib 
            # (PyTorch default is [C, H, W] but Matplotlib is [H, W, C])
            transformed_image = transform(f).permute(1, 2, 0) 
            ax[1].imshow(transformed_image) 
            ax[1].set_title(f""Transformed \nSize: {transformed_image.shape}"")
            ax[1].axis(""off"")

            fig.suptitle(f""Class: {image_path.parent.stem}"", fontsize=16)
            # fig.show()
            plt.show(block=False)

plot_transformed_images(image_path_list_test, transform=data_transform, n=3)",
183,2,https://www.google.com/search?q=fig+show+closed+on+its+own&rlz=1C1SQJL_enUS958US958&oq=fig+show+close&aqs=chrome.3.69i57j33i160j33i160i395l2j33i22i29i30i395l6.4876j1j4&sourceid=chrome&ie=UTF-8,14131,screencapture-n121_2022-10-27-23_58_51.png,,search: fig show closed on its own;,,
184,2,https://stackoverflow.com/questions/40395659/view-and-then-close-the-figure-automatically-in-matplotlib,14132,screencapture-n122_2022-10-27-23_58_52.png,,visit: python - view and then close the figure automatically in matplotlib? - Stack Overflow;,,
185,2,,14194,,,code: main.py;,"# from PIL import Image
  
# im = Image.open(r""C:\Users\thien\Desktop\project\dat\Garbage classification\Garbage classification\glass\glass11.jpg"")
# im.show() 

from genericpath import exists
import math
import os
garbage_classification_folder = r""C:\Users\thien\Desktop\project\dat\Garbage classification\Garbage classification""

from pathlib import Path

# Setup path to data folder
data_path = Path(garbage_classification_folder)
image_path = data_path / ""cardboard""

def walk_through_dir(dir_path):
    no_of_files = 0
    for dirpath, dirnames, filenames in os.walk(dir_path):
        # print(f""There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'."")
        no_of_files = len(filenames)
    return no_of_files

import random
from PIL import Image

def allUnique(x):
    seen = list()
    return not any(i in seen or seen.append(i) for i in x)

# pass in the img dir path (eg. ./cardboard)
def get_random_img_list(dir_path, N):
    # Set seed
    random.seed(42)

    # 1. Get all image paths (* means ""any combination"")
    image_path_list = list(dir_path.glob(""*.jpg""))

    # converting the list into a set
    # image_path_set = set(image_path_list)

    # 2. Get random image path
    image_list_train = random.sample(image_path_list, k = N)

    s = set(image_list_train)
    image_list_test = [x for x in image_path_list if x not in s]

    return image_list_train, image_list_test

def flatten(l):
    return [item for sublist in l for item in sublist]

import shutil
def make_train_test_folder(dir_path):
    train_folder = dir_path / ""train""
    test_folder = dir_path / ""test""
    if os.path.exists(train_folder):
        shutil.rmtree(train_folder)
    if os.path.exists(test_folder):
        shutil.rmtree(test_folder)
    
    if not os.path.exists(train_folder) and not os.path.exists(test_folder):
        # we need to select random images from all img folders and build up our train set
        training_dataset = []
        testing_dataset = []
        collection = [""cardboard"", ""glass"", ""metal"", ""paper"", ""plastic"", ""trash""]
        for el in collection:
            el_path = dir_path / el
            no_of_imgs = walk_through_dir(el_path)

            # grab 80% of imgs for training
            training_amount = math.floor(0.8 * no_of_imgs)
            training_dat, testing_dat = get_random_img_list(el_path, training_amount)
            
            training_dataset.append(training_dat)
            testing_dataset.append(testing_dat)

        training_dataset = flatten(training_dataset)
        testing_dataset = flatten(testing_dataset)
        
        os.mkdir(train_folder)
        os.mkdir(test_folder)
        for train_img_path in training_dataset:
            shutil.copy2(src=train_img_path, dst=train_folder)
        
        for test_img_path in testing_dataset:
            shutil.copy2(src=test_img_path, dst=test_folder)

# make_train_test_folder(data_path)

import torch
from torch.utils.data import DataLoader
from torchvision import datasets, transforms

train_dir = data_path / ""train""
test_dir = data_path / ""test""

# Write transform for image
data_transform = transforms.Compose([
    # Resize the images to 128x128
    transforms.Resize(size=(128, 128)),
    # Turn the image into a torch.Tensor
    transforms.ToTensor() # this also converts all pixel values from 0 to 255 to be between 0.0 and 1.0 
])

image_path_list_test = list(train_dir.glob(""*.jpg""))
random_image_path_test = random.choice(image_path_list_test)

import matplotlib.pyplot as plt

def plot_transformed_images(image_paths, transform, n=3):
    # Plots a series of random images from image_paths.
    # Will open n image paths from image_paths, transform them
    # with transform and plot them side by side.
    random.seed(42)
    random_image_paths = random.sample(image_paths, k=n)
    for image_path in random_image_paths:
        with Image.open(image_path) as f:
            fig, ax = plt.subplots(1, 2)
            ax[0].imshow(f) 
            ax[0].set_title(f""Original \nSize: {f.size}"")
            ax[0].axis(""off"")

            # Transform and plot image
            # Note: permute() will change shape of image to suit matplotlib 
            # (PyTorch default is [C, H, W] but Matplotlib is [H, W, C])
            transformed_image = transform(f).permute(1, 2, 0) 
            ax[1].imshow(transformed_image) 
            ax[1].set_title(f""Transformed \nSize: {transformed_image.shape}"")
            ax[1].axis(""off"")

            fig.suptitle(f""Class: {image_path.parent.stem}"", fontsize=16)
            # fig.show()
            plt.show(block=False)
            plt.pause(5)
            plt.close()

plot_transformed_images(image_path_list_test, transform=data_transform, n=3)",
186,2,,14311,,,code: main.py;,"# from PIL import Image
  
# im = Image.open(r""C:\Users\thien\Desktop\project\dat\Garbage classification\Garbage classification\glass\glass11.jpg"")
# im.show() 

from genericpath import exists
import math
import os
garbage_classification_folder = r""C:\Users\thien\Desktop\project\dat\Garbage classification\Garbage classification""

from pathlib import Path

# Setup path to data folder
data_path = Path(garbage_classification_folder)
image_path = data_path / ""cardboard""

def walk_through_dir(dir_path):
    no_of_files = 0
    for dirpath, dirnames, filenames in os.walk(dir_path):
        # print(f""There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'."")
        no_of_files = len(filenames)
    return no_of_files

import random
from PIL import Image

def allUnique(x):
    seen = list()
    return not any(i in seen or seen.append(i) for i in x)

# pass in the img dir path (eg. ./cardboard)
def get_random_img_list(dir_path, N):
    # Set seed
    random.seed(42)

    # 1. Get all image paths (* means ""any combination"")
    image_path_list = list(dir_path.glob(""*.jpg""))

    # converting the list into a set
    # image_path_set = set(image_path_list)

    # 2. Get random image path
    image_list_train = random.sample(image_path_list, k = N)

    s = set(image_list_train)
    image_list_test = [x for x in image_path_list if x not in s]

    return image_list_train, image_list_test

def flatten(l):
    return [item for sublist in l for item in sublist]

import shutil
def make_train_test_folder(dir_path):
    train_folder = dir_path / ""train""
    test_folder = dir_path / ""test""
    if os.path.exists(train_folder):
        shutil.rmtree(train_folder)
    if os.path.exists(test_folder):
        shutil.rmtree(test_folder)
    
    if not os.path.exists(train_folder) and not os.path.exists(test_folder):
        # we need to select random images from all img folders and build up our train set
        training_dataset = []
        testing_dataset = []
        collection = [""cardboard"", ""glass"", ""metal"", ""paper"", ""plastic"", ""trash""]
        for el in collection:
            el_path = dir_path / el
            no_of_imgs = walk_through_dir(el_path)

            # grab 80% of imgs for training
            training_amount = math.floor(0.8 * no_of_imgs)
            training_dat, testing_dat = get_random_img_list(el_path, training_amount)
            
            training_dataset.append(training_dat)
            testing_dataset.append(testing_dat)

        training_dataset = flatten(training_dataset)
        testing_dataset = flatten(testing_dataset)
        
        os.mkdir(train_folder)
        os.mkdir(test_folder)
        for train_img_path in training_dataset:
            shutil.copy2(src=train_img_path, dst=train_folder)
        
        for test_img_path in testing_dataset:
            shutil.copy2(src=test_img_path, dst=test_folder)

# make_train_test_folder(data_path)

import torch
from torch.utils.data import DataLoader
from torchvision import datasets, transforms

train_dir = data_path / ""train""
test_dir = data_path / ""test""

# Write transform for image
data_transform = transforms.Compose([
    # Resize the images to 128x128
    transforms.Resize(size=(128, 128)),
    # Turn the image into a torch.Tensor
    transforms.ToTensor() # this also converts all pixel values from 0 to 255 to be between 0.0 and 1.0 
])

image_path_list_test = list(train_dir.glob(""*.jpg""))
random_image_path_test = random.choice(image_path_list_test)

import matplotlib.pyplot as plt

def plot_transformed_images(image_paths, transform, n):
    # Plots a series of random images from image_paths.
    # Will open n image paths from image_paths, transform them
    # with transform and plot them side by side.
    random.seed(42)
    random_image_paths = random.sample(image_paths, k=n)
    for image_path in random_image_paths:
        with Image.open(image_path) as f:
            fig, ax = plt.subplots(1, 2)
            ax[0].imshow(f) 
            ax[0].set_title(f""Original \nSize: {f.size}"")
            ax[0].axis(""off"")

            # Transform and plot image
            # Note: permute() will change shape of image to suit matplotlib 
            # (PyTorch default is [C, H, W] but Matplotlib is [H, W, C])
            transformed_image = transform(f).permute(1, 2, 0) 
            ax[1].imshow(transformed_image) 
            ax[1].set_title(f""Transformed \nSize: {transformed_image.shape}"")
            ax[1].axis(""off"")

            fig.suptitle(f""Class: {image_path.parent.stem}"", fontsize=16)
            plt.show(block=False)
            plt.pause(10)
            plt.close()

plot_transformed_images(image_path_list_test, transform=data_transform, n=1)",
187,2,https://www.google.com/search?q=windows+path+strip+image+name&rlz=1C1SQJL_enUS958US958&oq=windows+path+strip+image+name&aqs=chrome..69i57j33i160.17194j1j4&sourceid=chrome&ie=UTF-8,14430,screencapture-n123_2022-10-28-00_03_50.png,,search: windows path strip image name;,,
188,2,https://stackoverflow.com/questions/59791829/how-to-remove-filename-from-path-in-windows-file-filter-driver,14435,screencapture-n124_2022-10-28-00_03_55.png,,visit: c - How to remove filename from path in Windows File Filter Driver? - Stack Overflow;,,
190,2,https://www.google.com/search?q=how+to+grab+a+file+name+from+a+pil+image+path&rlz=1C1SQJL_enUS958US958&oq=how+to+grab+a+file+name+from+a+pil+ima&aqs=chrome.3.69i57j33i160j33i160i395l3.7645j1j9&sourceid=chrome&ie=UTF-8,14552,screencapture-n126_2022-10-28-00_05_52.png,,search: how to grab a file name from a pil image path;,,
191,2,https://stackoverflow.com/questions/8384737/extract-file-name-from-path-no-matter-what-the-os-path-format,14553,screencapture-n127_2022-10-28-00_05_53.png,,"visit: python - Extract file name from path, no matter what the os/path format - Stack Overflow;",,
192,2,,14637,,,code: main.py;,"# from PIL import Image
  
# im = Image.open(r""C:\Users\thien\Desktop\project\dat\Garbage classification\Garbage classification\glass\glass11.jpg"")
# im.show() 

from genericpath import exists
import math
import os
garbage_classification_folder = r""C:\Users\thien\Desktop\project\dat\Garbage classification\Garbage classification""

from pathlib import Path

# Setup path to data folder
data_path = Path(garbage_classification_folder)
image_path = data_path / ""cardboard""

def walk_through_dir(dir_path):
    no_of_files = 0
    for dirpath, dirnames, filenames in os.walk(dir_path):
        # print(f""There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'."")
        no_of_files = len(filenames)
    return no_of_files

import random
from PIL import Image

def allUnique(x):
    seen = list()
    return not any(i in seen or seen.append(i) for i in x)

# pass in the img dir path (eg. ./cardboard)
def get_random_img_list(dir_path, N):
    # Set seed
    random.seed(42)

    # 1. Get all image paths (* means ""any combination"")
    image_path_list = list(dir_path.glob(""*.jpg""))

    # converting the list into a set
    # image_path_set = set(image_path_list)

    # 2. Get random image path
    image_list_train = random.sample(image_path_list, k = N)

    s = set(image_list_train)
    image_list_test = [x for x in image_path_list if x not in s]

    return image_list_train, image_list_test

def flatten(l):
    return [item for sublist in l for item in sublist]

import shutil
def make_train_test_folder(dir_path):
    train_folder = dir_path / ""train""
    test_folder = dir_path / ""test""
    if os.path.exists(train_folder):
        shutil.rmtree(train_folder)
    if os.path.exists(test_folder):
        shutil.rmtree(test_folder)
    
    if not os.path.exists(train_folder) and not os.path.exists(test_folder):
        # we need to select random images from all img folders and build up our train set
        training_dataset = []
        testing_dataset = []
        collection = [""cardboard"", ""glass"", ""metal"", ""paper"", ""plastic"", ""trash""]
        for el in collection:
            el_path = dir_path / el
            no_of_imgs = walk_through_dir(el_path)

            # grab 80% of imgs for training
            training_amount = math.floor(0.8 * no_of_imgs)
            training_dat, testing_dat = get_random_img_list(el_path, training_amount)
            
            training_dataset.append(training_dat)
            testing_dataset.append(testing_dat)

        training_dataset = flatten(training_dataset)
        testing_dataset = flatten(testing_dataset)
        
        os.mkdir(train_folder)
        os.mkdir(test_folder)
        for train_img_path in training_dataset:
            shutil.copy2(src=train_img_path, dst=train_folder)
        
        for test_img_path in testing_dataset:
            shutil.copy2(src=test_img_path, dst=test_folder)

# make_train_test_folder(data_path)

import torch
from torch.utils.data import DataLoader
from torchvision import datasets, transforms

train_dir = data_path / ""train""
test_dir = data_path / ""test""

# Write transform for image
data_transform = transforms.Compose([
    # Resize the images to 128x128
    transforms.Resize(size=(128, 128)),
    # Turn the image into a torch.Tensor
    transforms.ToTensor() # this also converts all pixel values from 0 to 255 to be between 0.0 and 1.0 
])

image_path_list_test = list(train_dir.glob(""*.jpg""))
random_image_path_test = random.choice(image_path_list_test)

import matplotlib.pyplot as plt

def plot_transformed_images(image_paths, transform, n):
    # Plots a series of random images from image_paths.
    # Will open n image paths from image_paths, transform them
    # with transform and plot them side by side.
    random.seed(42)
    random_image_paths = random.sample(image_paths, k=n)
    for image_path in random_image_paths:
        with Image.open(image_path) as f:
            fig, ax = plt.subplots(1, 2)
            ax[0].imshow(f) 
            ax[0].set_title(f""Original \nSize: {f.size}"")
            ax[0].axis(""off"")

            # Transform and plot image
            # Note: permute() will change shape of image to suit matplotlib 
            # (PyTorch default is [C, H, W] but Matplotlib is [H, W, C])
            transformed_image = transform(f).permute(1, 2, 0) 
            ax[1].imshow(transformed_image) 
            ax[1].set_title(f""Transformed \nSize: {transformed_image.shape}"")
            ax[1].axis(""off"")

            fig.suptitle(f""Class: {Path(image_path).name}"", fontsize=16)
            plt.show(block=False)
            plt.pause(10)
            plt.close()

plot_transformed_images(image_path_list_test, transform=data_transform, n=1)",
193,2,https://www.learnpytorch.io/04_pytorch_custom_datasets/,14704,screencapture-n128_2022-10-28-00_08_24.png,,revisit: 04. PyTorch Custom Datasets - Zero to Mastery Learn PyTorch for Deep Learning;,,
194,2,https://www.google.com/search?q=torchvision.datasets.ImageFolder&rlz=1C1SQJL_enUS958US958&oq=torchvision.datasets.ImageFolder&aqs=chrome..69i57j0i512l5j0i30l4.239j0j7&sourceid=chrome&ie=UTF-8,14828,screencapture-n129_2022-10-28-00_10_28.png,,search: torchvision.datasets.ImageFolder;,,
195,2,https://pytorch.org/vision/stable/generated/torchvision.datasets.ImageFolder.html,14832,screencapture-n130_2022-10-28-00_10_32.png,,visit: ImageFolder â€” Torchvision main documentation;,,
196,2,https://www.learnpytorch.io/04_pytorch_custom_datasets/#4-option-1-loading-image-data-using-imagefolder,14899,screencapture-n131_2022-10-28-00_11_39.png,,revisit: 04. PyTorch Custom Datasets - Zero to Mastery Learn PyTorch for Deep Learning;,,
197,2,https://pytorch.org/vision/stable/generated/torchvision.datasets.ImageFolder.html,15058,screencapture-n132_2022-10-28-00_14_18.png,,revisit: ImageFolder â€” Torchvision main documentation;,,
198,2,,15201,,,code: main.py;,"# from PIL import Image
  
# im = Image.open(r""C:\Users\thien\Desktop\project\dat\Garbage classification\Garbage classification\glass\glass11.jpg"")
# im.show() 

from genericpath import exists
import math
import os
garbage_classification_folder = r""C:\Users\thien\Desktop\project\dat\Garbage classification\Garbage classification""

from pathlib import Path

# Setup path to data folder
data_path = Path(garbage_classification_folder)
image_path = data_path / ""cardboard""

def walk_through_dir(dir_path):
    no_of_files = 0
    for dirpath, dirnames, filenames in os.walk(dir_path):
        # print(f""There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'."")
        no_of_files = len(filenames)
    return no_of_files

import random
from PIL import Image

def allUnique(x):
    seen = list()
    return not any(i in seen or seen.append(i) for i in x)

# pass in the img dir path (eg. ./cardboard)
def get_random_img_list(dir_path, N):
    # Set seed
    random.seed(42)

    # 1. Get all image paths (* means ""any combination"")
    image_path_list = list(dir_path.glob(""*.jpg""))

    # converting the list into a set
    # image_path_set = set(image_path_list)

    # 2. Get random image path
    image_list_train = random.sample(image_path_list, k = N)

    s = set(image_list_train)
    image_list_test = [x for x in image_path_list if x not in s]

    return image_list_train, image_list_test

def flatten(l):
    return [item for sublist in l for item in sublist]

import shutil
def make_train_test_folder(dir_path):
    train_folder = dir_path / ""train""
    test_folder = dir_path / ""test""
    if os.path.exists(train_folder):
        shutil.rmtree(train_folder)
    if os.path.exists(test_folder):
        shutil.rmtree(test_folder)
    
    if not os.path.exists(train_folder) and not os.path.exists(test_folder):
        # we need to select random images from all img folders and build up our train set
        training_dataset = []
        testing_dataset = []
        collection = [""cardboard"", ""glass"", ""metal"", ""paper"", ""plastic"", ""trash""]
        for el in collection:
            el_path = dir_path / el
            no_of_imgs = walk_through_dir(el_path)

            # grab 80% of imgs for training
            training_amount = math.floor(0.8 * no_of_imgs)
            training_dat, testing_dat = get_random_img_list(el_path, training_amount)
            
            training_dataset.append(training_dat)
            testing_dataset.append(testing_dat)

        training_dataset = flatten(training_dataset)
        testing_dataset = flatten(testing_dataset)
        
        os.mkdir(train_folder)
        os.mkdir(test_folder)
        for train_img_path in training_dataset:
            shutil.copy2(src=train_img_path, dst=train_folder)
        
        for test_img_path in testing_dataset:
            shutil.copy2(src=test_img_path, dst=test_folder)

# make_train_test_folder(data_path)

import torch
from torch.utils.data import DataLoader
from torchvision import datasets, transforms

train_dir = data_path / ""train""
test_dir = data_path / ""test""

# Write transform for image
data_transform = transforms.Compose([
    # Resize the images to 128x128
    transforms.Resize(size=(128, 128)),
    # Turn the image into a torch.Tensor
    transforms.ToTensor() # this also converts all pixel values from 0 to 255 to be between 0.0 and 1.0 
])

image_path_list_test = list(train_dir.glob(""*.jpg""))
random_image_path_test = random.choice(image_path_list_test)

import matplotlib.pyplot as plt

def plot_transformed_images(image_paths, transform, n):
    # Plots a series of random images from image_paths.
    # Will open n image paths from image_paths, transform them
    # with transform and plot them side by side.
    random.seed(42)
    random_image_paths = random.sample(image_paths, k=n)
    for image_path in random_image_paths:
        with Image.open(image_path) as f:
            fig, ax = plt.subplots(1, 2)
            ax[0].imshow(f) 
            ax[0].set_title(f""Original \nSize: {f.size}"")
            ax[0].axis(""off"")

            # Transform and plot image
            # Note: permute() will change shape of image to suit matplotlib 
            # (PyTorch default is [C, H, W] but Matplotlib is [H, W, C])
            transformed_image = transform(f).permute(1, 2, 0) 
            ax[1].imshow(transformed_image) 
            ax[1].set_title(f""Transformed \nSize: {transformed_image.shape}"")
            ax[1].axis(""off"")

            fig.suptitle(f""Class: {Path(image_path).name}"", fontsize=16)
            plt.show(block=False)
            plt.pause(10)
            plt.close()

# plot_transformed_images(image_path_list_test, transform=data_transform, n=1)

# Use ImageFolder to create dataset(s)
from torchvision import datasets
train_data = datasets.ImageFolder(root=train_dir, # target folder of images
                                  transform=data_transform, # transforms to perform on data (images)
                                  target_transform=None) # transforms to perform on labels (if necessary)

test_data = datasets.ImageFolder(root=test_dir, 
                                 transform=data_transform)

print(f""Train data:\n{train_data}\nTest data:\n{test_data}"")",
199,2,,15201,,,output: output.txt;,"c:/Users/thien/Desktop/project/venv/Scripts/python.exe c:/Users/thien/Desktop/project/main.py
Traceback (most recent call last):
  File ""c:/Users/thien/Desktop/project/main.py"", line 141, in <module>
    train_data = datasets.ImageFolder(root=train_dir, # target folder of images
  File ""C:\Users\thien\Desktop\project\venv\lib\site-packages\torchvision\datasets\folder.py"", line 310, in __init__
    super().__init__(
  File ""C:\Users\thien\Desktop\project\venv\lib\site-packages\torchvision\datasets\folder.py"", line 145, in __init__
    classes, class_to_idx = self.find_classes(self.root)
  File ""C:\Users\thien\Desktop\project\venv\lib\site-packages\torchvision\datasets\folder.py"", line 219, in find_classes
    return find_classes(directory)
  File ""C:\Users\thien\Desktop\project\venv\lib\site-packages\torchvision\datasets\folder.py"", line 43, in find_classes
    raise FileNotFoundError(f""Couldn't find any class folder in {directory}."")
FileNotFoundError: Couldn't find any class folder in C:\Users\thien\Desktop\project\dat\Garbage classification\Garbage classification\train.
(venv)",
200,2,https://www.learnpytorch.io/04_pytorch_custom_datasets/#41-turn-loaded-images-into-dataloaders,15220,screencapture-n133_2022-10-28-00_17_00.png,,revisit: 04. PyTorch Custom Datasets - Zero to Mastery Learn PyTorch for Deep Learning;,,
201,2,,15569,,,code: main.py;,"# from PIL import Image
  
# im = Image.open(r""C:\Users\thien\Desktop\project\dat\Garbage classification\Garbage classification\glass\glass11.jpg"")
# im.show() 

from genericpath import exists
import math
import os
garbage_classification_folder = r""C:\Users\thien\Desktop\project\dat\Garbage classification\Garbage classification""

from pathlib import Path

# Setup path to data folder
data_path = Path(garbage_classification_folder)
image_path = data_path / ""cardboard""

def walk_through_dir(dir_path):
    no_of_files = 0
    for dirpath, dirnames, filenames in os.walk(dir_path):
        # print(f""There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'."")
        no_of_files = len(filenames)
    return no_of_files

import random
from PIL import Image

def allUnique(x):
    seen = list()
    return not any(i in seen or seen.append(i) for i in x)

# pass in the img dir path (eg. ./cardboard)
def get_random_img_list(dir_path, N):
    # Set seed
    random.seed(42)

    # 1. Get all image paths (* means ""any combination"")
    image_path_list = list(dir_path.glob(""*.jpg""))

    # converting the list into a set
    # image_path_set = set(image_path_list)

    # 2. Get random image path
    image_list_train = random.sample(image_path_list, k = N)

    s = set(image_list_train)
    image_list_test = [x for x in image_path_list if x not in s]

    return image_list_train, image_list_test

def flatten(l):
    return [item for sublist in l for item in sublist]

import shutil
def make_train_test_folder(dir_path):
    train_folder = dir_path / ""train""
    test_folder = dir_path / ""test""
    if os.path.exists(train_folder):
        shutil.rmtree(train_folder)
    if os.path.exists(test_folder):
        shutil.rmtree(test_folder)
    
    if not os.path.exists(train_folder) and not os.path.exists(test_folder):
        os.mkdir(train_folder)
        os.mkdir(test_folder)
        # we need to select random images from all img folders and build up our train set
        collection = [""cardboard"", ""glass"", ""metal"", ""paper"", ""plastic"", ""trash""]
        for el in collection:
            el_path = dir_path / el
            no_of_imgs = walk_through_dir(el_path)

            # grab 80% of imgs for training
            training_amount = math.floor(0.8 * no_of_imgs)
            training_dat, testing_dat = get_random_img_list(el_path, training_amount)

            for train_img_path in training_dat:
                shutil.copy2(src=train_img_path, dst=train_folder / el)
            
            for test_img_path in testing_dat:
                shutil.copy2(src=test_img_path, dst=test_folder / el)

# make_train_test_folder(data_path)

import torch
from torch.utils.data import DataLoader
from torchvision import datasets, transforms

train_dir = data_path / ""train""
test_dir = data_path / ""test""

# Write transform for image
data_transform = transforms.Compose([
    # Resize the images to 128x128
    transforms.Resize(size=(128, 128)),
    # Turn the image into a torch.Tensor
    transforms.ToTensor() # this also converts all pixel values from 0 to 255 to be between 0.0 and 1.0 
])

image_path_list_test = list(train_dir.glob(""*.jpg""))
random_image_path_test = random.choice(image_path_list_test)

import matplotlib.pyplot as plt

def plot_transformed_images(image_paths, transform, n):
    # Plots a series of random images from image_paths.
    # Will open n image paths from image_paths, transform them
    # with transform and plot them side by side.
    random.seed(42)
    random_image_paths = random.sample(image_paths, k=n)
    for image_path in random_image_paths:
        with Image.open(image_path) as f:
            fig, ax = plt.subplots(1, 2)
            ax[0].imshow(f) 
            ax[0].set_title(f""Original \nSize: {f.size}"")
            ax[0].axis(""off"")

            # Transform and plot image
            # Note: permute() will change shape of image to suit matplotlib 
            # (PyTorch default is [C, H, W] but Matplotlib is [H, W, C])
            transformed_image = transform(f).permute(1, 2, 0) 
            ax[1].imshow(transformed_image) 
            ax[1].set_title(f""Transformed \nSize: {transformed_image.shape}"")
            ax[1].axis(""off"")

            fig.suptitle(f""Class: {Path(image_path).name}"", fontsize=16)
            plt.show(block=False)
            plt.pause(10)
            plt.close()

# plot_transformed_images(image_path_list_test, transform=data_transform, n=1)

# Use ImageFolder to create dataset(s)
from torchvision import datasets
train_data = datasets.ImageFolder(root=train_dir, # target folder of images
                                  transform=data_transform, # transforms to perform on data (images)
                                  target_transform=None) # transforms to perform on labels (if necessary)

test_data = datasets.ImageFolder(root=test_dir, 
                                 transform=data_transform)

print(f""Train data:\n{train_data}\nTest data:\n{test_data}"")",
202,2,,15569,,,output: output.txt;,"c:/Users/thien/Desktop/project/venv/Scripts/python.exe c:/Users/thien/Desktop/project/main.py
Traceback (most recent call last):
  File ""c:/Users/thien/Desktop/project/main.py"", line 133, in <module>
    train_data = datasets.ImageFolder(root=train_dir, # target folder of images
  File ""C:\Users\thien\Desktop\project\venv\lib\site-packages\torchvision\datasets\folder.py"", line 310, in __init__
    super().__init__(
  File ""C:\Users\thien\Desktop\project\venv\lib\site-packages\torchvision\datasets\folder.py"", line 145, in __init__
    classes, class_to_idx = self.find_classes(self.root)
  File ""C:\Users\thien\Desktop\project\venv\lib\site-packages\torchvision\datasets\folder.py"", line 219, in find_classes
    return find_classes(directory)
  File ""C:\Users\thien\Desktop\project\venv\lib\site-packages\torchvision\datasets\folder.py"", line 43, in find_classes
    raise FileNotFoundError(f""Couldn't find any class folder in {directory}."")
FileNotFoundError: Couldn't find any class folder in C:\Users\thien\Desktop\project\dat\Garbage classification\Garbage classification\train.
(venv)",
203,2,,15661,,,code: main.py;,"# from PIL import Image
  
# im = Image.open(r""C:\Users\thien\Desktop\project\dat\Garbage classification\Garbage classification\glass\glass11.jpg"")
# im.show() 

from genericpath import exists
import math
import os
garbage_classification_folder = r""C:\Users\thien\Desktop\project\dat\Garbage classification\Garbage classification""

from pathlib import Path

# Setup path to data folder
data_path = Path(garbage_classification_folder)
image_path = data_path / ""cardboard""

def walk_through_dir(dir_path):
    no_of_files = 0
    for dirpath, dirnames, filenames in os.walk(dir_path):
        # print(f""There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'."")
        no_of_files = len(filenames)
    return no_of_files

import random
from PIL import Image

def allUnique(x):
    seen = list()
    return not any(i in seen or seen.append(i) for i in x)

# pass in the img dir path (eg. ./cardboard)
def get_random_img_list(dir_path, N):
    # Set seed
    random.seed(42)

    # 1. Get all image paths (* means ""any combination"")
    image_path_list = list(dir_path.glob(""*.jpg""))

    # converting the list into a set
    # image_path_set = set(image_path_list)

    # 2. Get random image path
    image_list_train = random.sample(image_path_list, k = N)

    s = set(image_list_train)
    image_list_test = [x for x in image_path_list if x not in s]

    return image_list_train, image_list_test

def flatten(l):
    return [item for sublist in l for item in sublist]

import shutil
def make_train_test_folder(dir_path):
    train_folder = dir_path / ""train""
    test_folder = dir_path / ""test""
    if os.path.exists(train_folder):
        shutil.rmtree(train_folder)
    if os.path.exists(test_folder):
        shutil.rmtree(test_folder)
    
    if not os.path.exists(train_folder) and not os.path.exists(test_folder):
        # we need to select random images from all img folders and build up our train set
        collection = [""cardboard"", ""glass"", ""metal"", ""paper"", ""plastic"", ""trash""]
        for el in collection:
            el_path = dir_path / el
            no_of_imgs = walk_through_dir(el_path)

            # grab 80% of imgs for training
            training_amount = math.floor(0.8 * no_of_imgs)
            training_dat, testing_dat = get_random_img_list(el_path, training_amount)

            os.mkdir(train_folder / el)
            os.mkdir(test_folder / el)

            for train_img_path in training_dat:
                shutil.copy2(src=train_img_path, dst=train_folder / el)
            
            for test_img_path in testing_dat:
                shutil.copy2(src=test_img_path, dst=test_folder / el)

# make_train_test_folder(data_path)

import torch
from torch.utils.data import DataLoader
from torchvision import datasets, transforms

train_dir = data_path / ""train""
test_dir = data_path / ""test""

# Write transform for image
data_transform = transforms.Compose([
    # Resize the images to 128x128
    transforms.Resize(size=(128, 128)),
    # Turn the image into a torch.Tensor
    transforms.ToTensor() # this also converts all pixel values from 0 to 255 to be between 0.0 and 1.0 
])

image_path_list_test = list(train_dir.glob(""*.jpg""))
random_image_path_test = random.choice(image_path_list_test)

import matplotlib.pyplot as plt

def plot_transformed_images(image_paths, transform, n):
    # Plots a series of random images from image_paths.
    # Will open n image paths from image_paths, transform them
    # with transform and plot them side by side.
    random.seed(42)
    random_image_paths = random.sample(image_paths, k=n)
    for image_path in random_image_paths:
        with Image.open(image_path) as f:
            fig, ax = plt.subplots(1, 2)
            ax[0].imshow(f) 
            ax[0].set_title(f""Original \nSize: {f.size}"")
            ax[0].axis(""off"")

            # Transform and plot image
            # Note: permute() will change shape of image to suit matplotlib 
            # (PyTorch default is [C, H, W] but Matplotlib is [H, W, C])
            transformed_image = transform(f).permute(1, 2, 0) 
            ax[1].imshow(transformed_image) 
            ax[1].set_title(f""Transformed \nSize: {transformed_image.shape}"")
            ax[1].axis(""off"")

            fig.suptitle(f""Class: {Path(image_path).name}"", fontsize=16)
            plt.show(block=False)
            plt.pause(10)
            plt.close()

# plot_transformed_images(image_path_list_test, transform=data_transform, n=1)

# Use ImageFolder to create dataset(s)
from torchvision import datasets
train_data = datasets.ImageFolder(root=train_dir, # target folder of images
                                  transform=data_transform, # transforms to perform on data (images)
                                  target_transform=None) # transforms to perform on labels (if necessary)

test_data = datasets.ImageFolder(root=test_dir, 
                                 transform=data_transform)

print(f""Train data:\n{train_data}\nTest data:\n{test_data}"")",
204,2,,15661,,,output: output.txt;,"c:/Users/thien/Desktop/project/venv/Scripts/python.exe c:/Users/thien/Desktop/project/main.py
Traceback (most recent call last):
  File ""c:/Users/thien/Desktop/project/main.py"", line 134, in <module>
    train_data = datasets.ImageFolder(root=train_dir, # target folder of images
  File ""C:\Users\thien\Desktop\project\venv\lib\site-packages\torchvision\datasets\folder.py"", line 310, in __init__
    super().__init__(
  File ""C:\Users\thien\Desktop\project\venv\lib\site-packages\torchvision\datasets\folder.py"", line 145, in __init__
    classes, class_to_idx = self.find_classes(self.root)
  File ""C:\Users\thien\Desktop\project\venv\lib\site-packages\torchvision\datasets\folder.py"", line 219, in find_classes
    return find_classes(directory)
  File ""C:\Users\thien\Desktop\project\venv\lib\site-packages\torchvision\datasets\folder.py"", line 43, in find_classes
    raise FileNotFoundError(f""Couldn't find any class folder in {directory}."")
FileNotFoundError: Couldn't find any class folder in C:\Users\thien\Desktop\project\dat\Garbage classification\Garbage classification\train.
(venv)",
205,2,,15697,,,code: main.py;,"# from PIL import Image
  
# im = Image.open(r""C:\Users\thien\Desktop\project\dat\Garbage classification\Garbage classification\glass\glass11.jpg"")
# im.show() 

from genericpath import exists
import math
import os
garbage_classification_folder = r""C:\Users\thien\Desktop\project\dat\Garbage classification\Garbage classification""

from pathlib import Path

# Setup path to data folder
data_path = Path(garbage_classification_folder)
image_path = data_path / ""cardboard""

def walk_through_dir(dir_path):
    no_of_files = 0
    for dirpath, dirnames, filenames in os.walk(dir_path):
        # print(f""There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'."")
        no_of_files = len(filenames)
    return no_of_files

import random
from PIL import Image

def allUnique(x):
    seen = list()
    return not any(i in seen or seen.append(i) for i in x)

# pass in the img dir path (eg. ./cardboard)
def get_random_img_list(dir_path, N):
    # Set seed
    random.seed(42)

    # 1. Get all image paths (* means ""any combination"")
    image_path_list = list(dir_path.glob(""*.jpg""))

    # converting the list into a set
    # image_path_set = set(image_path_list)

    # 2. Get random image path
    image_list_train = random.sample(image_path_list, k = N)

    s = set(image_list_train)
    image_list_test = [x for x in image_path_list if x not in s]

    return image_list_train, image_list_test

def flatten(l):
    return [item for sublist in l for item in sublist]

import shutil
def make_train_test_folder(dir_path):
    train_folder = dir_path / ""train""
    test_folder = dir_path / ""test""
    if os.path.exists(train_folder):
        shutil.rmtree(train_folder)
    if os.path.exists(test_folder):
        shutil.rmtree(test_folder)
    
    if not os.path.exists(train_folder) and not os.path.exists(test_folder):
        # we need to select random images from all img folders and build up our train set
        collection = [""cardboard"", ""glass"", ""metal"", ""paper"", ""plastic"", ""trash""]
        for el in collection:
            el_path = dir_path / el
            no_of_imgs = walk_through_dir(el_path)

            # grab 80% of imgs for training
            training_amount = math.floor(0.8 * no_of_imgs)
            training_dat, testing_dat = get_random_img_list(el_path, training_amount)

            os.mkdir(train_folder / el)
            os.mkdir(test_folder / el)

            for train_img_path in training_dat:
                shutil.copy2(src=train_img_path, dst=train_folder / el)
            
            for test_img_path in testing_dat:
                shutil.copy2(src=test_img_path, dst=test_folder / el)

make_train_test_folder(data_path)

import torch
from torch.utils.data import DataLoader
from torchvision import datasets, transforms

train_dir = data_path / ""train""
test_dir = data_path / ""test""

# Write transform for image
data_transform = transforms.Compose([
    # Resize the images to 128x128
    transforms.Resize(size=(128, 128)),
    # Turn the image into a torch.Tensor
    transforms.ToTensor() # this also converts all pixel values from 0 to 255 to be between 0.0 and 1.0 
])

image_path_list_test = list(train_dir.glob(""*.jpg""))
random_image_path_test = random.choice(image_path_list_test)

import matplotlib.pyplot as plt

def plot_transformed_images(image_paths, transform, n):
    # Plots a series of random images from image_paths.
    # Will open n image paths from image_paths, transform them
    # with transform and plot them side by side.
    random.seed(42)
    random_image_paths = random.sample(image_paths, k=n)
    for image_path in random_image_paths:
        with Image.open(image_path) as f:
            fig, ax = plt.subplots(1, 2)
            ax[0].imshow(f) 
            ax[0].set_title(f""Original \nSize: {f.size}"")
            ax[0].axis(""off"")

            # Transform and plot image
            # Note: permute() will change shape of image to suit matplotlib 
            # (PyTorch default is [C, H, W] but Matplotlib is [H, W, C])
            transformed_image = transform(f).permute(1, 2, 0) 
            ax[1].imshow(transformed_image) 
            ax[1].set_title(f""Transformed \nSize: {transformed_image.shape}"")
            ax[1].axis(""off"")

            fig.suptitle(f""Class: {Path(image_path).name}"", fontsize=16)
            plt.show(block=False)
            plt.pause(10)
            plt.close()

# plot_transformed_images(image_path_list_test, transform=data_transform, n=1)

# Use ImageFolder to create dataset(s)
from torchvision import datasets
train_data = datasets.ImageFolder(root=train_dir, # target folder of images
                                  transform=data_transform, # transforms to perform on data (images)
                                  target_transform=None) # transforms to perform on labels (if necessary)

test_data = datasets.ImageFolder(root=test_dir, 
                                 transform=data_transform)

print(f""Train data:\n{train_data}\nTest data:\n{test_data}"")",
206,2,,15697,,,output: output.txt;,"c:/Users/thien/Desktop/project/venv/Scripts/python.exe c:/Users/thien/Desktop/project/main.py
Traceback (most recent call last):
  File ""c:/Users/thien/Desktop/project/main.py"", line 82, in <module>
    make_train_test_folder(data_path)
  File ""c:/Users/thien/Desktop/project/main.py"", line 73, in make_train_test_folder
    os.mkdir(train_folder / el)
FileNotFoundError: [WinError 3] The system cannot find the path specified: 'C:\\Users\\thien\\Desktop\\project\\dat\\Garbage classification\\Garbage classification\\train\\cardboard'
(venv)",
207,2,https://www.google.com/search?q=make+directory+within+directory+python&rlz=1C1SQJL_enUS958US958&oq=make+directory+within+directory+python&aqs=chrome..69i57j0i22i30l2j0i390l3.9751j1j7&sourceid=chrome&ie=UTF-8,15759,screencapture-n134_2022-10-28-00_25_59.png,,search: make directory within directory python;,,
208,2,https://www.geeksforgeeks.org/create-a-directory-in-python/,15762,screencapture-n135_2022-10-28-00_26_02.png,,visit: Create a directory in Python - GeeksforGeeks;,,
209,2,https://www.google.com/search?q=FileNotFoundError%3A+%5BWinError+3%5D+The+system+cannot+find+the+path+specified&rlz=1C1SQJL_enUS958US958&oq=FileNotFoundError%3A+%5BWinError+3%5D+The+system+cannot+find+the+path+specified&aqs=chrome..69i57j69i58.232j0j4&sourceid=chrome&ie=UTF-8,15830,screencapture-n136_2022-10-28-00_27_10.png,,search: FileNotFoundError: [WinError 3] The system cannot find the path specified;,,
210,2,https://stackoverflow.com/questions/51007476/filenotfounderror-winerror-3-the-system-cannot-find-the-path-specified,15831,screencapture-n137_2022-10-28-00_27_11.png,,visit: python 3.x - FileNotFoundError: [WinError 3] The system cannot find the path specified: - Stack Overflow;,,
211,2,,15906,,,code: main.py;,"# from PIL import Image
  
# im = Image.open(r""C:\Users\thien\Desktop\project\dat\Garbage classification\Garbage classification\glass\glass11.jpg"")
# im.show() 

from genericpath import exists
import math
import os
garbage_classification_folder = r""C:\Users\thien\Desktop\project\dat\Garbage classification\Garbage classification""

from pathlib import Path

# Setup path to data folder
data_path = Path(garbage_classification_folder)
image_path = data_path / ""cardboard""

def walk_through_dir(dir_path):
    no_of_files = 0
    for dirpath, dirnames, filenames in os.walk(dir_path):
        # print(f""There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'."")
        no_of_files = len(filenames)
    return no_of_files

import random
from PIL import Image

def allUnique(x):
    seen = list()
    return not any(i in seen or seen.append(i) for i in x)

# pass in the img dir path (eg. ./cardboard)
def get_random_img_list(dir_path, N):
    # Set seed
    random.seed(42)

    # 1. Get all image paths (* means ""any combination"")
    image_path_list = list(dir_path.glob(""*.jpg""))

    # converting the list into a set
    # image_path_set = set(image_path_list)

    # 2. Get random image path
    image_list_train = random.sample(image_path_list, k = N)

    s = set(image_list_train)
    image_list_test = [x for x in image_path_list if x not in s]

    return image_list_train, image_list_test

def flatten(l):
    return [item for sublist in l for item in sublist]

import shutil
def make_train_test_folder(dir_path):
    train_folder = dir_path / ""train""
    test_folder = dir_path / ""test""
    if os.path.exists(train_folder):
        shutil.rmtree(train_folder)
    if os.path.exists(test_folder):
        shutil.rmtree(test_folder)
    
    if not os.path.exists(train_folder) and not os.path.exists(test_folder):
        # we need to select random images from all img folders and build up our train set
        collection = [""cardboard"", ""glass"", ""metal"", ""paper"", ""plastic"", ""trash""]
        for el in collection:
            el_path = dir_path / el
            no_of_imgs = walk_through_dir(el_path)

            # grab 80% of imgs for training
            training_amount = math.floor(0.8 * no_of_imgs)
            training_dat, testing_dat = get_random_img_list(el_path, training_amount)

            os.mkdir(train_folder)
            os.mkdir(test_folder)

            for train_img_path in training_dat:
                shutil.copy2(src=train_img_path, dst=train_folder / el)
            
            for test_img_path in testing_dat:
                shutil.copy2(src=test_img_path, dst=test_folder / el)

make_train_test_folder(data_path)

import torch
from torch.utils.data import DataLoader
from torchvision import datasets, transforms

train_dir = data_path / ""train""
test_dir = data_path / ""test""

# Write transform for image
data_transform = transforms.Compose([
    # Resize the images to 128x128
    transforms.Resize(size=(128, 128)),
    # Turn the image into a torch.Tensor
    transforms.ToTensor() # this also converts all pixel values from 0 to 255 to be between 0.0 and 1.0 
])

image_path_list_test = list(train_dir.glob(""*.jpg""))
random_image_path_test = random.choice(image_path_list_test)

import matplotlib.pyplot as plt

def plot_transformed_images(image_paths, transform, n):
    # Plots a series of random images from image_paths.
    # Will open n image paths from image_paths, transform them
    # with transform and plot them side by side.
    random.seed(42)
    random_image_paths = random.sample(image_paths, k=n)
    for image_path in random_image_paths:
        with Image.open(image_path) as f:
            fig, ax = plt.subplots(1, 2)
            ax[0].imshow(f) 
            ax[0].set_title(f""Original \nSize: {f.size}"")
            ax[0].axis(""off"")

            # Transform and plot image
            # Note: permute() will change shape of image to suit matplotlib 
            # (PyTorch default is [C, H, W] but Matplotlib is [H, W, C])
            transformed_image = transform(f).permute(1, 2, 0) 
            ax[1].imshow(transformed_image) 
            ax[1].set_title(f""Transformed \nSize: {transformed_image.shape}"")
            ax[1].axis(""off"")

            fig.suptitle(f""Class: {Path(image_path).name}"", fontsize=16)
            plt.show(block=False)
            plt.pause(10)
            plt.close()

# plot_transformed_images(image_path_list_test, transform=data_transform, n=1)

# Use ImageFolder to create dataset(s)
from torchvision import datasets
train_data = datasets.ImageFolder(root=train_dir, # target folder of images
                                  transform=data_transform, # transforms to perform on data (images)
                                  target_transform=None) # transforms to perform on labels (if necessary)

test_data = datasets.ImageFolder(root=test_dir, 
                                 transform=data_transform)

print(f""Train data:\n{train_data}\nTest data:\n{test_data}"")",
212,2,,15906,,,output: output.txt;,"c:/Users/thien/Desktop/project/venv/Scripts/python.exe c:/Users/thien/Desktop/project/main.py
Traceback (most recent call last):
  File ""c:/Users/thien/Desktop/project/main.py"", line 82, in <module>
    make_train_test_folder(data_path)
  File ""c:/Users/thien/Desktop/project/main.py"", line 73, in make_train_test_folder
    os.mkdir(train_folder)
FileExistsError: [WinError 183] Cannot create a file when that file already exists: 'C:\\Users\\thien\\Desktop\\project\\dat\\Garbage classification\\Garbage classification\\train'
(venv)",
213,2,,16023,,,code: main.py;,"# from PIL import Image
  
# im = Image.open(r""C:\Users\thien\Desktop\project\dat\Garbage classification\Garbage classification\glass\glass11.jpg"")
# im.show() 

from genericpath import exists
import math
import os
garbage_classification_folder = r""C:\Users\thien\Desktop\project\dat\Garbage classification\Garbage classification""

from pathlib import Path

# Setup path to data folder
data_path = Path(garbage_classification_folder)
image_path = data_path / ""cardboard""

def walk_through_dir(dir_path):
    no_of_files = 0
    for dirpath, dirnames, filenames in os.walk(dir_path):
        # print(f""There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'."")
        no_of_files = len(filenames)
    return no_of_files

import random
from PIL import Image

def allUnique(x):
    seen = list()
    return not any(i in seen or seen.append(i) for i in x)

# pass in the img dir path (eg. ./cardboard)
def get_random_img_list(dir_path, N):
    # Set seed
    random.seed(42)

    # 1. Get all image paths (* means ""any combination"")
    image_path_list = list(dir_path.glob(""*.jpg""))

    # converting the list into a set
    # image_path_set = set(image_path_list)

    # 2. Get random image path
    image_list_train = random.sample(image_path_list, k = N)

    s = set(image_list_train)
    image_list_test = [x for x in image_path_list if x not in s]

    return image_list_train, image_list_test

def flatten(l):
    return [item for sublist in l for item in sublist]

import shutil
def make_train_test_folder(dir_path):
    train_folder = dir_path / ""train""
    test_folder = dir_path / ""test""
    if os.path.exists(train_folder):
        shutil.rmtree(train_folder)
    if os.path.exists(test_folder):
        shutil.rmtree(test_folder)
    
    if not os.path.exists(train_folder) and not os.path.exists(test_folder):
        # we need to select random images from all img folders and build up our train set
        collection = [""cardboard"", ""glass"", ""metal"", ""paper"", ""plastic"", ""trash""]
        for el in collection:
            el_path = dir_path / el
            no_of_imgs = walk_through_dir(el_path)

            # grab 80% of imgs for training
            training_amount = math.floor(0.8 * no_of_imgs)
            training_dat, testing_dat = get_random_img_list(el_path, training_amount)

            os.mkdir(train_folder)
            os.mkdir(train_folder / el)
            os.mkdir(test_folder)
            os.mkdir(test_folder / el)

            for train_img_path in training_dat:
                shutil.copy2(src=train_img_path, dst=train_folder / el)
            
            for test_img_path in testing_dat:
                shutil.copy2(src=test_img_path, dst=test_folder / el)

make_train_test_folder(data_path)

import torch
from torch.utils.data import DataLoader
from torchvision import datasets, transforms

train_dir = data_path / ""train""
test_dir = data_path / ""test""

# Write transform for image
data_transform = transforms.Compose([
    # Resize the images to 128x128
    transforms.Resize(size=(128, 128)),
    # Turn the image into a torch.Tensor
    transforms.ToTensor() # this also converts all pixel values from 0 to 255 to be between 0.0 and 1.0 
])

image_path_list_test = list(train_dir.glob(""*.jpg""))
random_image_path_test = random.choice(image_path_list_test)

import matplotlib.pyplot as plt

def plot_transformed_images(image_paths, transform, n):
    # Plots a series of random images from image_paths.
    # Will open n image paths from image_paths, transform them
    # with transform and plot them side by side.
    random.seed(42)
    random_image_paths = random.sample(image_paths, k=n)
    for image_path in random_image_paths:
        with Image.open(image_path) as f:
            fig, ax = plt.subplots(1, 2)
            ax[0].imshow(f) 
            ax[0].set_title(f""Original \nSize: {f.size}"")
            ax[0].axis(""off"")

            # Transform and plot image
            # Note: permute() will change shape of image to suit matplotlib 
            # (PyTorch default is [C, H, W] but Matplotlib is [H, W, C])
            transformed_image = transform(f).permute(1, 2, 0) 
            ax[1].imshow(transformed_image) 
            ax[1].set_title(f""Transformed \nSize: {transformed_image.shape}"")
            ax[1].axis(""off"")

            fig.suptitle(f""Class: {Path(image_path).name}"", fontsize=16)
            plt.show(block=False)
            plt.pause(10)
            plt.close()

# plot_transformed_images(image_path_list_test, transform=data_transform, n=1)

# Use ImageFolder to create dataset(s)
from torchvision import datasets
train_data = datasets.ImageFolder(root=train_dir, # target folder of images
                                  transform=data_transform, # transforms to perform on data (images)
                                  target_transform=None) # transforms to perform on labels (if necessary)

test_data = datasets.ImageFolder(root=test_dir, 
                                 transform=data_transform)

print(f""Train data:\n{train_data}\nTest data:\n{test_data}"")",
214,2,,16023,,,output: output.txt;,"c:/Users/thien/Desktop/project/venv/Scripts/python.exe c:/Users/thien/Desktop/project/main.py
Traceback (most recent call last):
  File ""c:/Users/thien/Desktop/project/main.py"", line 84, in <module>
    make_train_test_folder(data_path)
  File ""c:/Users/thien/Desktop/project/main.py"", line 73, in make_train_test_folder
    os.mkdir(train_folder)
FileExistsError: [WinError 183] Cannot create a file when that file already exists: 'C:\\Users\\thien\\Desktop\\project\\dat\\Garbage classification\\Garbage classification\\train'
(venv)",
215,2,,16112,,,code: main.py;,"# from PIL import Image
  
# im = Image.open(r""C:\Users\thien\Desktop\project\dat\Garbage classification\Garbage classification\glass\glass11.jpg"")
# im.show() 

from genericpath import exists
import math
import os
garbage_classification_folder = r""C:\Users\thien\Desktop\project\dat\Garbage classification\Garbage classification""

from pathlib import Path

# Setup path to data folder
data_path = Path(garbage_classification_folder)
image_path = data_path / ""cardboard""

def walk_through_dir(dir_path):
    no_of_files = 0
    for dirpath, dirnames, filenames in os.walk(dir_path):
        # print(f""There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'."")
        no_of_files = len(filenames)
    return no_of_files

import random
from PIL import Image

def allUnique(x):
    seen = list()
    return not any(i in seen or seen.append(i) for i in x)

# pass in the img dir path (eg. ./cardboard)
def get_random_img_list(dir_path, N):
    # Set seed
    random.seed(42)

    # 1. Get all image paths (* means ""any combination"")
    image_path_list = list(dir_path.glob(""*.jpg""))

    # converting the list into a set
    # image_path_set = set(image_path_list)

    # 2. Get random image path
    image_list_train = random.sample(image_path_list, k = N)

    s = set(image_list_train)
    image_list_test = [x for x in image_path_list if x not in s]

    return image_list_train, image_list_test

def flatten(l):
    return [item for sublist in l for item in sublist]

import shutil
def make_train_test_folder(dir_path):
    train_folder = dir_path / ""train""
    test_folder = dir_path / ""test""
    if os.path.exists(train_folder):
        shutil.rmtree(train_folder)
    if os.path.exists(test_folder):
        shutil.rmtree(test_folder)
    
    if not os.path.exists(train_folder) and not os.path.exists(test_folder):
        os.mkdir(train_folder)
        os.mkdir(test_folder)
        # we need to select random images from all img folders and build up our train set
        collection = [""cardboard"", ""glass"", ""metal"", ""paper"", ""plastic"", ""trash""]
        for el in collection:
            el_path = dir_path / el
            no_of_imgs = walk_through_dir(el_path)

            # grab 80% of imgs for training
            training_amount = math.floor(0.8 * no_of_imgs)
            training_dat, testing_dat = get_random_img_list(el_path, training_amount)
            
            os.mkdir(train_folder / el)
            os.mkdir(test_folder / el)

            for train_img_path in training_dat:
                shutil.copy2(src=train_img_path, dst=train_folder / el)
            
            for test_img_path in testing_dat:
                shutil.copy2(src=test_img_path, dst=test_folder / el)

make_train_test_folder(data_path)

import torch
from torch.utils.data import DataLoader
from torchvision import datasets, transforms

train_dir = data_path / ""train""
test_dir = data_path / ""test""

# Write transform for image
data_transform = transforms.Compose([
    # Resize the images to 128x128
    transforms.Resize(size=(128, 128)),
    # Turn the image into a torch.Tensor
    transforms.ToTensor() # this also converts all pixel values from 0 to 255 to be between 0.0 and 1.0 
])

image_path_list_test = list(train_dir.glob(""*.jpg""))
random_image_path_test = random.choice(image_path_list_test)

import matplotlib.pyplot as plt

def plot_transformed_images(image_paths, transform, n):
    # Plots a series of random images from image_paths.
    # Will open n image paths from image_paths, transform them
    # with transform and plot them side by side.
    random.seed(42)
    random_image_paths = random.sample(image_paths, k=n)
    for image_path in random_image_paths:
        with Image.open(image_path) as f:
            fig, ax = plt.subplots(1, 2)
            ax[0].imshow(f) 
            ax[0].set_title(f""Original \nSize: {f.size}"")
            ax[0].axis(""off"")

            # Transform and plot image
            # Note: permute() will change shape of image to suit matplotlib 
            # (PyTorch default is [C, H, W] but Matplotlib is [H, W, C])
            transformed_image = transform(f).permute(1, 2, 0) 
            ax[1].imshow(transformed_image) 
            ax[1].set_title(f""Transformed \nSize: {transformed_image.shape}"")
            ax[1].axis(""off"")

            fig.suptitle(f""Class: {Path(image_path).name}"", fontsize=16)
            plt.show(block=False)
            plt.pause(10)
            plt.close()

# plot_transformed_images(image_path_list_test, transform=data_transform, n=1)

# Use ImageFolder to create dataset(s)
from torchvision import datasets
train_data = datasets.ImageFolder(root=train_dir, # target folder of images
                                  transform=data_transform, # transforms to perform on data (images)
                                  target_transform=None) # transforms to perform on labels (if necessary)

test_data = datasets.ImageFolder(root=test_dir, 
                                 transform=data_transform)

print(f""Train data:\n{train_data}\nTest data:\n{test_data}"")",
216,2,,16112,,,output: output.txt;,"c:/Users/thien/Desktop/project/venv/Scripts/python.exe c:/Users/thien/Desktop/project/main.py
Traceback (most recent call last):
  File ""c:/Users/thien/Desktop/project/main.py"", line 102, in <module>
    random_image_path_test = random.choice(image_path_list_test)
  File ""C:\Python38\lib\random.py"", line 290, in choice
    raise IndexError('Cannot choose from an empty sequence') from None
IndexError: Cannot choose from an empty sequence
(venv)",
217,2,https://www.learnpytorch.io/04_pytorch_custom_datasets/#4-option-1-loading-image-data-using-imagefolder,16210,screencapture-n138_2022-10-28-00_33_30.png,,revisit: 04. PyTorch Custom Datasets - Zero to Mastery Learn PyTorch for Deep Learning;,,
218,2,,16270,,,code: main.py;,"# from PIL import Image
  
# im = Image.open(r""C:\Users\thien\Desktop\project\dat\Garbage classification\Garbage classification\glass\glass11.jpg"")
# im.show() 

from genericpath import exists
import math
import os
garbage_classification_folder = r""C:\Users\thien\Desktop\project\dat\Garbage classification\Garbage classification""

from pathlib import Path

# Setup path to data folder
data_path = Path(garbage_classification_folder)
image_path = data_path / ""cardboard""

def walk_through_dir(dir_path):
    no_of_files = 0
    for dirpath, dirnames, filenames in os.walk(dir_path):
        # print(f""There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'."")
        no_of_files = len(filenames)
    return no_of_files

import random
from PIL import Image

def allUnique(x):
    seen = list()
    return not any(i in seen or seen.append(i) for i in x)

# pass in the img dir path (eg. ./cardboard)
def get_random_img_list(dir_path, N):
    # Set seed
    random.seed(42)

    # 1. Get all image paths (* means ""any combination"")
    image_path_list = list(dir_path.glob(""*.jpg""))

    # converting the list into a set
    # image_path_set = set(image_path_list)

    # 2. Get random image path
    image_list_train = random.sample(image_path_list, k = N)

    s = set(image_list_train)
    image_list_test = [x for x in image_path_list if x not in s]

    return image_list_train, image_list_test

def flatten(l):
    return [item for sublist in l for item in sublist]

import shutil
def make_train_test_folder(dir_path):
    train_folder = dir_path / ""train""
    test_folder = dir_path / ""test""
    if os.path.exists(train_folder):
        shutil.rmtree(train_folder)
    if os.path.exists(test_folder):
        shutil.rmtree(test_folder)
    
    if not os.path.exists(train_folder) and not os.path.exists(test_folder):
        os.mkdir(train_folder)
        os.mkdir(test_folder)
        # we need to select random images from all img folders and build up our train set
        collection = [""cardboard"", ""glass"", ""metal"", ""paper"", ""plastic"", ""trash""]
        for el in collection:
            el_path = dir_path / el
            no_of_imgs = walk_through_dir(el_path)

            # grab 80% of imgs for training
            training_amount = math.floor(0.8 * no_of_imgs)
            training_dat, testing_dat = get_random_img_list(el_path, training_amount)

            os.mkdir(train_folder / el)
            os.mkdir(test_folder / el)

            for train_img_path in training_dat:
                shutil.copy2(src=train_img_path, dst=train_folder / el)
            
            for test_img_path in testing_dat:
                shutil.copy2(src=test_img_path, dst=test_folder / el)

# make_train_test_folder(data_path)

import torch
from torch.utils.data import DataLoader
from torchvision import datasets, transforms

train_dir = data_path / ""train""
test_dir = data_path / ""test""

# Write transform for image
data_transform = transforms.Compose([
    # Resize the images to 128x128
    transforms.Resize(size=(128, 128)),
    # Turn the image into a torch.Tensor
    transforms.ToTensor() # this also converts all pixel values from 0 to 255 to be between 0.0 and 1.0 
])

image_path_list_test = list(train_dir.glob(""*/*.jpg""))
random_image_path_test = random.choice(image_path_list_test)

import matplotlib.pyplot as plt

def plot_transformed_images(image_paths, transform, n):
    # Plots a series of random images from image_paths.
    # Will open n image paths from image_paths, transform them
    # with transform and plot them side by side.
    random.seed(42)
    random_image_paths = random.sample(image_paths, k=n)
    for image_path in random_image_paths:
        with Image.open(image_path) as f:
            fig, ax = plt.subplots(1, 2)
            ax[0].imshow(f) 
            ax[0].set_title(f""Original \nSize: {f.size}"")
            ax[0].axis(""off"")

            # Transform and plot image
            # Note: permute() will change shape of image to suit matplotlib 
            # (PyTorch default is [C, H, W] but Matplotlib is [H, W, C])
            transformed_image = transform(f).permute(1, 2, 0) 
            ax[1].imshow(transformed_image) 
            ax[1].set_title(f""Transformed \nSize: {transformed_image.shape}"")
            ax[1].axis(""off"")

            fig.suptitle(f""Class: {image_path.parent.stem}"", fontsize=16)
            plt.show(block=False)
            plt.pause(10)
            plt.close()

# plot_transformed_images(image_path_list_test, transform=data_transform, n=1)

# Use ImageFolder to create dataset(s)
from torchvision import datasets
train_data = datasets.ImageFolder(root=train_dir, # target folder of images
                                  transform=data_transform, # transforms to perform on data (images)
                                  target_transform=None) # transforms to perform on labels (if necessary)

test_data = datasets.ImageFolder(root=test_dir, 
                                 transform=data_transform)

print(f""Train data:\n{train_data}\nTest data:\n{test_data}"")",
219,2,,16270,,,output: output.txt;,"c:/Users/thien/Desktop/project/venv/Scripts/python.exe c:/Users/thien/Desktop/project/main.py
Train data:
Dataset ImageFolder
    Number of datapoints: 2019
    Root location: C:\Users\thien\Desktop\project\dat\Garbage classification\Garbage classification\train
    StandardTransform
Transform: Compose(
               Resize(size=(128, 128), interpolation=bilinear, max_size=None, antialias=None)
               ToTensor()
           )
Test data:
Dataset ImageFolder
    Number of datapoints: 508
    Root location: C:\Users\thien\Desktop\project\dat\Garbage classification\Garbage classification\test
    StandardTransform
Transform: Compose(
               Resize(size=(128, 128), interpolation=bilinear, max_size=None, antialias=None)
               ToTensor()
           )
(venv)",
220,2,,16386,,,code: main.py;,"# from PIL import Image
  
# im = Image.open(r""C:\Users\thien\Desktop\project\dat\Garbage classification\Garbage classification\glass\glass11.jpg"")
# im.show() 

from genericpath import exists
import math
import os
garbage_classification_folder = r""C:\Users\thien\Desktop\project\dat\Garbage classification\Garbage classification""

from pathlib import Path

# Setup path to data folder
data_path = Path(garbage_classification_folder)
image_path = data_path / ""cardboard""

def walk_through_dir(dir_path):
    no_of_files = 0
    for dirpath, dirnames, filenames in os.walk(dir_path):
        # print(f""There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'."")
        no_of_files = len(filenames)
    return no_of_files

import random
from PIL import Image

def allUnique(x):
    seen = list()
    return not any(i in seen or seen.append(i) for i in x)

# pass in the img dir path (eg. ./cardboard)
def get_random_img_list(dir_path, N):
    # Set seed
    random.seed(42)

    # 1. Get all image paths (* means ""any combination"")
    image_path_list = list(dir_path.glob(""*.jpg""))

    # converting the list into a set
    # image_path_set = set(image_path_list)

    # 2. Get random image path
    image_list_train = random.sample(image_path_list, k = N)

    s = set(image_list_train)
    image_list_test = [x for x in image_path_list if x not in s]

    return image_list_train, image_list_test

def flatten(l):
    return [item for sublist in l for item in sublist]

import shutil
def make_train_test_folder(dir_path):
    train_folder = dir_path / ""train""
    test_folder = dir_path / ""test""
    if os.path.exists(train_folder):
        shutil.rmtree(train_folder)
    if os.path.exists(test_folder):
        shutil.rmtree(test_folder)
    
    if not os.path.exists(train_folder) and not os.path.exists(test_folder):
        os.mkdir(train_folder)
        os.mkdir(test_folder)
        # we need to select random images from all img folders and build up our train set
        collection = [""cardboard"", ""glass"", ""metal"", ""paper"", ""plastic"", ""trash""]
        for el in collection:
            el_path = dir_path / el
            no_of_imgs = walk_through_dir(el_path)

            # grab 80% of imgs for training
            training_amount = math.floor(0.8 * no_of_imgs)
            training_dat, testing_dat = get_random_img_list(el_path, training_amount)

            os.mkdir(train_folder / el)
            os.mkdir(test_folder / el)

            for train_img_path in training_dat:
                shutil.copy2(src=train_img_path, dst=train_folder / el)
            
            for test_img_path in testing_dat:
                shutil.copy2(src=test_img_path, dst=test_folder / el)

# make_train_test_folder(data_path)

import torch
from torch.utils.data import DataLoader
from torchvision import datasets, transforms

train_dir = data_path / ""train""
test_dir = data_path / ""test""

# Write transform for image
data_transform = transforms.Compose([
    # Resize the images to 128x128
    transforms.Resize(size=(128, 128)),
    # Turn the image into a torch.Tensor
    transforms.ToTensor() # this also converts all pixel values from 0 to 255 to be between 0.0 and 1.0 
])

image_path_list_test = list(train_dir.glob(""*/*.jpg""))
random_image_path_test = random.choice(image_path_list_test)

import matplotlib.pyplot as plt

def plot_transformed_images(image_paths, transform, n):
    # Plots a series of random images from image_paths.
    # Will open n image paths from image_paths, transform them
    # with transform and plot them side by side.
    random.seed(42)
    random_image_paths = random.sample(image_paths, k=n)
    for image_path in random_image_paths:
        with Image.open(image_path) as f:
            fig, ax = plt.subplots(1, 2)
            ax[0].imshow(f) 
            ax[0].set_title(f""Original \nSize: {f.size}"")
            ax[0].axis(""off"")

            # Transform and plot image
            # Note: permute() will change shape of image to suit matplotlib 
            # (PyTorch default is [C, H, W] but Matplotlib is [H, W, C])
            transformed_image = transform(f).permute(1, 2, 0) 
            ax[1].imshow(transformed_image) 
            ax[1].set_title(f""Transformed \nSize: {transformed_image.shape}"")
            ax[1].axis(""off"")

            fig.suptitle(f""Class: {image_path.parent.stem}"", fontsize=16)
            plt.show(block=False)
            plt.pause(10)
            plt.close()

# plot_transformed_images(image_path_list_test, transform=data_transform, n=1)

# Use ImageFolder to create dataset(s)
from torchvision import datasets
train_data = datasets.ImageFolder(root=train_dir, # target folder of images
                                  transform=data_transform, # transforms to perform on data (images)
                                  target_transform=None) # transforms to perform on labels (if necessary)

test_data = datasets.ImageFolder(root=test_dir, 
                                 transform=data_transform)

class_names = train_data.classes

print(class_names)
print(len(train_data), len(test_data))",
221,2,,16386,,,output: output.txt;,"c:/Users/thien/Desktop/project/venv/Scripts/python.exe c:/Users/thien/Desktop/project/main.py
['cardboard', 'glass', 'metal', 'paper', 'plastic', 'trash']
2019 508
(venv)",
222,2,,17199,,,code: main.py;,"# from PIL import Image
  
# im = Image.open(r""C:\Users\thien\Desktop\project\dat\Garbage classification\Garbage classification\glass\glass11.jpg"")
# im.show() 

from genericpath import exists
import math
import os
garbage_classification_folder = r""C:\Users\thien\Desktop\project\dat\Garbage classification\Garbage classification""

from pathlib import Path

# Setup path to data folder
data_path = Path(garbage_classification_folder)
image_path = data_path / ""cardboard""

def walk_through_dir(dir_path):
    no_of_files = 0
    for dirpath, dirnames, filenames in os.walk(dir_path):
        # print(f""There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'."")
        no_of_files = len(filenames)
    return no_of_files

import random
from PIL import Image

def allUnique(x):
    seen = list()
    return not any(i in seen or seen.append(i) for i in x)

# pass in the img dir path (eg. ./cardboard)
def get_random_img_list(dir_path, N):
    # Set seed
    random.seed(42)

    # 1. Get all image paths (* means ""any combination"")
    image_path_list = list(dir_path.glob(""*.jpg""))

    # converting the list into a set
    # image_path_set = set(image_path_list)

    # 2. Get random image path
    image_list_train = random.sample(image_path_list, k = N)

    s = set(image_list_train)
    image_list_test = [x for x in image_path_list if x not in s]

    return image_list_train, image_list_test

def flatten(l):
    return [item for sublist in l for item in sublist]

import shutil
def make_train_test_folder(dir_path):
    train_folder = dir_path / ""train""
    test_folder = dir_path / ""test""
    if os.path.exists(train_folder):
        shutil.rmtree(train_folder)
    if os.path.exists(test_folder):
        shutil.rmtree(test_folder)
    
    if not os.path.exists(train_folder) and not os.path.exists(test_folder):
        os.mkdir(train_folder)
        os.mkdir(test_folder)
        # we need to select random images from all img folders and build up our train set
        collection = [""cardboard"", ""glass"", ""metal"", ""paper"", ""plastic"", ""trash""]
        for el in collection:
            el_path = dir_path / el
            no_of_imgs = walk_through_dir(el_path)

            # grab 80% of imgs for training
            training_amount = math.floor(0.8 * no_of_imgs)
            training_dat, testing_dat = get_random_img_list(el_path, training_amount)

            os.mkdir(train_folder / el)
            os.mkdir(test_folder / el)

            for train_img_path in training_dat:
                shutil.copy2(src=train_img_path, dst=train_folder / el)
            
            for test_img_path in testing_dat:
                shutil.copy2(src=test_img_path, dst=test_folder / el)

# make_train_test_folder(data_path)

import torch
from torch.utils.data import DataLoader
from torchvision import datasets, transforms

train_dir = data_path / ""train""
test_dir = data_path / ""test""

# Write transform for image
data_transform = transforms.Compose([
    # Resize the images to 128x128
    transforms.Resize(size=(128, 128)),
    # Turn the image into a torch.Tensor
    transforms.ToTensor() # this also converts all pixel values from 0 to 255 to be between 0.0 and 1.0 
])

image_path_list_test = list(train_dir.glob(""*/*.jpg""))
random_image_path_test = random.choice(image_path_list_test)

import matplotlib.pyplot as plt

def plot_transformed_images(image_paths, transform, n):
    # Plots a series of random images from image_paths.
    # Will open n image paths from image_paths, transform them
    # with transform and plot them side by side.
    random.seed(42)
    random_image_paths = random.sample(image_paths, k=n)
    for image_path in random_image_paths:
        with Image.open(image_path) as f:
            fig, ax = plt.subplots(1, 2)
            ax[0].imshow(f) 
            ax[0].set_title(f""Original \nSize: {f.size}"")
            ax[0].axis(""off"")

            # Transform and plot image
            # Note: permute() will change shape of image to suit matplotlib 
            # (PyTorch default is [C, H, W] but Matplotlib is [H, W, C])
            transformed_image = transform(f).permute(1, 2, 0) 
            ax[1].imshow(transformed_image) 
            ax[1].set_title(f""Transformed \nSize: {transformed_image.shape}"")
            ax[1].axis(""off"")

            fig.suptitle(f""Class: {image_path.parent.stem}"", fontsize=16)
            plt.show(block=False)
            plt.pause(10)
            plt.close()

# plot_transformed_images(image_path_list_test, transform=data_transform, n=1)

# Use ImageFolder to create dataset(s)
from torchvision import datasets
train_data = datasets.ImageFolder(root=train_dir, # target folder of images
                                  transform=data_transform, # transforms to perform on data (images)
                                  target_transform=None) # transforms to perform on labels (if necessary)

test_data = datasets.ImageFolder(root=test_dir, 
                                 transform=data_transform)

# Turn train and test Datasets into DataLoaders
from torch.utils.data import DataLoader
batch_size = 4
train_dataloader = DataLoader(dataset=train_data, batch_size=batch_size, 
                                num_workers=0, shuffle=True)

test_dataloader = DataLoader(dataset=test_data, batch_size=batch_size, 
                                num_workers=0, shuffle=False)

import torchvision
import numpy as np

# functions to show an image
def imshow(img):
    npimg = img.numpy()
    plt.imshow(np.transpose(npimg, (1, 2, 0)))
    plt.show()


# get some random training images
dataiter = iter(train_dataloader)
images, labels = next(dataiter)

# show images
imshow(torchvision.utils.make_grid(images))",
223,2,,17199,,,output: output.txt;,"c:/Users/thien/Desktop/project/venv/Scripts/python.exe c:/Users/thien/Desktop/project/main.py
(venv)",
224,2,https://www.google.com/search?q=import+python+file+as+module&rlz=1C1SQJL_enUS958US958&oq=import+python+file+as+&aqs=chrome.0.0i512j69i57j0i512l3j0i22i30l5.11613j0j7&sourceid=chrome&ie=UTF-8,17779,screencapture-n139_2022-10-28-00_59_39.png,,search: import python file as module;,,
225,2,https://csatlas.com/python-import-file-module/,17783,screencapture-n140_2022-10-28-00_59_43.png,,visit: Python 3: Import Another Python File as a Module â€” Computer Science Atlas;,,
226,2,,18292,,,code: main.py;,"import math
import os
from pathlib import Path
import random
from PIL import Image
import shutil
import torch
from torch.utils.data import DataLoader
from torchvision import datasets, transforms

garbage_classification_folder = r""C:\Users\thien\Desktop\project\dat\Garbage classification\Garbage classification""

# Setup path to data folder
data_path = Path(garbage_classification_folder)

def walk_through_dir(dir_path):
    no_of_files = 0
    for dirpath, dirnames, filenames in os.walk(dir_path):
        # print(f""There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'."")
        no_of_files = len(filenames)
    return no_of_files


# pass in the img dir path (eg. ./cardboard)
def get_random_img_list(dir_path, N):
    random.seed(42)

    # get all image paths (* means ""any combination"")
    image_path_list = list(dir_path.glob(""*.jpg""))

    # get random image paths for training data
    image_list_train = random.sample(image_path_list, k = N)

    # remaining image paths will be used as testing data
    s = set(image_list_train)
    image_list_test = [x for x in image_path_list if x not in s]

    return image_list_train, image_list_test


def make_train_test_folder(dir_path):
    train_folder = dir_path / ""train""
    test_folder = dir_path / ""test""
    if os.path.exists(train_folder):
        shutil.rmtree(train_folder)
    if os.path.exists(test_folder):
        shutil.rmtree(test_folder)
    
    if not os.path.exists(train_folder) and not os.path.exists(test_folder):
        os.mkdir(train_folder)
        os.mkdir(test_folder)
        # we need to select random images from all img folders and build up our train set
        collection = [""cardboard"", ""glass"", ""metal"", ""paper"", ""plastic"", ""trash""]
        for el in collection:
            el_path = dir_path / el
            no_of_imgs = walk_through_dir(el_path)

            # grab 80% of imgs for training
            training_amount = math.floor(0.8 * no_of_imgs)
            training_dat, testing_dat = get_random_img_list(el_path, training_amount)

            os.mkdir(train_folder / el)
            os.mkdir(test_folder / el)

            for train_img_path in training_dat:
                shutil.copy2(src=train_img_path, dst=train_folder / el)
            
            for test_img_path in testing_dat:
                shutil.copy2(src=test_img_path, dst=test_folder / el)


def main():
    # make_train_test_folder(data_path) # uncomment this line if want to build new train and test set

    train_dir = data_path / ""train""
    test_dir = data_path / ""test""

    # Write transform for image
    data_transform = transforms.Compose([
        # Resize the images to 128x128
        transforms.Resize(size=(128, 128)),
        # Turn the image into a torch.Tensor
        transforms.ToTensor() # this also converts all pixel values from 0 to 255 to be between 0.0 and 1.0 
    ])

    # Use ImageFolder to create dataset(s)
    train_data = datasets.ImageFolder(root=train_dir, # target folder of images
                                    transform=data_transform, # transforms to perform on data (images)
                                    target_transform=None) # transforms to perform on labels (if necessary)

    test_data = datasets.ImageFolder(root=test_dir, 
                                    transform=data_transform)

    # Turn train and test Datasets into DataLoaders
    from torch.utils.data import DataLoader
    batch_size = 4
    train_dataloader = DataLoader(dataset=train_data, batch_size=batch_size, 
                                    num_workers=0, shuffle=True)

    test_dataloader = DataLoader(dataset=test_data, batch_size=batch_size, 
                                    num_workers=0, shuffle=False)

    print(""refactored file"")
    print(train_dataloader)
    print(test_dataloader)",
227,2,,18292,,,code: plot_func.py;,"import random
from PIL import Image
import matplotlib.pyplot as plt
import numpy as np

# eg. call: plot_transformed_images(image_path_list, transform=data_transform, n=1)
def plot_transformed_images(image_paths, transform, n):
    # Plots a series of random images from image_paths.
    # Will open n image paths from image_paths, transform them
    # with transform and plot them side by side.
    random.seed(42)
    random_image_paths = random.sample(image_paths, k=n)
    for image_path in random_image_paths:
        with Image.open(image_path) as f:
            fig, ax = plt.subplots(1, 2)
            ax[0].imshow(f) 
            ax[0].set_title(f""Original \nSize: {f.size}"")
            ax[0].axis(""off"")

            # Transform and plot image
            # Note: permute() will change shape of image to suit matplotlib 
            # (PyTorch default is [C, H, W] but Matplotlib is [H, W, C])
            transformed_image = transform(f).permute(1, 2, 0) 
            ax[1].imshow(transformed_image) 
            ax[1].set_title(f""Transformed \nSize: {transformed_image.shape}"")
            ax[1].axis(""off"")

            fig.suptitle(f""Class: {image_path.parent.stem}"", fontsize=16)
            plt.show(block=False)
            plt.pause(10)
            plt.close()


# eg. imshow(torchvision.utils.make_grid(images))
def imshow(img):
    npimg = img.numpy()
    plt.imshow(np.transpose(npimg, (1, 2, 0)))
    plt.show()",
228,2,,18323,,,code: main.py;,"import math
import os
from pathlib import Path
import random
from PIL import Image
import shutil
import torch
from torch.utils.data import DataLoader
from torchvision import datasets, transforms

garbage_classification_folder = r""C:\Users\thien\Desktop\project\dat\Garbage classification\Garbage classification""

# Setup path to data folder
data_path = Path(garbage_classification_folder)

def walk_through_dir(dir_path):
    no_of_files = 0
    for dirpath, dirnames, filenames in os.walk(dir_path):
        # print(f""There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'."")
        no_of_files = len(filenames)
    return no_of_files


# pass in the img dir path (eg. ./cardboard)
def get_random_img_list(dir_path, N):
    random.seed(42)

    # get all image paths (* means ""any combination"")
    image_path_list = list(dir_path.glob(""*.jpg""))

    # get random image paths for training data
    image_list_train = random.sample(image_path_list, k = N)

    # remaining image paths will be used as testing data
    s = set(image_list_train)
    image_list_test = [x for x in image_path_list if x not in s]

    return image_list_train, image_list_test


def make_train_test_folder(dir_path):
    train_folder = dir_path / ""train""
    test_folder = dir_path / ""test""
    if os.path.exists(train_folder):
        shutil.rmtree(train_folder)
    if os.path.exists(test_folder):
        shutil.rmtree(test_folder)
    
    if not os.path.exists(train_folder) and not os.path.exists(test_folder):
        os.mkdir(train_folder)
        os.mkdir(test_folder)
        # we need to select random images from all img folders and build up our train set
        collection = [""cardboard"", ""glass"", ""metal"", ""paper"", ""plastic"", ""trash""]
        for el in collection:
            el_path = dir_path / el
            no_of_imgs = walk_through_dir(el_path)

            # grab 80% of imgs for training
            training_amount = math.floor(0.8 * no_of_imgs)
            training_dat, testing_dat = get_random_img_list(el_path, training_amount)

            os.mkdir(train_folder / el)
            os.mkdir(test_folder / el)

            for train_img_path in training_dat:
                shutil.copy2(src=train_img_path, dst=train_folder / el)
            
            for test_img_path in testing_dat:
                shutil.copy2(src=test_img_path, dst=test_folder / el)


def main():
    # make_train_test_folder(data_path) # uncomment this line if want to build new train and test set

    train_dir = data_path / ""train""
    test_dir = data_path / ""test""

    # Write transform for image
    data_transform = transforms.Compose([
        # Resize the images to 128x128
        transforms.Resize(size=(128, 128)),
        # Turn the image into a torch.Tensor
        transforms.ToTensor() # this also converts all pixel values from 0 to 255 to be between 0.0 and 1.0 
    ])

    # Use ImageFolder to create dataset(s)
    train_data = datasets.ImageFolder(root=train_dir, # target folder of images
                                    transform=data_transform, # transforms to perform on data (images)
                                    target_transform=None) # transforms to perform on labels (if necessary)

    test_data = datasets.ImageFolder(root=test_dir, 
                                    transform=data_transform)

    # Turn train and test Datasets into DataLoaders
    from torch.utils.data import DataLoader
    batch_size = 4
    train_dataloader = DataLoader(dataset=train_data, batch_size=batch_size, 
                                    num_workers=0, shuffle=True)

    test_dataloader = DataLoader(dataset=test_data, batch_size=batch_size, 
                                    num_workers=0, shuffle=False)

    print(""refactored file"")
    print(train_dataloader)
    print(test_dataloader)

main()",
229,2,,18323,,,output: output.txt;,"c:/Users/thien/Desktop/project/venv/Scripts/python.exe c:/Users/thien/Desktop/project/main.py
refactored file
<torch.utils.data.dataloader.DataLoader object at 0x00000181AFB0CBB0>
<torch.utils.data.dataloader.DataLoader object at 0x00000181D3A98E50>
(venv)",
230,2,https://www.google.com/search?q=common+pytorch+cnn+model&rlz=1C1SQJL_enUS958US958&oq=common+pytorch+cnn+&aqs=chrome.1.69i57j33i160i395l2j33i160j33i160i395j33i299i395.10728j1j4&sourceid=chrome&ie=UTF-8,18574,screencapture-n141_2022-10-28-01_12_54.png,,search: common pytorch cnn model;,,
231,2,https://www.analyticsvidhya.com/blog/2019/10/building-image-classification-models-cnn-pytorch/,18578,screencapture-n142_2022-10-28-01_12_58.png,,visit: Convolutional Neural Network Pytorch | CNN Using Pytorch;,,
232,2,https://www.run.ai/guides/deep-learning-for-computer-vision/pytorch-cnn,18788,screencapture-n143_2022-10-28-01_16_28.png,,visit: PyTorch CNN: The Basics and a Quick Tutorial;,,
233,2,https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html#training-an-image-classifier,18849,screencapture-n144_2022-10-28-01_17_29.png,,revisit: Training a Classifier â€” PyTorch Tutorials 1.13.0+cu117 documentation;,,
234,2,https://www.google.com/search?q=general+cnn+architecture+for+image+classification+pytorch&rlz=1C1SQJL_enUS958US958&oq=general+cnn+architecture+for+image+classification+pytorch&aqs=chrome..69i57j33i299i395.17890j1j7&sourceid=chrome&ie=UTF-8,19110,screencapture-n145_2022-10-28-01_21_50.png,,search: general cnn architecture for image classification pytorch;,,
235,2,https://www.geeksforgeeks.org/implementation-of-a-cnn-based-image-classifier-using-pytorch/,19115,screencapture-n146_2022-10-28-01_21_55.png,,visit: Implementation of a CNN based Image Classifier using PyTorch - GeeksforGeeks;,,
236,2,https://www.google.com/search?q=how+to+visualize+batch+size+and+epochs&rlz=1C1SQJL_enUS958US958&oq=how+to+visualize+batch+size&aqs=chrome.3.69i57j33i160j33i160i395j33i22i29i30i395l7.9233j1j7&sourceid=chrome&ie=UTF-8,20826,screencapture-n147_2022-10-28-01_50_26.png,,search: how to visualize batch size and epochs;,,
237,2,https://www.youtube.com/watch?v=SftOqbMrGfE,20843,screencapture-n148_2022-10-28-01_50_43.png,,"visit: Epochs, Iterations and Batch Size | Deep Learning Basics - YouTube;",,
238,2,,21437,,,code: main.py;,"import math
import os
from pathlib import Path
import random
from PIL import Image
import shutil
import torch
from torch.utils.data import DataLoader
from torchvision import datasets, transforms

garbage_classification_folder = r""C:\Users\thien\Desktop\project\dat\Garbage classification\Garbage classification""

# Setup path to data folder
data_path = Path(garbage_classification_folder)

def walk_through_dir(dir_path):
    no_of_files = 0
    for dirpath, dirnames, filenames in os.walk(dir_path):
        # print(f""There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'."")
        no_of_files = len(filenames)
    return no_of_files


# pass in the img dir path (eg. ./cardboard)
def get_random_img_list(dir_path, N):
    random.seed(42)

    # get all image paths (* means ""any combination"")
    image_path_list = list(dir_path.glob(""*.jpg""))

    # get random image paths for training data
    image_list_train = random.sample(image_path_list, k = N)

    # remaining image paths will be used as testing data
    s = set(image_list_train)
    image_list_test = [x for x in image_path_list if x not in s]

    return image_list_train, image_list_test


def make_train_test_folder(dir_path):
    train_folder = dir_path / ""train""
    test_folder = dir_path / ""test""
    if os.path.exists(train_folder):
        shutil.rmtree(train_folder)
    if os.path.exists(test_folder):
        shutil.rmtree(test_folder)
    
    if not os.path.exists(train_folder) and not os.path.exists(test_folder):
        os.mkdir(train_folder)
        os.mkdir(test_folder)
        # we need to select random images from all img folders and build up our train set
        collection = [""cardboard"", ""glass"", ""metal"", ""paper"", ""plastic"", ""trash""]
        for el in collection:
            el_path = dir_path / el
            no_of_imgs = walk_through_dir(el_path)

            # grab 80% of imgs for training
            training_amount = math.floor(0.8 * no_of_imgs)
            training_dat, testing_dat = get_random_img_list(el_path, training_amount)

            os.mkdir(train_folder / el)
            os.mkdir(test_folder / el)

            for train_img_path in training_dat:
                shutil.copy2(src=train_img_path, dst=train_folder / el)
            
            for test_img_path in testing_dat:
                shutil.copy2(src=test_img_path, dst=test_folder / el)


class CNN(torch.nn.Module):
    def __init__(self):
        super().__init__()
        self.model = torch.nn.Sequential(
            #Input = 3 x 128 x 128, Output = 128 x 128 x 128
            torch.nn.Conv2d(in_channels = 3, out_channels = 128, kernel_size = 3, padding = 1), 
            torch.nn.ReLU(),
            #Input = 128 x 128 x 128, Output = 128 x 64 x 64
            torch.nn.MaxPool2d(kernel_size=2),
  
            #Input = 128 x 64 x 64, Output = 256 x 64 x 64
            torch.nn.Conv2d(in_channels = 128, out_channels = 256, kernel_size = 3, padding = 1),
            torch.nn.ReLU(),
            #Input = 256 x 64 x 64, Output = 256 x 32 x 32
            torch.nn.MaxPool2d(kernel_size=2),
              
            #Input = 256 x 32 x 32, Output = 256 x 32 x 32
            torch.nn.Conv2d(in_channels = 256, out_channels = 256, kernel_size = 3, padding = 1),
            torch.nn.ReLU(),
            #Input = 256 x 32 x 32, Output = 256 x 16 x 16
            torch.nn.MaxPool2d(kernel_size=2),

            #Input = 256 x 16 x 16, Output = 128 x 16 x 16
            torch.nn.Conv2d(in_channels = 256, out_channels = 128, kernel_size = 3, padding = 1),
            torch.nn.ReLU(),
            #Input = 128 x 16 x 16, Output = 128 x 8 x 8
            torch.nn.MaxPool2d(kernel_size=2),
  
            torch.nn.Flatten(),
            torch.nn.Linear(128*8*8, 2048),
            torch.nn.ReLU(),
            torch.nn.Linear(2048, 6)
        )
  
    def forward(self, x):
        return self.model(x)


def main():
    # make_train_test_folder(data_path) # uncomment this line if want to build new train and test set

    train_dir = data_path / ""train""
    test_dir = data_path / ""test""

    # Write transform for image
    data_transform = transforms.Compose([
        # Resize the images to 128x128
        transforms.Resize(size=(128, 128)),
        # Turn the image into a torch.Tensor
        transforms.ToTensor() # this also converts all pixel values from 0 to 255 to be between 0.0 and 1.0 
    ])

    # Use ImageFolder to create dataset(s)
    train_data = datasets.ImageFolder(root=train_dir, # target folder of images
                                    transform=data_transform, # transforms to perform on data (images)
                                    target_transform=None) # transforms to perform on labels (if necessary)

    test_data = datasets.ImageFolder(root=test_dir, 
                                    transform=data_transform)

    # Turn train and test Datasets into DataLoaders
    from torch.utils.data import DataLoader
    batch_size = 4
    train_dataloader = DataLoader(dataset=train_data, batch_size=batch_size, 
                                    num_workers=0, shuffle=True)

    test_dataloader = DataLoader(dataset=test_data, batch_size=batch_size, 
                                    num_workers=0, shuffle=False)

    model = CNN()

    #Defining the model hyper parameters
    num_epochs = 50
    learning_rate = 0.001
    weight_decay = 0.01
    criterion = torch.nn.CrossEntropyLoss()
    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)

    train_loss_list = []
    for epoch in range(num_epochs):
        print(f'Epoch {epoch+1}/{num_epochs}:', end = ' ')
        train_loss = 0
        
        #Iterating over the training dataset in batches
        model.train()
        for i, (images, labels) in enumerate(train_dataloader):
            #Calculating the model output and the cross entropy loss
            outputs = model(images)
            loss = criterion(outputs, labels)
    
            #Updating weights according to calculated loss
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
            train_loss += loss.item()
        
        #Printing loss for each epoch
        train_loss_list.append(train_loss/len(train_dataloader))
        print(f""Training loss = {train_loss_list[-1]}"")  

main()",
239,2,,21437,,,output: output.txt;,"c:/Users/thien/Desktop/project/venv/Scripts/python.exe c:/Users/thien/Desktop/project/main.py
Epoch 1/50: Training loss = 1.7476223145381058
Epoch 2/50: Training loss = 1.7292644514895903
Epoch 3/50: Training loss = 1.7292675256729126
Epoch 4/50: Training loss = 1.7299542736298967
Epoch 5/50: Training loss = 1.7296329800445254
Epoch 6/50: Training loss = 1.7304873818218118
Epoch 7/50: Traceback (most recent call last):
  File ""c:/Users/thien/Desktop/project/main.py"", line 172, in <module>
    main()
  File ""c:/Users/thien/Desktop/project/main.py"", line 164, in main
    loss.backward()
  File ""C:\Users\thien\Desktop\project\venv\lib\site-packages\torch\_tensor.py"", line 396, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File ""C:\Users\thien\Desktop\project\venv\lib\site-packages\torch\autograd\__init__.py"", line 173, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt

(venv)",
240,2,https://pytorch.org/get-started/locally/,21447,screencapture-n149_2022-10-28-02_00_47.png,,revisit: Start Locally | PyTorch;,,
241,2,https://www.geeksforgeeks.org/implementation-of-a-cnn-based-image-classifier-using-pytorch/,21469,screencapture-n150_2022-10-28-02_01_09.png,,revisit: Implementation of a CNN based Image Classifier using PyTorch - GeeksforGeeks;,,
242,2,https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html#training-an-image-classifier,21554,screencapture-n151_2022-10-28-02_02_34.png,,revisit: Training a Classifier â€” PyTorch Tutorials 1.13.0+cu117 documentation;,,
243,2,https://www.google.com/search?q=difference+between+adam+and+sgd&rlz=1C1SQJL_enUS958US958&oq=difference+between+adam+and+&aqs=chrome.0.0i512l2j69i57j0i512l7.6790j0j7&sourceid=chrome&ie=UTF-8,21783,screencapture-n152_2022-10-28-02_06_23.png,,search: difference between adam and sgd;,,
244,2,https://opt-ml.org/papers/2021/paper53.pdf,21798,screencapture-n153_2022-10-28-02_06_38.png,,visit: Adam vs. SGD: Closing the generalization gap on image classification;,,
245,2,https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html#training-an-image-classifier,22014,screencapture-n154_2022-10-28-02_10_14.png,,revisit: Training a Classifier â€” PyTorch Tutorials 1.13.0+cu117 documentation;,,
246,2,https://pytorch.org/docs/stable/notes/serialization.html,22086,screencapture-n155_2022-10-28-02_11_26.png,,visit: Serialization semantics â€” PyTorch 1.13 documentation;,,
247,2,https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html#training-an-image-classifier,22132,screencapture-n156_2022-10-28-02_12_12.png,,revisit: Training a Classifier â€” PyTorch Tutorials 1.13.0+cu117 documentation;,,
248,2,,22205,,,code: main.py;,"import math
import os
from pathlib import Path
import random
from PIL import Image
import shutil
import torch
from torch.utils.data import DataLoader
from torchvision import datasets, transforms

garbage_classification_folder = r""C:\Users\thien\Desktop\project\dat\Garbage classification\Garbage classification""

# Setup path to data folder
data_path = Path(garbage_classification_folder)

def walk_through_dir(dir_path):
    no_of_files = 0
    for dirpath, dirnames, filenames in os.walk(dir_path):
        # print(f""There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'."")
        no_of_files = len(filenames)
    return no_of_files


# pass in the img dir path (eg. ./cardboard)
def get_random_img_list(dir_path, N):
    random.seed(42)

    # get all image paths (* means ""any combination"")
    image_path_list = list(dir_path.glob(""*.jpg""))

    # get random image paths for training data
    image_list_train = random.sample(image_path_list, k = N)

    # remaining image paths will be used as testing data
    s = set(image_list_train)
    image_list_test = [x for x in image_path_list if x not in s]

    return image_list_train, image_list_test


def make_train_test_folder(dir_path):
    train_folder = dir_path / ""train""
    test_folder = dir_path / ""test""
    if os.path.exists(train_folder):
        shutil.rmtree(train_folder)
    if os.path.exists(test_folder):
        shutil.rmtree(test_folder)
    
    if not os.path.exists(train_folder) and not os.path.exists(test_folder):
        os.mkdir(train_folder)
        os.mkdir(test_folder)
        # we need to select random images from all img folders and build up our train set
        collection = [""cardboard"", ""glass"", ""metal"", ""paper"", ""plastic"", ""trash""]
        for el in collection:
            el_path = dir_path / el
            no_of_imgs = walk_through_dir(el_path)

            # grab 80% of imgs for training
            training_amount = math.floor(0.8 * no_of_imgs)
            training_dat, testing_dat = get_random_img_list(el_path, training_amount)

            os.mkdir(train_folder / el)
            os.mkdir(test_folder / el)

            for train_img_path in training_dat:
                shutil.copy2(src=train_img_path, dst=train_folder / el)
            
            for test_img_path in testing_dat:
                shutil.copy2(src=test_img_path, dst=test_folder / el)


class CNN(torch.nn.Module):
    def __init__(self):
        super().__init__()
        self.model = torch.nn.Sequential(
            #Input = 3 x 128 x 128, Output = 128 x 128 x 128
            torch.nn.Conv2d(in_channels = 3, out_channels = 128, kernel_size = 3, padding = 1), 
            torch.nn.ReLU(),
            #Input = 128 x 128 x 128, Output = 128 x 64 x 64
            torch.nn.MaxPool2d(kernel_size=2),
  
            #Input = 128 x 64 x 64, Output = 256 x 64 x 64
            torch.nn.Conv2d(in_channels = 128, out_channels = 256, kernel_size = 3, padding = 1),
            torch.nn.ReLU(),
            #Input = 256 x 64 x 64, Output = 256 x 32 x 32
            torch.nn.MaxPool2d(kernel_size=2),
              
            #Input = 256 x 32 x 32, Output = 256 x 32 x 32
            torch.nn.Conv2d(in_channels = 256, out_channels = 256, kernel_size = 3, padding = 1),
            torch.nn.ReLU(),
            #Input = 256 x 32 x 32, Output = 256 x 16 x 16
            torch.nn.MaxPool2d(kernel_size=2),

            #Input = 256 x 16 x 16, Output = 128 x 16 x 16
            torch.nn.Conv2d(in_channels = 256, out_channels = 128, kernel_size = 3, padding = 1),
            torch.nn.ReLU(),
            #Input = 128 x 16 x 16, Output = 128 x 8 x 8
            torch.nn.MaxPool2d(kernel_size=2),
  
            torch.nn.Flatten(),
            torch.nn.Linear(128*8*8, 2048),
            torch.nn.ReLU(),
            torch.nn.Linear(2048, 6)
        )
  
    def forward(self, x):
        return self.model(x)


def main():
    # make_train_test_folder(data_path) # uncomment this line if want to build new train and test set

    train_dir = data_path / ""train""
    test_dir = data_path / ""test""

    # Write transform for image
    data_transform = transforms.Compose([
        # Resize the images to 128x128
        transforms.Resize(size=(128, 128)),
        # Turn the image into a torch.Tensor
        transforms.ToTensor(), # this also converts all pixel values from 0 to 255 to be between 0.0 and 1.0 
        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
    ])

    # Use ImageFolder to create dataset(s)
    train_data = datasets.ImageFolder(root=train_dir, # target folder of images
                                    transform=data_transform, # transforms to perform on data (images)
                                    target_transform=None) # transforms to perform on labels (if necessary)

    test_data = datasets.ImageFolder(root=test_dir, 
                                    transform=data_transform)

    # Turn train and test Datasets into DataLoaders
    from torch.utils.data import DataLoader
    batch_size = 32
    train_dataloader = DataLoader(dataset=train_data, batch_size=batch_size, 
                                    num_workers=0, shuffle=True)

    test_dataloader = DataLoader(dataset=test_data, batch_size=batch_size, 
                                    num_workers=0, shuffle=False)

    #Selecting the appropriate training device
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    model = CNN().to(device)

    #Defining the model hyper parameters
    num_epochs = 40
    criterion = torch.nn.CrossEntropyLoss()
    optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)

    train_loss_list = []
    for epoch in range(num_epochs):
        print(f'Epoch {epoch+1}/{num_epochs}:', end = ' ')
        train_loss = 0
        
        #Iterating over the training dataset in batches
        model.train()
        for i, (images, labels) in enumerate(train_dataloader):
            #Extracting images and target labels for the batch being iterated
            images = images.to(device)
            labels = labels.to(device)

            #Calculating the model output and the cross entropy loss
            outputs = model(images)
            loss = criterion(outputs, labels)
    
            #Updating weights according to calculated loss
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
            train_loss += loss.item()
        
        #Printing loss for each epoch
        train_loss_list.append(train_loss/len(train_dataloader))
        print(f""Training loss = {train_loss_list[-1]}"")  

main()",
249,2,,22205,,,output: output.txt;,"c:/Users/thien/Desktop/project/venv/Scripts/python.exe c:/Users/thien/Desktop/project/main.py
Epoch 1/40: Training loss = 1.7813884560018778
Epoch 2/40: Training loss = 1.7432941775768995
Epoch 3/40: Training loss = 1.7143312245607376
Epoch 4/40: Traceback (most recent call last):
  File ""c:/Users/thien/Desktop/project/main.py"", line 177, in <module>
    main()
  File ""c:/Users/thien/Desktop/project/main.py"", line 169, in main
    loss.backward()
  File ""C:\Users\thien\Desktop\project\venv\lib\site-packages\torch\_tensor.py"", line 396, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File ""C:\Users\thien\Desktop\project\venv\lib\site-packages\torch\autograd\__init__.py"", line 173, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt

(venv)",
250,2,https://www.youtube.com/watch?v=OSqIP-mOWOI&list=PL_lsbAsL_o2CTlGHgMxNrKhzP97BaG9ZN&index=4,23736,screencapture-n157_2022-10-28-02_38_56.png,,revisit: Building Models with PyTorch - YouTube;,,
251,2,,26345,,,code: main.py;,"import math
import os
from pathlib import Path
import random
from PIL import Image
import shutil
import torch
from torch.utils.data import DataLoader
from torchvision import datasets, transforms

garbage_classification_folder = r""C:\Users\thien\Desktop\project\dat\Garbage classification\Garbage classification""

# Setup path to data folder
data_path = Path(garbage_classification_folder)

def walk_through_dir(dir_path):
    no_of_files = 0
    for dirpath, dirnames, filenames in os.walk(dir_path):
        # print(f""There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'."")
        no_of_files = len(filenames)
    return no_of_files


# pass in the img dir path (eg. ./cardboard)
def get_random_img_list(dir_path, N):
    random.seed(42)

    # get all image paths (* means ""any combination"")
    image_path_list = list(dir_path.glob(""*.jpg""))

    # get random image paths for training data
    image_list_train = random.sample(image_path_list, k = N)

    # remaining image paths will be used as testing data
    s = set(image_list_train)
    image_list_test = [x for x in image_path_list if x not in s]

    return image_list_train, image_list_test


def make_train_test_folder(dir_path):
    train_folder = dir_path / ""train""
    test_folder = dir_path / ""test""
    if os.path.exists(train_folder):
        shutil.rmtree(train_folder)
    if os.path.exists(test_folder):
        shutil.rmtree(test_folder)
    
    if not os.path.exists(train_folder) and not os.path.exists(test_folder):
        os.mkdir(train_folder)
        os.mkdir(test_folder)
        # we need to select random images from all img folders and build up our train set
        collection = [""cardboard"", ""glass"", ""metal"", ""paper"", ""plastic"", ""trash""]
        for el in collection:
            el_path = dir_path / el
            no_of_imgs = walk_through_dir(el_path)

            # grab 80% of imgs for training
            training_amount = math.floor(0.8 * no_of_imgs)
            training_dat, testing_dat = get_random_img_list(el_path, training_amount)

            os.mkdir(train_folder / el)
            os.mkdir(test_folder / el)

            for train_img_path in training_dat:
                shutil.copy2(src=train_img_path, dst=train_folder / el)
            
            for test_img_path in testing_dat:
                shutil.copy2(src=test_img_path, dst=test_folder / el)


class CNN(torch.nn.Module):
    def __init__(self):
        super().__init__()
        self.model = torch.nn.Sequential(
            #Input = 3 x 128 x 128, Output = 128 x 128 x 128
            torch.nn.Conv2d(in_channels = 3, out_channels = 128, kernel_size = 3, padding = 1), 
            torch.nn.ReLU(),
            #Input = 128 x 128 x 128, Output = 128 x 64 x 64
            torch.nn.MaxPool2d(kernel_size=2),
  
            #Input = 128 x 64 x 64, Output = 256 x 64 x 64
            torch.nn.Conv2d(in_channels = 128, out_channels = 256, kernel_size = 3, padding = 1),
            torch.nn.ReLU(),
            #Input = 256 x 64 x 64, Output = 256 x 32 x 32
            torch.nn.MaxPool2d(kernel_size=2),
              
            #Input = 256 x 32 x 32, Output = 256 x 32 x 32
            torch.nn.Conv2d(in_channels = 256, out_channels = 256, kernel_size = 3, padding = 1),
            torch.nn.ReLU(),
            #Input = 256 x 32 x 32, Output = 256 x 16 x 16
            torch.nn.MaxPool2d(kernel_size=2),

            #Input = 256 x 16 x 16, Output = 128 x 16 x 16
            torch.nn.Conv2d(in_channels = 256, out_channels = 128, kernel_size = 3, padding = 1),
            torch.nn.ReLU(),
            #Input = 128 x 16 x 16, Output = 128 x 8 x 8
            torch.nn.MaxPool2d(kernel_size=2),
  
            torch.nn.Flatten(),
            torch.nn.Linear(128*8*8, 2048),
            torch.nn.ReLU(),
            torch.nn.Linear(2048, 6)
        )
  
    def forward(self, x):
        return self.model(x)


def main():
    # make_train_test_folder(data_path) # uncomment this line if want to build new train and test set

    train_dir = data_path / ""train""
    test_dir = data_path / ""test""

    # Write transform for image
    data_transform = transforms.Compose([
        # Resize the images to 128x128
        transforms.Resize(size=(128, 128)),
        # Turn the image into a torch.Tensor
        transforms.ToTensor(), # this also converts all pixel values from 0 to 255 to be between 0.0 and 1.0 
        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
    ])

    # Use ImageFolder to create dataset(s)
    train_data = datasets.ImageFolder(root=train_dir, # target folder of images
                                    transform=data_transform, # transforms to perform on data (images)
                                    target_transform=None) # transforms to perform on labels (if necessary)

    test_data = datasets.ImageFolder(root=test_dir, 
                                    transform=data_transform)

    # Turn train and test Datasets into DataLoaders
    from torch.utils.data import DataLoader
    batch_size = 32
    train_dataloader = DataLoader(dataset=train_data, batch_size=batch_size, 
                                    num_workers=0, shuffle=True)

    test_dataloader = DataLoader(dataset=test_data, batch_size=batch_size, 
                                    num_workers=0, shuffle=False)

    #Selecting the appropriate training device
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    model = CNN().to(device)

    #Defining the model hyper parameters
    num_epochs = 40
    criterion = torch.nn.CrossEntropyLoss()
    optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)

    train_loss_list = []
    for epoch in range(num_epochs):
        print(f'Epoch {epoch+1}/{num_epochs}:', end = ' ')
        train_loss = 0
        
        #Iterating over the training dataset in batches
        model.train()
        for i, (images, labels) in enumerate(train_dataloader):
            #Extracting images and target labels for the batch being iterated
            images = images.to(device)
            labels = labels.to(device)

            #Calculating the model output and the cross entropy loss
            outputs = model(images)
            loss = criterion(outputs, labels)
    
            #Updating weights according to calculated loss
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
            train_loss += loss.item()
        
        #Printing loss for each epoch
        train_loss_list.append(train_loss/len(train_dataloader))
        print(f""Training loss = {train_loss_list[-1]}"")  

    PATH = './garbage_classification.pth'
    torch.save(model.state_dict(), PATH)

main()",
252,2,,26345,,,output: output.txt;,"c:/Users/thien/Desktop/project/venv/Scripts/python.exe c:/Users/thien/Desktop/project/main.py
Epoch 1/40: Training loss = 1.7854167111217976
Epoch 2/40: Training loss = 1.7471971306949854
Epoch 3/40: Training loss = 1.712446739897132
Epoch 4/40: Training loss = 1.6957744881510735
Epoch 5/40: Training loss = 1.6832782793790102
Epoch 6/40: Training loss = 1.6477041989564896
Epoch 7/40: Training loss = 1.5658220835030079
Epoch 8/40: Training loss = 1.4755164217203856
Epoch 9/40: Training loss = 1.4164458774030209
Epoch 10/40: Training loss = 1.3560378160327673
Epoch 11/40: Training loss = 1.2991477455943823
Epoch 12/40: Training loss = 1.2554121520370245
Epoch 13/40: Training loss = 1.2024528542533517
Epoch 14/40: Training loss = 1.1637245249003172
Epoch 15/40: Training loss = 1.1284416047856212
Epoch 16/40: Training loss = 1.037733152974397
Epoch 17/40: Training loss = 0.9970606658607721
Epoch 18/40: Training loss = 1.005813923664391
Epoch 19/40: Training loss = 0.9700831482186913
Epoch 20/40: Training loss = 0.9626860534772277
Epoch 21/40: Training loss = 0.8919500554911792
Epoch 22/40: Training loss = 0.8850745111703873
Epoch 23/40: Training loss = 0.8252996830269694
Epoch 24/40: Training loss = 0.7723292415030301
Epoch 25/40: Training loss = 0.7522510192357004
Epoch 26/40: Training loss = 0.6952927149832249
Epoch 27/40: Training loss = 0.6584245744161308
Epoch 28/40: Training loss = 0.6631922768428922
Epoch 29/40: Training loss = 0.6314520915038884
Epoch 30/40: Training loss = 0.565929255913943
Epoch 31/40: Training loss = 0.4993853832129389
Epoch 32/40: Training loss = 0.5169962492072955
Epoch 33/40: Training loss = 0.42100979617680423
Epoch 34/40: Training loss = 0.4261490472126752
Epoch 35/40: Training loss = 0.549605994252488
Epoch 36/40: Training loss = 0.3558828205568716
Epoch 37/40: Training loss = 0.3287995143327862
Epoch 38/40: Training loss = 0.29706557022291236
Epoch 39/40: Training loss = 0.2790843365364708
Epoch 40/40: Training loss = 0.2666292732465081
(venv)",
253,2,https://opt-ml.org/papers/2021/paper53.pdf,26373,screencapture-n158_2022-10-28-03_22_53.png,,revisit: Adam vs. SGD: Closing the generalization gap on image classification;,,
254,2,https://www.google.com/search?q=how+to+load+pth+file+pytorch&rlz=1C1SQJL_enUS958US958&oq=how+to+load+pth&aqs=chrome.0.0i512j69i57j0i22i30l2j0i10i22i30j0i22i30l5.8678j0j4&sourceid=chrome&ie=UTF-8,26385,screencapture-n159_2022-10-28-03_23_05.png,,search: how to load pth file pytorch;,,
255,2,https://stackoverflow.com/questions/67657926/how-to-load-pth-file,26387,screencapture-n160_2022-10-28-03_23_07.png,,visit: python - How to load .pth file? - Stack Overflow;,,
256,2,https://pytorch.org/tutorials/beginner/saving_loading_models.html,26405,screencapture-n161_2022-10-28-03_23_25.png,,visit: Saving and Loading Models â€” PyTorch Tutorials 1.12.1+cu102 documentation;,,
257,2,https://www.google.com/search?q=load+pth+file+pytorch+and+testng&rlz=1C1SQJL_enUS958US958&oq=load+pth+file+pytorch+and+test&aqs=chrome.1.69i57j33i160i395l2.15888j1j7&sourceid=chrome&ie=UTF-8,26640,screencapture-n162_2022-10-28-03_27_20.png,,search: load pth file pytorch and testng;,,
258,2,https://discuss.pytorch.org/t/how-to-test-image-for-classification-on-my-pretrained-cnn-pth-file/42692,26648,screencapture-n163_2022-10-28-03_27_28.png,,visit: How to test image for classification on my pretrained CNN .pth file - vision - PyTorch Forums;,,
259,2,https://discuss.pytorch.org/t/how-to-test-image-for-classification-on-my-pretrained-cnn-pth-file/42692/2,26669,screencapture-n164_2022-10-28-03_27_49.png,,visit: How to test image for classification on my pretrained CNN .pth file - #2 by ptrblck - vision - PyTorch Forums;,,
260,2,https://www.learnpytorch.io/04_pytorch_custom_datasets/#41-turn-loaded-images-into-dataloaders,26689,screencapture-n165_2022-10-28-03_28_09.png,,revisit: 04. PyTorch Custom Datasets - Zero to Mastery Learn PyTorch for Deep Learning;,,
261,2,https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html#training-an-image-classifier,26713,screencapture-n166_2022-10-28-03_28_33.png,,revisit: Training a Classifier â€” PyTorch Tutorials 1.13.0+cu117 documentation;,,
262,2,,27066,,,code: main.py;,"import math
import os
from pathlib import Path
import random
from PIL import Image
import shutil
import torch
from torch.utils.data import DataLoader
from torchvision import datasets, transforms

garbage_classification_folder = r""C:\Users\thien\Desktop\project\dat\Garbage classification\Garbage classification""

# Setup path to data folder
data_path = Path(garbage_classification_folder)

def walk_through_dir(dir_path):
    no_of_files = 0
    for dirpath, dirnames, filenames in os.walk(dir_path):
        # print(f""There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'."")
        no_of_files = len(filenames)
    return no_of_files


# pass in the img dir path (eg. ./cardboard)
def get_random_img_list(dir_path, N):
    random.seed(42)

    # get all image paths (* means ""any combination"")
    image_path_list = list(dir_path.glob(""*.jpg""))

    # get random image paths for training data
    image_list_train = random.sample(image_path_list, k = N)

    # remaining image paths will be used as testing data
    s = set(image_list_train)
    image_list_test = [x for x in image_path_list if x not in s]

    return image_list_train, image_list_test


def make_train_test_folder(dir_path):
    train_folder = dir_path / ""train""
    test_folder = dir_path / ""test""
    if os.path.exists(train_folder):
        shutil.rmtree(train_folder)
    if os.path.exists(test_folder):
        shutil.rmtree(test_folder)
    
    if not os.path.exists(train_folder) and not os.path.exists(test_folder):
        os.mkdir(train_folder)
        os.mkdir(test_folder)
        # we need to select random images from all img folders and build up our train set
        collection = [""cardboard"", ""glass"", ""metal"", ""paper"", ""plastic"", ""trash""]
        for el in collection:
            el_path = dir_path / el
            no_of_imgs = walk_through_dir(el_path)

            # grab 80% of imgs for training
            training_amount = math.floor(0.8 * no_of_imgs)
            training_dat, testing_dat = get_random_img_list(el_path, training_amount)

            os.mkdir(train_folder / el)
            os.mkdir(test_folder / el)

            for train_img_path in training_dat:
                shutil.copy2(src=train_img_path, dst=train_folder / el)
            
            for test_img_path in testing_dat:
                shutil.copy2(src=test_img_path, dst=test_folder / el)


class CNN(torch.nn.Module):
    def __init__(self):
        super().__init__()
        self.model = torch.nn.Sequential(
            #Input = 3 x 128 x 128, Output = 128 x 128 x 128
            torch.nn.Conv2d(in_channels = 3, out_channels = 128, kernel_size = 3, padding = 1), 
            torch.nn.ReLU(),
            #Input = 128 x 128 x 128, Output = 128 x 64 x 64
            torch.nn.MaxPool2d(kernel_size=2),
  
            #Input = 128 x 64 x 64, Output = 256 x 64 x 64
            torch.nn.Conv2d(in_channels = 128, out_channels = 256, kernel_size = 3, padding = 1),
            torch.nn.ReLU(),
            #Input = 256 x 64 x 64, Output = 256 x 32 x 32
            torch.nn.MaxPool2d(kernel_size=2),
              
            #Input = 256 x 32 x 32, Output = 256 x 32 x 32
            torch.nn.Conv2d(in_channels = 256, out_channels = 256, kernel_size = 3, padding = 1),
            torch.nn.ReLU(),
            #Input = 256 x 32 x 32, Output = 256 x 16 x 16
            torch.nn.MaxPool2d(kernel_size=2),

            #Input = 256 x 16 x 16, Output = 128 x 16 x 16
            torch.nn.Conv2d(in_channels = 256, out_channels = 128, kernel_size = 3, padding = 1),
            torch.nn.ReLU(),
            #Input = 128 x 16 x 16, Output = 128 x 8 x 8
            torch.nn.MaxPool2d(kernel_size=2),
  
            torch.nn.Flatten(),
            torch.nn.Linear(128*8*8, 2048),
            torch.nn.ReLU(),
            torch.nn.Linear(2048, 6)
        )
  
    def forward(self, x):
        return self.model(x)


def main():
    # make_train_test_folder(data_path) # uncomment this line if want to build new train and test set

    train_dir = data_path / ""train""
    test_dir = data_path / ""test""

    # Write transform for image
    data_transform = transforms.Compose([
        # Resize the images to 128x128
        transforms.Resize(size=(128, 128)),
        # Turn the image into a torch.Tensor
        transforms.ToTensor(), # this also converts all pixel values from 0 to 255 to be between 0.0 and 1.0 
        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
    ])

    # Use ImageFolder to create dataset(s)
    train_data = datasets.ImageFolder(root=train_dir, # target folder of images
                                    transform=data_transform, # transforms to perform on data (images)
                                    target_transform=None) # transforms to perform on labels (if necessary)

    test_data = datasets.ImageFolder(root=test_dir, 
                                    transform=data_transform)

    # Turn train and test Datasets into DataLoaders
    from torch.utils.data import DataLoader
    batch_size = 32
    train_dataloader = DataLoader(dataset=train_data, batch_size=batch_size, 
                                    num_workers=0, shuffle=True)

    test_dataloader = DataLoader(dataset=test_data, batch_size=batch_size, 
                                    num_workers=0, shuffle=False)

    #Selecting the appropriate training device
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    # model = CNN().to(device)

    # #Defining the model hyper parameters
    # num_epochs = 40
    # criterion = torch.nn.CrossEntropyLoss()
    # optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)

    # train_loss_list = []
    # for epoch in range(num_epochs):
    #     print(f'Epoch {epoch+1}/{num_epochs}:', end = ' ')
    #     train_loss = 0
        
    #     #Iterating over the training dataset in batches
    #     model.train()
    #     for i, (images, labels) in enumerate(train_dataloader):
    #         #Extracting images and target labels for the batch being iterated
    #         images = images.to(device)
    #         labels = labels.to(device)

    #         #Calculating the model output and the cross entropy loss
    #         outputs = model(images)
    #         loss = criterion(outputs, labels)
    
    #         #Updating weights according to calculated loss
    #         optimizer.zero_grad()
    #         loss.backward()
    #         optimizer.step()
    #         train_loss += loss.item()
        
    #     #Printing loss for each epoch
    #     train_loss_list.append(train_loss/len(train_dataloader))
    #     print(f""Training loss = {train_loss_list[-1]}"")  

    PATH = './garbage_classification.pth'
    # torch.save(model.state_dict(), PATH)

    model = CNN().to(device)
    model.load_state_dict(torch.load(PATH))
    model.eval()

    dataiter = iter(test_dataloader)
    images, labels = next(dataiter)

    outputs = model(images)

    _, predicted = torch.max(outputs, 1)
    print('Predicted: ', ' '.join(f'{classes[predicted[j]]:5s}' for j in range(4)))

    from plot_func import imshow
    import torchvision

    classes = (""cardboard"", ""glass"", ""metal"", ""paper"", ""plastic"", ""trash"")

    # print images
    imshow(torchvision.utils.make_grid(images))
    print('GroundTruth: ', ' '.join(f'{classes[labels[j]]:5s}' for j in range(4)))

main()",
263,2,,27066,,,output: output.txt;,"c:/Users/thien/Desktop/project/venv/Scripts/python.exe c:/Users/thien/Desktop/project/main.py
Traceback (most recent call last):
  File ""c:/Users/thien/Desktop/project/main.py"", line 201, in <module>
    main()
  File ""c:/Users/thien/Desktop/project/main.py"", line 190, in main
    print('Predicted: ', ' '.join(f'{classes[predicted[j]]:5s}' for j in range(4)))
  File ""c:/Users/thien/Desktop/project/main.py"", line 190, in <genexpr>
    print('Predicted: ', ' '.join(f'{classes[predicted[j]]:5s}' for j in range(4)))
NameError: free variable 'classes' referenced before assignment in enclosing scope
(venv)",
264,2,,27128,,,code: main.py;,"import math
import os
from pathlib import Path
import random
from PIL import Image
import shutil
import torch
from torch.utils.data import DataLoader
from torchvision import datasets, transforms

garbage_classification_folder = r""C:\Users\thien\Desktop\project\dat\Garbage classification\Garbage classification""

# Setup path to data folder
data_path = Path(garbage_classification_folder)

def walk_through_dir(dir_path):
    no_of_files = 0
    for dirpath, dirnames, filenames in os.walk(dir_path):
        # print(f""There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'."")
        no_of_files = len(filenames)
    return no_of_files


# pass in the img dir path (eg. ./cardboard)
def get_random_img_list(dir_path, N):
    random.seed(42)

    # get all image paths (* means ""any combination"")
    image_path_list = list(dir_path.glob(""*.jpg""))

    # get random image paths for training data
    image_list_train = random.sample(image_path_list, k = N)

    # remaining image paths will be used as testing data
    s = set(image_list_train)
    image_list_test = [x for x in image_path_list if x not in s]

    return image_list_train, image_list_test


def make_train_test_folder(dir_path):
    train_folder = dir_path / ""train""
    test_folder = dir_path / ""test""
    if os.path.exists(train_folder):
        shutil.rmtree(train_folder)
    if os.path.exists(test_folder):
        shutil.rmtree(test_folder)
    
    if not os.path.exists(train_folder) and not os.path.exists(test_folder):
        os.mkdir(train_folder)
        os.mkdir(test_folder)
        # we need to select random images from all img folders and build up our train set
        collection = [""cardboard"", ""glass"", ""metal"", ""paper"", ""plastic"", ""trash""]
        for el in collection:
            el_path = dir_path / el
            no_of_imgs = walk_through_dir(el_path)

            # grab 80% of imgs for training
            training_amount = math.floor(0.8 * no_of_imgs)
            training_dat, testing_dat = get_random_img_list(el_path, training_amount)

            os.mkdir(train_folder / el)
            os.mkdir(test_folder / el)

            for train_img_path in training_dat:
                shutil.copy2(src=train_img_path, dst=train_folder / el)
            
            for test_img_path in testing_dat:
                shutil.copy2(src=test_img_path, dst=test_folder / el)


class CNN(torch.nn.Module):
    def __init__(self):
        super().__init__()
        self.model = torch.nn.Sequential(
            #Input = 3 x 128 x 128, Output = 128 x 128 x 128
            torch.nn.Conv2d(in_channels = 3, out_channels = 128, kernel_size = 3, padding = 1), 
            torch.nn.ReLU(),
            #Input = 128 x 128 x 128, Output = 128 x 64 x 64
            torch.nn.MaxPool2d(kernel_size=2),
  
            #Input = 128 x 64 x 64, Output = 256 x 64 x 64
            torch.nn.Conv2d(in_channels = 128, out_channels = 256, kernel_size = 3, padding = 1),
            torch.nn.ReLU(),
            #Input = 256 x 64 x 64, Output = 256 x 32 x 32
            torch.nn.MaxPool2d(kernel_size=2),
              
            #Input = 256 x 32 x 32, Output = 256 x 32 x 32
            torch.nn.Conv2d(in_channels = 256, out_channels = 256, kernel_size = 3, padding = 1),
            torch.nn.ReLU(),
            #Input = 256 x 32 x 32, Output = 256 x 16 x 16
            torch.nn.MaxPool2d(kernel_size=2),

            #Input = 256 x 16 x 16, Output = 128 x 16 x 16
            torch.nn.Conv2d(in_channels = 256, out_channels = 128, kernel_size = 3, padding = 1),
            torch.nn.ReLU(),
            #Input = 128 x 16 x 16, Output = 128 x 8 x 8
            torch.nn.MaxPool2d(kernel_size=2),
  
            torch.nn.Flatten(),
            torch.nn.Linear(128*8*8, 2048),
            torch.nn.ReLU(),
            torch.nn.Linear(2048, 6)
        )
  
    def forward(self, x):
        return self.model(x)


def main():
    # make_train_test_folder(data_path) # uncomment this line if want to build new train and test set

    train_dir = data_path / ""train""
    test_dir = data_path / ""test""

    # Write transform for image
    data_transform = transforms.Compose([
        # Resize the images to 128x128
        transforms.Resize(size=(128, 128)),
        # Turn the image into a torch.Tensor
        transforms.ToTensor(), # this also converts all pixel values from 0 to 255 to be between 0.0 and 1.0 
        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
    ])

    # Use ImageFolder to create dataset(s)
    train_data = datasets.ImageFolder(root=train_dir, # target folder of images
                                    transform=data_transform, # transforms to perform on data (images)
                                    target_transform=None) # transforms to perform on labels (if necessary)

    test_data = datasets.ImageFolder(root=test_dir, 
                                    transform=data_transform)

    # Turn train and test Datasets into DataLoaders
    from torch.utils.data import DataLoader
    batch_size = 32
    train_dataloader = DataLoader(dataset=train_data, batch_size=batch_size, 
                                    num_workers=0, shuffle=True)

    test_dataloader = DataLoader(dataset=test_data, batch_size=batch_size, 
                                    num_workers=0, shuffle=False)

    #Selecting the appropriate training device
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    # model = CNN().to(device)

    # #Defining the model hyper parameters
    # num_epochs = 40
    # criterion = torch.nn.CrossEntropyLoss()
    # optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)

    # train_loss_list = []
    # for epoch in range(num_epochs):
    #     print(f'Epoch {epoch+1}/{num_epochs}:', end = ' ')
    #     train_loss = 0
        
    #     #Iterating over the training dataset in batches
    #     model.train()
    #     for i, (images, labels) in enumerate(train_dataloader):
    #         #Extracting images and target labels for the batch being iterated
    #         images = images.to(device)
    #         labels = labels.to(device)

    #         #Calculating the model output and the cross entropy loss
    #         outputs = model(images)
    #         loss = criterion(outputs, labels)
    
    #         #Updating weights according to calculated loss
    #         optimizer.zero_grad()
    #         loss.backward()
    #         optimizer.step()
    #         train_loss += loss.item()
        
    #     #Printing loss for each epoch
    #     train_loss_list.append(train_loss/len(train_dataloader))
    #     print(f""Training loss = {train_loss_list[-1]}"")  

    PATH = './garbage_classification.pth'
    # torch.save(model.state_dict(), PATH)

    model = CNN().to(device)
    model.load_state_dict(torch.load(PATH))
    model.eval()

    classes = (""cardboard"", ""glass"", ""metal"", ""paper"", ""plastic"", ""trash"")

    dataiter = iter(test_dataloader)
    images, labels = next(dataiter)

    outputs = model(images)
    _, predicted = torch.max(outputs, 1)
    print('Predicted: ', ' '.join(f'{classes[predicted[j]]:5s}' for j in range(4)))

    from plot_func import imshow
    import torchvision

    # print images
    imshow(torchvision.utils.make_grid(images))
    print('GroundTruth: ', ' '.join(f'{classes[labels[j]]:5s}' for j in range(4)))

main()",
265,2,,27128,,,output: output.txt;,"c:/Users/thien/Desktop/project/venv/Scripts/python.exe c:/Users/thien/Desktop/project/main.py
Predicted:  glass cardboard cardboard metal
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
GroundTruth:  cardboard cardboard cardboard cardboard
(venv)",
266,2,,27322,,,code: main.py;,"import math
import os
from pathlib import Path
import random
from PIL import Image
import shutil
import torch
from torch.utils.data import DataLoader
from torchvision import datasets, transforms

garbage_classification_folder = r""C:\Users\thien\Desktop\project\dat\Garbage classification\Garbage classification""

# Setup path to data folder
data_path = Path(garbage_classification_folder)

def walk_through_dir(dir_path):
    no_of_files = 0
    for dirpath, dirnames, filenames in os.walk(dir_path):
        # print(f""There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'."")
        no_of_files = len(filenames)
    return no_of_files


# pass in the img dir path (eg. ./cardboard)
def get_random_img_list(dir_path, N):
    random.seed(42)

    # get all image paths (* means ""any combination"")
    image_path_list = list(dir_path.glob(""*.jpg""))

    # get random image paths for training data
    image_list_train = random.sample(image_path_list, k = N)

    # remaining image paths will be used as testing data
    s = set(image_list_train)
    image_list_test = [x for x in image_path_list if x not in s]

    return image_list_train, image_list_test


def make_train_test_folder(dir_path):
    train_folder = dir_path / ""train""
    test_folder = dir_path / ""test""
    if os.path.exists(train_folder):
        shutil.rmtree(train_folder)
    if os.path.exists(test_folder):
        shutil.rmtree(test_folder)
    
    if not os.path.exists(train_folder) and not os.path.exists(test_folder):
        os.mkdir(train_folder)
        os.mkdir(test_folder)
        # we need to select random images from all img folders and build up our train set
        collection = [""cardboard"", ""glass"", ""metal"", ""paper"", ""plastic"", ""trash""]
        for el in collection:
            el_path = dir_path / el
            no_of_imgs = walk_through_dir(el_path)

            # grab 80% of imgs for training
            training_amount = math.floor(0.8 * no_of_imgs)
            training_dat, testing_dat = get_random_img_list(el_path, training_amount)

            os.mkdir(train_folder / el)
            os.mkdir(test_folder / el)

            for train_img_path in training_dat:
                shutil.copy2(src=train_img_path, dst=train_folder / el)
            
            for test_img_path in testing_dat:
                shutil.copy2(src=test_img_path, dst=test_folder / el)


class CNN(torch.nn.Module):
    def __init__(self):
        super().__init__()
        self.model = torch.nn.Sequential(
            #Input = 3 x 128 x 128, Output = 128 x 128 x 128
            torch.nn.Conv2d(in_channels = 3, out_channels = 128, kernel_size = 3, padding = 1), 
            torch.nn.ReLU(),
            #Input = 128 x 128 x 128, Output = 128 x 64 x 64
            torch.nn.MaxPool2d(kernel_size=2),
  
            #Input = 128 x 64 x 64, Output = 256 x 64 x 64
            torch.nn.Conv2d(in_channels = 128, out_channels = 256, kernel_size = 3, padding = 1),
            torch.nn.ReLU(),
            #Input = 256 x 64 x 64, Output = 256 x 32 x 32
            torch.nn.MaxPool2d(kernel_size=2),
              
            #Input = 256 x 32 x 32, Output = 256 x 32 x 32
            torch.nn.Conv2d(in_channels = 256, out_channels = 256, kernel_size = 3, padding = 1),
            torch.nn.ReLU(),
            #Input = 256 x 32 x 32, Output = 256 x 16 x 16
            torch.nn.MaxPool2d(kernel_size=2),

            #Input = 256 x 16 x 16, Output = 128 x 16 x 16
            torch.nn.Conv2d(in_channels = 256, out_channels = 128, kernel_size = 3, padding = 1),
            torch.nn.ReLU(),
            #Input = 128 x 16 x 16, Output = 128 x 8 x 8
            torch.nn.MaxPool2d(kernel_size=2),
  
            torch.nn.Flatten(),
            torch.nn.Linear(128*8*8, 2048),
            torch.nn.ReLU(),
            torch.nn.Linear(2048, 6)
        )
  
    def forward(self, x):
        return self.model(x)


def main():
    # make_train_test_folder(data_path) # uncomment this line if want to build new train and test set

    train_dir = data_path / ""train""
    test_dir = data_path / ""test""

    # Write transform for image
    data_transform = transforms.Compose([
        # Resize the images to 128x128
        transforms.Resize(size=(128, 128)),
        # Turn the image into a torch.Tensor
        transforms.ToTensor(), # this also converts all pixel values from 0 to 255 to be between 0.0 and 1.0 
        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
    ])

    # Use ImageFolder to create dataset(s)
    train_data = datasets.ImageFolder(root=train_dir, # target folder of images
                                    transform=data_transform, # transforms to perform on data (images)
                                    target_transform=None) # transforms to perform on labels (if necessary)

    test_data = datasets.ImageFolder(root=test_dir, 
                                    transform=data_transform)

    # Turn train and test Datasets into DataLoaders
    from torch.utils.data import DataLoader
    batch_size = 32
    train_dataloader = DataLoader(dataset=train_data, batch_size=batch_size, 
                                    num_workers=0, shuffle=True)

    test_dataloader = DataLoader(dataset=test_data, batch_size=batch_size, 
                                    num_workers=0, shuffle=False)

    #Selecting the appropriate training device
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    # model = CNN().to(device)

    # #Defining the model hyper parameters
    # num_epochs = 40
    # criterion = torch.nn.CrossEntropyLoss()
    # optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)

    # train_loss_list = []
    # for epoch in range(num_epochs):
    #     print(f'Epoch {epoch+1}/{num_epochs}:', end = ' ')
    #     train_loss = 0
        
    #     #Iterating over the training dataset in batches
    #     model.train()
    #     for i, (images, labels) in enumerate(train_dataloader):
    #         #Extracting images and target labels for the batch being iterated
    #         images = images.to(device)
    #         labels = labels.to(device)

    #         #Calculating the model output and the cross entropy loss
    #         outputs = model(images)
    #         loss = criterion(outputs, labels)
    
    #         #Updating weights according to calculated loss
    #         optimizer.zero_grad()
    #         loss.backward()
    #         optimizer.step()
    #         train_loss += loss.item()
        
    #     #Printing loss for each epoch
    #     train_loss_list.append(train_loss/len(train_dataloader))
    #     print(f""Training loss = {train_loss_list[-1]}"")  

    PATH = './garbage_classification.pth'
    # torch.save(model.state_dict(), PATH)

    model = CNN().to(device)
    model.load_state_dict(torch.load(PATH))
    model.eval()

    classes = (""cardboard"", ""glass"", ""metal"", ""paper"", ""plastic"", ""trash"")

    dataiter = iter(test_dataloader)
    images, labels = next(dataiter)

    outputs = model(images)
    _, predicted = torch.max(outputs, 1)
    print('Predicted: ', ' '.join(f'{classes[predicted[j]]:5s}' for j in range(batch_size)))

    from plot_func import imshow
    import torchvision

    # print images
    imshow(torchvision.utils.make_grid(images))
    print('GroundTruth: ', ' '.join(f'{classes[labels[j]]:5s}' for j in range(batch_size)))

main()",
267,2,,27322,,,output: output.txt;,"c:/Users/thien/Desktop/project/venv/Scripts/python.exe c:/Users/thien/Desktop/project/main.py
Predicted:  glass cardboard cardboard metal metal cardboard cardboard cardboard cardboard cardboard paper metal plastic cardboard cardboard cardboard cardboard cardboard paper plastic cardboard cardboard paper paper cardboard cardboard ca
dboard cardboard cardboard metal plastic cardboard
GroundTruth:  cardboard cardboard cardboard cardboard cardboard cardboard cardboard cardboard cardboard cardboard cardboard cardboard cardboard cardboard cardboard cardboard cardboard cardboard cardboard cardboard cardboard cardboard card
oard cardboard cardboard cardboard cardboard cardboard cardboard cardboard cardboard cardboard
(venv)",
268,2,,27322,,,code: plot_func.py;,"import random
from PIL import Image
import matplotlib.pyplot as plt
import numpy as np

# eg. call: plot_transformed_images(image_path_list, transform=data_transform, n=1)
def plot_transformed_images(image_paths, transform, n):
    # Plots a series of random images from image_paths.
    # Will open n image paths from image_paths, transform them
    # with transform and plot them side by side.
    random.seed(42)
    random_image_paths = random.sample(image_paths, k=n)
    for image_path in random_image_paths:
        with Image.open(image_path) as f:
            fig, ax = plt.subplots(1, 2)
            ax[0].imshow(f) 
            ax[0].set_title(f""Original \nSize: {f.size}"")
            ax[0].axis(""off"")

            # Transform and plot image
            # Note: permute() will change shape of image to suit matplotlib 
            # (PyTorch default is [C, H, W] but Matplotlib is [H, W, C])
            transformed_image = transform(f).permute(1, 2, 0) 
            ax[1].imshow(transformed_image) 
            ax[1].set_title(f""Transformed \nSize: {transformed_image.shape}"")
            ax[1].axis(""off"")

            fig.suptitle(f""Class: {image_path.parent.stem}"", fontsize=16)
            plt.show(block=False)
            plt.pause(10)
            plt.close()


# eg. imshow(torchvision.utils.make_grid(images))
def imshow(img):
    img = img / 2 + 0.5     # unnormalize
    npimg = img.numpy()
    plt.imshow(np.transpose(npimg, (1, 2, 0)))
    plt.show()",
269,2,,27602,,,code: main.py;,"import math
import os
from pathlib import Path
import random
from PIL import Image
import shutil
import torch
from torch.utils.data import DataLoader
from torchvision import datasets, transforms

garbage_classification_folder = r""C:\Users\thien\Desktop\project\dat\Garbage classification\Garbage classification""

# Setup path to data folder
data_path = Path(garbage_classification_folder)

def walk_through_dir(dir_path):
    no_of_files = 0
    for dirpath, dirnames, filenames in os.walk(dir_path):
        # print(f""There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'."")
        no_of_files = len(filenames)
    return no_of_files


# pass in the img dir path (eg. ./cardboard)
def get_random_img_list(dir_path, N):
    random.seed(42)

    # get all image paths (* means ""any combination"")
    image_path_list = list(dir_path.glob(""*.jpg""))

    # get random image paths for training data
    image_list_train = random.sample(image_path_list, k = N)

    # remaining image paths will be used as testing data
    s = set(image_list_train)
    image_list_test = [x for x in image_path_list if x not in s]

    return image_list_train, image_list_test


def make_train_test_folder(dir_path):
    train_folder = dir_path / ""train""
    test_folder = dir_path / ""test""
    if os.path.exists(train_folder):
        shutil.rmtree(train_folder)
    if os.path.exists(test_folder):
        shutil.rmtree(test_folder)
    
    if not os.path.exists(train_folder) and not os.path.exists(test_folder):
        os.mkdir(train_folder)
        os.mkdir(test_folder)
        # we need to select random images from all img folders and build up our train set
        collection = [""cardboard"", ""glass"", ""metal"", ""paper"", ""plastic"", ""trash""]
        for el in collection:
            el_path = dir_path / el
            no_of_imgs = walk_through_dir(el_path)

            # grab 80% of imgs for training
            training_amount = math.floor(0.8 * no_of_imgs)
            training_dat, testing_dat = get_random_img_list(el_path, training_amount)

            os.mkdir(train_folder / el)
            os.mkdir(test_folder / el)

            for train_img_path in training_dat:
                shutil.copy2(src=train_img_path, dst=train_folder / el)
            
            for test_img_path in testing_dat:
                shutil.copy2(src=test_img_path, dst=test_folder / el)


class CNN(torch.nn.Module):
    def __init__(self):
        super().__init__()
        self.model = torch.nn.Sequential(
            #Input = 3 x 128 x 128, Output = 128 x 128 x 128
            torch.nn.Conv2d(in_channels = 3, out_channels = 128, kernel_size = 3, padding = 1), 
            torch.nn.ReLU(),
            #Input = 128 x 128 x 128, Output = 128 x 64 x 64
            torch.nn.MaxPool2d(kernel_size=2),
  
            #Input = 128 x 64 x 64, Output = 256 x 64 x 64
            torch.nn.Conv2d(in_channels = 128, out_channels = 256, kernel_size = 3, padding = 1),
            torch.nn.ReLU(),
            #Input = 256 x 64 x 64, Output = 256 x 32 x 32
            torch.nn.MaxPool2d(kernel_size=2),
              
            #Input = 256 x 32 x 32, Output = 256 x 32 x 32
            torch.nn.Conv2d(in_channels = 256, out_channels = 256, kernel_size = 3, padding = 1),
            torch.nn.ReLU(),
            #Input = 256 x 32 x 32, Output = 256 x 16 x 16
            torch.nn.MaxPool2d(kernel_size=2),

            #Input = 256 x 16 x 16, Output = 128 x 16 x 16
            torch.nn.Conv2d(in_channels = 256, out_channels = 128, kernel_size = 3, padding = 1),
            torch.nn.ReLU(),
            #Input = 128 x 16 x 16, Output = 128 x 8 x 8
            torch.nn.MaxPool2d(kernel_size=2),
  
            torch.nn.Flatten(),
            torch.nn.Linear(128*8*8, 2048),
            torch.nn.ReLU(),
            torch.nn.Linear(2048, 6)
        )
  
    def forward(self, x):
        return self.model(x)


def main():
    # make_train_test_folder(data_path) # uncomment this line if want to build new train and test set

    train_dir = data_path / ""train""
    test_dir = data_path / ""test""

    # Write transform for image
    data_transform = transforms.Compose([
        # Resize the images to 128x128
        transforms.Resize(size=(128, 128)),
        # Turn the image into a torch.Tensor
        transforms.ToTensor(), # this also converts all pixel values from 0 to 255 to be between 0.0 and 1.0 
        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
    ])

    # Use ImageFolder to create dataset(s)
    train_data = datasets.ImageFolder(root=train_dir, # target folder of images
                                    transform=data_transform, # transforms to perform on data (images)
                                    target_transform=None) # transforms to perform on labels (if necessary)

    test_data = datasets.ImageFolder(root=test_dir, 
                                    transform=data_transform)

    # Turn train and test Datasets into DataLoaders
    from torch.utils.data import DataLoader
    batch_size = 32
    train_dataloader = DataLoader(dataset=train_data, batch_size=batch_size, 
                                    num_workers=0, shuffle=True)

    test_dataloader = DataLoader(dataset=test_data, batch_size=batch_size, 
                                    num_workers=0, shuffle=False)

    #Selecting the appropriate training device
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    # model = CNN().to(device)

    # #Defining the model hyper parameters
    # num_epochs = 40
    # criterion = torch.nn.CrossEntropyLoss()
    # optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)

    # train_loss_list = []
    # for epoch in range(num_epochs):
    #     print(f'Epoch {epoch+1}/{num_epochs}:', end = ' ')
    #     train_loss = 0
        
    #     #Iterating over the training dataset in batches
    #     model.train()
    #     for i, (images, labels) in enumerate(train_dataloader):
    #         #Extracting images and target labels for the batch being iterated
    #         images = images.to(device)
    #         labels = labels.to(device)

    #         #Calculating the model output and the cross entropy loss
    #         outputs = model(images)
    #         loss = criterion(outputs, labels)
    
    #         #Updating weights according to calculated loss
    #         optimizer.zero_grad()
    #         loss.backward()
    #         optimizer.step()
    #         train_loss += loss.item()
        
    #     #Printing loss for each epoch
    #     train_loss_list.append(train_loss/len(train_dataloader))
    #     print(f""Training loss = {train_loss_list[-1]}"")  

    PATH = './garbage_classification.pth'
    # torch.save(model.state_dict(), PATH)

    model = CNN().to(device)
    model.load_state_dict(torch.load(PATH))
    model.eval()

    classes = (""cardboard"", ""glass"", ""metal"", ""paper"", ""plastic"", ""trash"")

    correct = 0
    total = 0
    # since we're not training, we don't need to calculate the gradients for our outputs
    with torch.no_grad():
        for data in test_dataloader:
            images, labels = data
            # calculate outputs by running images through the network
            outputs = model(images)
            # the class with the highest energy is what we choose as prediction
            _, predicted = torch.max(outputs.data, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()

    print(f'Accuracy of the network on the test images: {100 * correct // total} %')

main()",
270,2,,27602,,,output: output.txt;,"c:/Users/thien/Desktop/project/venv/Scripts/python.exe c:/Users/thien/Desktop/project/main.py
Accuracy of the network on the test images: 62 %
(venv)",
271,2,https://www.google.com/search?q=making+a+confusion+matrix+pytorch&rlz=1C1SQJL_enUS958US958&oq=making+a+confusion+matrix+pytorch&aqs=chrome..69i57j0i22i30j0i390.11338j1j7&sourceid=chrome&ie=UTF-8,27670,screencapture-n167_2022-10-28-03_44_30.png,,search: making a confusion matrix pytorch;,,
272,2,https://torchmetrics.readthedocs.io/en/stable/classification/confusion_matrix.html,27675,screencapture-n168_2022-10-28-03_44_35.png,,visit: Confusion Matrix â€” PyTorch-Metrics 0.11.0 documentation;,,
273,2,https://androidkt.com/pytorch-confusion-matrix-for-multi-class-image-classification/,27691,screencapture-n169_2022-10-28-03_44_51.png,,visit: PyTorch Confusion Matrix for multi-class image classification - Knowledge Transfer;,,
274,2,https://www.google.com/search?q=scikit+learn+confusion+matrix&rlz=1C1SQJL_enUS958US958&oq=scikit+learn+con&aqs=chrome.0.0i67j69i57j0i512j0i67j0i20i263i512j0i512l5.4920j0j7&sourceid=chrome&ie=UTF-8,27903,screencapture-n170_2022-10-28-03_48_23.png,,search: scikit learn confusion matrix;,,
275,2,https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html,27904,screencapture-n171_2022-10-28-03_48_24.png,,visit: sklearn.metrics.confusion_matrix â€” scikit-learn 1.2.0 documentation;,,
276,2,https://androidkt.com/pytorch-confusion-matrix-for-multi-class-image-classification/,27966,screencapture-n172_2022-10-28-03_49_26.png,,revisit: PyTorch Confusion Matrix for multi-class image classification - Knowledge Transfer;,,
277,2,,28154,,,code: main.py;,"import math
import os
from pathlib import Path
import random
from PIL import Image
import shutil
import torch
from torch.utils.data import DataLoader
from torchvision import datasets, transforms

garbage_classification_folder = r""C:\Users\thien\Desktop\project\dat\Garbage classification\Garbage classification""

# Setup path to data folder
data_path = Path(garbage_classification_folder)

def walk_through_dir(dir_path):
    no_of_files = 0
    for dirpath, dirnames, filenames in os.walk(dir_path):
        # print(f""There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'."")
        no_of_files = len(filenames)
    return no_of_files


# pass in the img dir path (eg. ./cardboard)
def get_random_img_list(dir_path, N):
    random.seed(42)

    # get all image paths (* means ""any combination"")
    image_path_list = list(dir_path.glob(""*.jpg""))

    # get random image paths for training data
    image_list_train = random.sample(image_path_list, k = N)

    # remaining image paths will be used as testing data
    s = set(image_list_train)
    image_list_test = [x for x in image_path_list if x not in s]

    return image_list_train, image_list_test


def make_train_test_folder(dir_path):
    train_folder = dir_path / ""train""
    test_folder = dir_path / ""test""
    if os.path.exists(train_folder):
        shutil.rmtree(train_folder)
    if os.path.exists(test_folder):
        shutil.rmtree(test_folder)
    
    if not os.path.exists(train_folder) and not os.path.exists(test_folder):
        os.mkdir(train_folder)
        os.mkdir(test_folder)
        # we need to select random images from all img folders and build up our train set
        collection = [""cardboard"", ""glass"", ""metal"", ""paper"", ""plastic"", ""trash""]
        for el in collection:
            el_path = dir_path / el
            no_of_imgs = walk_through_dir(el_path)

            # grab 80% of imgs for training
            training_amount = math.floor(0.8 * no_of_imgs)
            training_dat, testing_dat = get_random_img_list(el_path, training_amount)

            os.mkdir(train_folder / el)
            os.mkdir(test_folder / el)

            for train_img_path in training_dat:
                shutil.copy2(src=train_img_path, dst=train_folder / el)
            
            for test_img_path in testing_dat:
                shutil.copy2(src=test_img_path, dst=test_folder / el)


class CNN(torch.nn.Module):
    def __init__(self):
        super().__init__()
        self.model = torch.nn.Sequential(
            #Input = 3 x 128 x 128, Output = 128 x 128 x 128
            torch.nn.Conv2d(in_channels = 3, out_channels = 128, kernel_size = 3, padding = 1), 
            torch.nn.ReLU(),
            #Input = 128 x 128 x 128, Output = 128 x 64 x 64
            torch.nn.MaxPool2d(kernel_size=2),
  
            #Input = 128 x 64 x 64, Output = 256 x 64 x 64
            torch.nn.Conv2d(in_channels = 128, out_channels = 256, kernel_size = 3, padding = 1),
            torch.nn.ReLU(),
            #Input = 256 x 64 x 64, Output = 256 x 32 x 32
            torch.nn.MaxPool2d(kernel_size=2),
              
            #Input = 256 x 32 x 32, Output = 256 x 32 x 32
            torch.nn.Conv2d(in_channels = 256, out_channels = 256, kernel_size = 3, padding = 1),
            torch.nn.ReLU(),
            #Input = 256 x 32 x 32, Output = 256 x 16 x 16
            torch.nn.MaxPool2d(kernel_size=2),

            #Input = 256 x 16 x 16, Output = 128 x 16 x 16
            torch.nn.Conv2d(in_channels = 256, out_channels = 128, kernel_size = 3, padding = 1),
            torch.nn.ReLU(),
            #Input = 128 x 16 x 16, Output = 128 x 8 x 8
            torch.nn.MaxPool2d(kernel_size=2),
  
            torch.nn.Flatten(),
            torch.nn.Linear(128*8*8, 2048),
            torch.nn.ReLU(),
            torch.nn.Linear(2048, 6)
        )
  
    def forward(self, x):
        return self.model(x)


def main():
    # make_train_test_folder(data_path) # uncomment this line if want to build new train and test set

    train_dir = data_path / ""train""
    test_dir = data_path / ""test""

    # Write transform for image
    data_transform = transforms.Compose([
        # Resize the images to 128x128
        transforms.Resize(size=(128, 128)),
        # Turn the image into a torch.Tensor
        transforms.ToTensor(), # this also converts all pixel values from 0 to 255 to be between 0.0 and 1.0 
        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
    ])

    # Use ImageFolder to create dataset(s)
    train_data = datasets.ImageFolder(root=train_dir, # target folder of images
                                    transform=data_transform, # transforms to perform on data (images)
                                    target_transform=None) # transforms to perform on labels (if necessary)

    test_data = datasets.ImageFolder(root=test_dir, 
                                    transform=data_transform)

    # Turn train and test Datasets into DataLoaders
    from torch.utils.data import DataLoader
    batch_size = 32
    train_dataloader = DataLoader(dataset=train_data, batch_size=batch_size, 
                                    num_workers=0, shuffle=True)

    test_dataloader = DataLoader(dataset=test_data, batch_size=batch_size, 
                                    num_workers=0, shuffle=False)

    #Selecting the appropriate training device
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    # model = CNN().to(device)

    # #Defining the model hyper parameters
    # num_epochs = 40
    # criterion = torch.nn.CrossEntropyLoss()
    # optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)

    # train_loss_list = []
    # for epoch in range(num_epochs):
    #     print(f'Epoch {epoch+1}/{num_epochs}:', end = ' ')
    #     train_loss = 0
        
    #     #Iterating over the training dataset in batches
    #     model.train()
    #     for i, (images, labels) in enumerate(train_dataloader):
    #         #Extracting images and target labels for the batch being iterated
    #         images = images.to(device)
    #         labels = labels.to(device)

    #         #Calculating the model output and the cross entropy loss
    #         outputs = model(images)
    #         loss = criterion(outputs, labels)
    
    #         #Updating weights according to calculated loss
    #         optimizer.zero_grad()
    #         loss.backward()
    #         optimizer.step()
    #         train_loss += loss.item()
        
    #     #Printing loss for each epoch
    #     train_loss_list.append(train_loss/len(train_dataloader))
    #     print(f""Training loss = {train_loss_list[-1]}"")  

    PATH = './garbage_classification.pth'
    # torch.save(model.state_dict(), PATH)

    model = CNN().to(device)
    model.load_state_dict(torch.load(PATH))
    model.eval()

    classes = (""cardboard"", ""glass"", ""metal"", ""paper"", ""plastic"", ""trash"")

    correct = 0
    total = 0
    y_true = []
    y_pred = []
    # since we're not training, we don't need to calculate the gradients for our outputs
    with torch.no_grad():
        for data in test_dataloader:
            images, labels = data
            y_true.extend(labels.numpy())
            # calculate outputs by running images through the network
            outputs = model(images)
            # the class with the highest energy is what we choose as prediction
            _, predicted = torch.max(outputs.data, 1)
            y_pred.extend(predicted.cpu().numpy())
            total += labels.size(0)
            correct += (predicted == labels).sum().item()

    print(f'Accuracy of the network on the test images: {100 * correct // total} %')

    from sklearn.metrics import confusion_matrix
    cf_matrix = confusion_matrix(y_true, y_pred)

    import pandas as pd
    dataframe = pd.DataFrame(cf_matrix, index=classes, columns=classes)

    print(dataframe)


main()",
278,2,,28154,,,output: output.txt;,"c:/Users/thien/Desktop/project/venv/Scripts/python.exe c:/Users/thien/Desktop/project/main.py
Accuracy of the network on the test images: 62 %
           cardboard  glass  metal  paper  plastic  trash
cardboard         60      2      6      5        8      0
glass              4     40      7     13       34      3
metal              8      7     37      7       21      2
paper              4      3      7    101        2      2
plastic            4      7      2     13       69      2
trash              4      4      6      0        3     11
(venv)",
279,2,,28407,,,code: main.py;,"import math
import os
from pathlib import Path
import random
from PIL import Image
import shutil
import torch
from torch.utils.data import DataLoader
from torchvision import datasets, transforms

garbage_classification_folder = r""C:\Users\thien\Desktop\project\dat\Garbage classification\Garbage classification""

# Setup path to data folder
data_path = Path(garbage_classification_folder)

def walk_through_dir(dir_path):
    no_of_files = 0
    for dirpath, dirnames, filenames in os.walk(dir_path):
        # print(f""There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'."")
        no_of_files = len(filenames)
    return no_of_files


# pass in the img dir path (eg. ./cardboard)
def get_random_img_list(dir_path, N):
    random.seed(42)

    # get all image paths (* means ""any combination"")
    image_path_list = list(dir_path.glob(""*.jpg""))

    # get random image paths for training data
    image_list_train = random.sample(image_path_list, k = N)

    # remaining image paths will be used as testing data
    s = set(image_list_train)
    image_list_test = [x for x in image_path_list if x not in s]

    return image_list_train, image_list_test


def make_train_test_folder(dir_path):
    train_folder = dir_path / ""train""
    test_folder = dir_path / ""test""
    if os.path.exists(train_folder):
        shutil.rmtree(train_folder)
    if os.path.exists(test_folder):
        shutil.rmtree(test_folder)
    
    if not os.path.exists(train_folder) and not os.path.exists(test_folder):
        os.mkdir(train_folder)
        os.mkdir(test_folder)
        # we need to select random images from all img folders and build up our train set
        collection = [""cardboard"", ""glass"", ""metal"", ""paper"", ""plastic"", ""trash""]
        for el in collection:
            el_path = dir_path / el
            no_of_imgs = walk_through_dir(el_path)

            # grab 80% of imgs for training
            training_amount = math.floor(0.8 * no_of_imgs)
            training_dat, testing_dat = get_random_img_list(el_path, training_amount)

            os.mkdir(train_folder / el)
            os.mkdir(test_folder / el)

            for train_img_path in training_dat:
                shutil.copy2(src=train_img_path, dst=train_folder / el)
            
            for test_img_path in testing_dat:
                shutil.copy2(src=test_img_path, dst=test_folder / el)


class CNN(torch.nn.Module):
    def __init__(self):
        super().__init__()
        self.model = torch.nn.Sequential(
            #Input = 3 x 128 x 128, Output = 128 x 128 x 128
            torch.nn.Conv2d(in_channels = 3, out_channels = 128, kernel_size = 3, padding = 1), 
            torch.nn.ReLU(),
            #Input = 128 x 128 x 128, Output = 128 x 64 x 64
            torch.nn.MaxPool2d(kernel_size=2),
  
            #Input = 128 x 64 x 64, Output = 256 x 64 x 64
            torch.nn.Conv2d(in_channels = 128, out_channels = 256, kernel_size = 3, padding = 1),
            torch.nn.ReLU(),
            #Input = 256 x 64 x 64, Output = 256 x 32 x 32
            torch.nn.MaxPool2d(kernel_size=2),
              
            #Input = 256 x 32 x 32, Output = 256 x 32 x 32
            torch.nn.Conv2d(in_channels = 256, out_channels = 256, kernel_size = 3, padding = 1),
            torch.nn.ReLU(),
            #Input = 256 x 32 x 32, Output = 256 x 16 x 16
            torch.nn.MaxPool2d(kernel_size=2),

            #Input = 256 x 16 x 16, Output = 128 x 16 x 16
            torch.nn.Conv2d(in_channels = 256, out_channels = 128, kernel_size = 3, padding = 1),
            torch.nn.ReLU(),
            #Input = 128 x 16 x 16, Output = 128 x 8 x 8
            torch.nn.MaxPool2d(kernel_size=2),
  
            torch.nn.Flatten(),
            torch.nn.Linear(128*8*8, 2048),
            torch.nn.ReLU(),
            torch.nn.Linear(2048, 6)
        )
  
    def forward(self, x):
        return self.model(x)


def main():
    # make_train_test_folder(data_path) # uncomment this line if want to build new train and test set

    train_dir = data_path / ""train""
    test_dir = data_path / ""test""

    # Write transform for image
    data_transform = transforms.Compose([
        # Resize the images to 128x128
        transforms.Resize(size=(128, 128)),
        # Turn the image into a torch.Tensor
        transforms.ToTensor(), # this also converts all pixel values from 0 to 255 to be between 0.0 and 1.0 
        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
    ])

    # Use ImageFolder to create dataset(s)
    train_data = datasets.ImageFolder(root=train_dir, # target folder of images
                                    transform=data_transform, # transforms to perform on data (images)
                                    target_transform=None) # transforms to perform on labels (if necessary)

    test_data = datasets.ImageFolder(root=test_dir, 
                                    transform=data_transform)

    # Turn train and test Datasets into DataLoaders
    from torch.utils.data import DataLoader
    batch_size = 32
    train_dataloader = DataLoader(dataset=train_data, batch_size=batch_size, 
                                    num_workers=0, shuffle=True)

    test_dataloader = DataLoader(dataset=test_data, batch_size=batch_size, 
                                    num_workers=0, shuffle=False)

    #Selecting the appropriate training device
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    # model = CNN().to(device)

    # #Defining the model hyper parameters
    # num_epochs = 40
    # criterion = torch.nn.CrossEntropyLoss()
    # optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)

    # train_loss_list = []
    # for epoch in range(num_epochs):
    #     print(f'Epoch {epoch+1}/{num_epochs}:', end = ' ')
    #     train_loss = 0
        
    #     #Iterating over the training dataset in batches
    #     model.train()
    #     for i, (images, labels) in enumerate(train_dataloader):
    #         #Extracting images and target labels for the batch being iterated
    #         images = images.to(device)
    #         labels = labels.to(device)

    #         #Calculating the model output and the cross entropy loss
    #         outputs = model(images)
    #         loss = criterion(outputs, labels)
    
    #         #Updating weights according to calculated loss
    #         optimizer.zero_grad()
    #         loss.backward()
    #         optimizer.step()
    #         train_loss += loss.item()
        
    #     #Printing loss for each epoch
    #     train_loss_list.append(train_loss/len(train_dataloader))
    #     print(f""Training loss = {train_loss_list[-1]}"")  

    PATH = './garbage_classification.pth'
    # torch.save(model.state_dict(), PATH)

    model = CNN().to(device)
    model.load_state_dict(torch.load(PATH))
    model.eval()

    classes = (""cardboard"", ""glass"", ""metal"", ""paper"", ""plastic"", ""trash"")

    correct = 0
    total = 0
    y_true = []
    y_pred = []
    # since we're not training, we don't need to calculate the gradients for our outputs
    with torch.no_grad():
        for data in test_dataloader:
            images, labels = data
            y_true.extend(labels.numpy())
            # calculate outputs by running images through the network
            outputs = model(images)
            # the class with the highest energy is what we choose as prediction
            _, predicted = torch.max(outputs.data, 1)
            y_pred.extend(predicted.cpu().numpy())
            total += labels.size(0)
            correct += (predicted == labels).sum().item()

    print(f'Accuracy of the network on the test images: {100 * correct // total} %')

    from sklearn.metrics import confusion_matrix
    cf_matrix = confusion_matrix(y_true, y_pred)

    import pandas as pd
    dataframe = pd.DataFrame(cf_matrix, index=classes, columns=classes)

    from plot_func import confusion_matrix_viz
    confusion_matrix_viz(dataframe)


main()",
280,2,,28407,,,output: output.txt;,"c:/Users/thien/Desktop/project/venv/Scripts/python.exe c:/Users/thien/Desktop/project/main.py
Accuracy of the network on the test images: 62 %
(venv)",
281,2,,28407,,,code: plot_func.py;,"import random
from PIL import Image
import matplotlib.pyplot as plt
import numpy as np
import seaborn as sns

# eg. call: plot_transformed_images(image_path_list, transform=data_transform, n=1)
def plot_transformed_images(image_paths, transform, n):
    # Plots a series of random images from image_paths.
    # Will open n image paths from image_paths, transform them
    # with transform and plot them side by side.
    random.seed(42)
    random_image_paths = random.sample(image_paths, k=n)
    for image_path in random_image_paths:
        with Image.open(image_path) as f:
            fig, ax = plt.subplots(1, 2)
            ax[0].imshow(f) 
            ax[0].set_title(f""Original \nSize: {f.size}"")
            ax[0].axis(""off"")

            # Transform and plot image
            # Note: permute() will change shape of image to suit matplotlib 
            # (PyTorch default is [C, H, W] but Matplotlib is [H, W, C])
            transformed_image = transform(f).permute(1, 2, 0) 
            ax[1].imshow(transformed_image) 
            ax[1].set_title(f""Transformed \nSize: {transformed_image.shape}"")
            ax[1].axis(""off"")

            fig.suptitle(f""Class: {image_path.parent.stem}"", fontsize=16)
            plt.show(block=False)
            plt.pause(10)
            plt.close()


# eg. imshow(torchvision.utils.make_grid(images))
def imshow(img):
    img = img / 2 + 0.5     # unnormalize
    npimg = img.numpy()
    plt.imshow(np.transpose(npimg, (1, 2, 0)))
    plt.show()

def confusion_matrix_viz(df):
    plt.figure(figsize=(8, 6))
 
    # Create heatmap
    sns.heatmap(df, annot=True, cbar=None,cmap=""YlGnBu"",fmt=""d"")
    
    plt.title(""Confusion Matrix""), plt.tight_layout()
    
    plt.ylabel(""True Class""), 
    plt.xlabel(""Predicted Class"")
    plt.show()",
282,2,,29185,,,code: main.py;,"import math
import os
from pathlib import Path
import random
from PIL import Image
import shutil
import torch
from torch.utils.data import DataLoader
from torchvision import datasets, transforms

garbage_classification_folder = r""C:\Users\thien\Desktop\project\dat\Garbage classification\Garbage classification""

# Setup path to data folder
data_path = Path(garbage_classification_folder)

def walk_through_dir(dir_path):
    no_of_files = 0
    for dirpath, dirnames, filenames in os.walk(dir_path):
        # print(f""There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'."")
        no_of_files = len(filenames)
    return no_of_files


# pass in the img dir path (eg. ./cardboard)
def get_random_img_list(dir_path, N):
    random.seed(42)

    # get all image paths (* means ""any combination"")
    image_path_list = list(dir_path.glob(""*.jpg""))

    # get random image paths for training data
    image_list_train = random.sample(image_path_list, k = N)

    # remaining image paths will be used as testing data
    s = set(image_list_train)
    image_list_test = [x for x in image_path_list if x not in s]

    return image_list_train, image_list_test


def make_train_test_folder(dir_path):
    train_folder = dir_path / ""train""
    test_folder = dir_path / ""test""
    if os.path.exists(train_folder):
        shutil.rmtree(train_folder)
    if os.path.exists(test_folder):
        shutil.rmtree(test_folder)
    
    if not os.path.exists(train_folder) and not os.path.exists(test_folder):
        os.mkdir(train_folder)
        os.mkdir(test_folder)
        # we need to select random images from all img folders and build up our train set
        collection = [""cardboard"", ""glass"", ""metal"", ""paper"", ""plastic"", ""trash""]
        for el in collection:
            el_path = dir_path / el
            no_of_imgs = walk_through_dir(el_path)

            # grab 80% of imgs for training
            training_amount = math.floor(0.8 * no_of_imgs)
            training_dat, testing_dat = get_random_img_list(el_path, training_amount)

            os.mkdir(train_folder / el)
            os.mkdir(test_folder / el)

            for train_img_path in training_dat:
                shutil.copy2(src=train_img_path, dst=train_folder / el)
            
            for test_img_path in testing_dat:
                shutil.copy2(src=test_img_path, dst=test_folder / el)


def train(model, num_epochs, train_dataloader, device, criterion, optimizer, PATH='./garbage_classification.pth'):
    train_loss_list = []
    for epoch in range(num_epochs):
        print(f'Epoch {epoch+1}/{num_epochs}:', end = ' ')
        train_loss = 0
        
        #Iterating over the training dataset in batches
        model.train()
        for i, (images, labels) in enumerate(train_dataloader):
            #Extracting images and target labels for the batch being iterated
            images = images.to(device)
            labels = labels.to(device)

            #Calculating the model output and the cross entropy loss
            outputs = model(images)
            loss = criterion(outputs, labels)
    
            #Updating weights according to calculated loss
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
            train_loss += loss.item()
        
        #Printing loss for each epoch
        train_loss_list.append(train_loss/len(train_dataloader))
        print(f""Training loss = {train_loss_list[-1]}"")
    
    save_path = PATH
    torch.save(model.state_dict(), save_path)


def main():
    # make_train_test_folder(data_path) # uncomment this line if want to build new train and test set

    train_dir = data_path / ""train""
    test_dir = data_path / ""test""

    # Write transform for image
    data_transform = transforms.Compose([
        # Resize the images to 128x128
        transforms.Resize(size=(128, 128)),
        # Turn the image into a torch.Tensor
        transforms.ToTensor(), # this also converts all pixel values from 0 to 255 to be between 0.0 and 1.0 
        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
    ])

    # Use ImageFolder to create dataset(s)
    train_data = datasets.ImageFolder(root=train_dir, # target folder of images
                                    transform=data_transform, # transforms to perform on data (images)
                                    target_transform=None) # transforms to perform on labels (if necessary)

    test_data = datasets.ImageFolder(root=test_dir, 
                                    transform=data_transform)

    # Turn train and test Datasets into DataLoaders
    from torch.utils.data import DataLoader
    batch_size = 32
    train_dataloader = DataLoader(dataset=train_data, batch_size=batch_size, 
                                    num_workers=0, shuffle=True)

    test_dataloader = DataLoader(dataset=test_data, batch_size=batch_size, 
                                    num_workers=0, shuffle=False)

    #Selecting the appropriate training device
    device = 'cuda' if torch.cuda.is_available() else 'cpu'

    from model import CNN
    model = CNN().to(device)

    #Defining the model hyper parameters
    num_epochs = 40
    criterion = torch.nn.CrossEntropyLoss()
    optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)
    PATH = './garbage_classification.pth'
    # train(model=model, num_epochs=num_epochs, train_dataloader=train_dataloader, device=device, criterion=criterion, optimizer=optimizer, PATH=PATH) # uncomment this line if want to train from beginning

    model.load_state_dict(torch.load(PATH))
    model.eval()

    classes = (""cardboard"", ""glass"", ""metal"", ""paper"", ""plastic"", ""trash"")

    correct = 0
    total = 0
    y_true = []
    y_pred = []
    # since we're not training, we don't need to calculate the gradients for our outputs
    with torch.no_grad():
        for data in test_dataloader:
            images, labels = data
            y_true.extend(labels.numpy())
            # calculate outputs by running images through the network
            outputs = model(images)
            # the class with the highest energy is what we choose as prediction
            _, predicted = torch.max(outputs.data, 1)
            y_pred.extend(predicted.cpu().numpy())
            total += labels.size(0)
            correct += (predicted == labels).sum().item()

    print(f'Accuracy of the network on the test images: {100 * correct // total} %')

    from sklearn.metrics import confusion_matrix
    cf_matrix = confusion_matrix(y_true, y_pred)

    import pandas as pd
    dataframe = pd.DataFrame(cf_matrix, index=classes, columns=classes)

    from plot_func import confusion_matrix_viz
    confusion_matrix_viz(dataframe)


main()",
283,2,,29185,,,code: model.py;,"import torch

class CNN(torch.nn.Module):
    def __init__(self):
        super().__init__()
        self.model = torch.nn.Sequential(
            #Input = 3 x 128 x 128, Output = 128 x 128 x 128
            torch.nn.Conv2d(in_channels = 3, out_channels = 128, kernel_size = 3, padding = 1), 
            torch.nn.ReLU(),
            #Input = 128 x 128 x 128, Output = 128 x 64 x 64
            torch.nn.MaxPool2d(kernel_size=2),
  
            #Input = 128 x 64 x 64, Output = 256 x 64 x 64
            torch.nn.Conv2d(in_channels = 128, out_channels = 256, kernel_size = 3, padding = 1),
            torch.nn.ReLU(),
            #Input = 256 x 64 x 64, Output = 256 x 32 x 32
            torch.nn.MaxPool2d(kernel_size=2),
              
            #Input = 256 x 32 x 32, Output = 256 x 32 x 32
            torch.nn.Conv2d(in_channels = 256, out_channels = 256, kernel_size = 3, padding = 1),
            torch.nn.ReLU(),
            #Input = 256 x 32 x 32, Output = 256 x 16 x 16
            torch.nn.MaxPool2d(kernel_size=2),

            #Input = 256 x 16 x 16, Output = 128 x 16 x 16
            torch.nn.Conv2d(in_channels = 256, out_channels = 128, kernel_size = 3, padding = 1),
            torch.nn.ReLU(),
            #Input = 128 x 16 x 16, Output = 128 x 8 x 8
            torch.nn.MaxPool2d(kernel_size=2),
  
            torch.nn.Flatten(),
            torch.nn.Linear(128*8*8, 2048),
            torch.nn.ReLU(),
            torch.nn.Linear(2048, 6)
        )
  
    def forward(self, x):
        return self.model(x)


",
